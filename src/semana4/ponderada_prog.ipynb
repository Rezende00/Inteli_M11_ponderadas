{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x16lolnDTBA4"
      },
      "source": [
        "# Otimização de Modelo Pré-Treinado para Detecção de Fraudes em Cartões de Crédito\n",
        "\n",
        "## Inteli - Sistemas de Informação - Programação\n",
        "- **Professor**👨‍🏫: Jefferson de Oliveira Silva\n",
        "- **Aluno**👨‍🎓: Pedro de Carvalho Rezende"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V_lSxpF3TBBB"
      },
      "source": [
        "### Objetivo🚨\n",
        "Otimizar um modelo de rede neural pré-treinado para detecção de fraudes em cartões de crédito. Aplicar técnicas avançadas de ajuste fino de hiperparâmetros, como grid search e random search, com o objetivo de aprimorar as métricas de desempenho do modelo, incluindo precisão, recall, F1-score e AUC-ROC. A atividade também exige uma comparação entre o modelo otimizado e o modelo original, permitindo avaliar o impacto das modificações nos hiperparâmetros sobre o desempenho geral.\n",
        "\n",
        "\n",
        "### Instruções📃\n",
        "Para realizar esta atividade, você deve começar treinando o modelo de rede neural para detecção de fraudes em cartões de crédito. Os dados do cartão podem ser encontrados no link de conteúdo. Depois, obtenha as métricas de desempenho deste modelo como a precisão, recall, F1-score e AUC-ROC.  \n",
        "\n",
        "Em seguida, defina uma faixa de valores para os hiperparâmetros que deseja otimizar. Aplique técnicas de ajuste fino de hiperparâmetros para melhorar o desempenho do modelo. Você pode usar métodos como grid search e random search para encontrar as melhores combinações de hiperparâmetros.\n",
        "\n",
        "Após otimizar o modelo, compare os resultados obtidos com os resultados do modelo original. Analise como as mudanças nos hiperparâmetros impactaram o desempenho, considerando cada uma das métricas mencionadas. Por fim, documente todas as etapas realizadas e as observações feitas durante o processo.\n",
        "\n",
        "Entregue o link do caderno `.ipynb` em um repositório GitHub."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HTcOYoV6TBBD"
      },
      "source": [
        "# Instalações e Importações"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_qQo7GeQTBBF",
        "outputId": "e61b6a4f-38f3-4e37-e1e2-5d9276079fd2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: imblearn in /usr/local/lib/python3.10/dist-packages (0.0)\n",
            "Requirement already satisfied: imbalanced-learn in /usr/local/lib/python3.10/dist-packages (from imblearn) (0.12.3)\n",
            "Requirement already satisfied: numpy>=1.17.3 in /usr/local/lib/python3.10/dist-packages (from imbalanced-learn->imblearn) (1.26.4)\n",
            "Requirement already satisfied: scipy>=1.5.0 in /usr/local/lib/python3.10/dist-packages (from imbalanced-learn->imblearn) (1.13.1)\n",
            "Requirement already satisfied: scikit-learn>=1.0.2 in /usr/local/lib/python3.10/dist-packages (from imbalanced-learn->imblearn) (1.3.2)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from imbalanced-learn->imblearn) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from imbalanced-learn->imblearn) (3.5.0)\n",
            "Requirement already satisfied: keras in /usr/local/lib/python3.10/dist-packages (3.4.1)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.10/dist-packages (from keras) (1.4.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from keras) (1.26.4)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.10/dist-packages (from keras) (13.8.0)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.10/dist-packages (from keras) (0.0.8)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.10/dist-packages (from keras) (3.11.0)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.10/dist-packages (from keras) (0.12.1)\n",
            "Requirement already satisfied: ml-dtypes in /usr/local/lib/python3.10/dist-packages (from keras) (0.4.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from keras) (24.1)\n",
            "Requirement already satisfied: typing-extensions>=4.5.0 in /usr/local/lib/python3.10/dist-packages (from optree->keras) (4.12.2)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras) (2.16.1)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich->keras) (0.1.2)\n",
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.10/dist-packages (2.17.0)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=24.3.25 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (24.3.25)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.6.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: h5py>=3.10.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.11.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (18.1.1)\n",
            "Requirement already satisfied: ml-dtypes<0.5.0,>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.4.0)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.3.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow) (24.1)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.20.3)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.32.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow) (71.0.4)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.16.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.4.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (4.12.2)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.16.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.64.1)\n",
            "Requirement already satisfied: tensorboard<2.18,>=2.17 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.17.0)\n",
            "Requirement already satisfied: keras>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.4.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.37.1)\n",
            "Requirement already satisfied: numpy<2.0.0,>=1.23.5 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.26.4)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow) (0.44.0)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.10/dist-packages (from keras>=3.2.0->tensorflow) (13.8.0)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.10/dist-packages (from keras>=3.2.0->tensorflow) (0.0.8)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.10/dist-packages (from keras>=3.2.0->tensorflow) (0.12.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.8)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow) (2024.7.4)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.18,>=2.17->tensorflow) (3.7)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.18,>=2.17->tensorflow) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.18,>=2.17->tensorflow) (3.0.4)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.18,>=2.17->tensorflow) (2.1.5)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras>=3.2.0->tensorflow) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras>=3.2.0->tensorflow) (2.16.1)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich->keras>=3.2.0->tensorflow) (0.1.2)\n",
            "Collecting scikeras\n",
            "  Downloading scikeras-0.13.0-py3-none-any.whl.metadata (3.1 kB)\n",
            "Requirement already satisfied: keras>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from scikeras) (3.4.1)\n",
            "Collecting scikit-learn>=1.4.2 (from scikeras)\n",
            "  Downloading scikit_learn-1.5.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.10/dist-packages (from keras>=3.2.0->scikeras) (1.4.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from keras>=3.2.0->scikeras) (1.26.4)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.10/dist-packages (from keras>=3.2.0->scikeras) (13.8.0)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.10/dist-packages (from keras>=3.2.0->scikeras) (0.0.8)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.10/dist-packages (from keras>=3.2.0->scikeras) (3.11.0)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.10/dist-packages (from keras>=3.2.0->scikeras) (0.12.1)\n",
            "Requirement already satisfied: ml-dtypes in /usr/local/lib/python3.10/dist-packages (from keras>=3.2.0->scikeras) (0.4.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from keras>=3.2.0->scikeras) (24.1)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=1.4.2->scikeras) (1.13.1)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=1.4.2->scikeras) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=1.4.2->scikeras) (3.5.0)\n",
            "Requirement already satisfied: typing-extensions>=4.5.0 in /usr/local/lib/python3.10/dist-packages (from optree->keras>=3.2.0->scikeras) (4.12.2)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras>=3.2.0->scikeras) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras>=3.2.0->scikeras) (2.16.1)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich->keras>=3.2.0->scikeras) (0.1.2)\n",
            "Downloading scikeras-0.13.0-py3-none-any.whl (26 kB)\n",
            "Downloading scikit_learn-1.5.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (13.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.4/13.4 MB\u001b[0m \u001b[31m54.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: scikit-learn, scikeras\n",
            "  Attempting uninstall: scikit-learn\n",
            "    Found existing installation: scikit-learn 1.3.2\n",
            "    Uninstalling scikit-learn-1.3.2:\n",
            "      Successfully uninstalled scikit-learn-1.3.2\n",
            "Successfully installed scikeras-0.13.0 scikit-learn-1.5.1\n"
          ]
        }
      ],
      "source": [
        "# %pip install -q -r requirements.txt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 69,
      "metadata": {
        "id": "U6rESLZUTBBJ"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import plotly.graph_objs as go\n",
        "import plotly.express as px\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from plotly.subplots import make_subplots\n",
        "\n",
        "import tensorflow as tf\n",
        "import keras\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Input, Dropout\n",
        "from tensorflow.keras.metrics import BinaryAccuracy, AUC, Precision, Recall, Accuracy\n",
        "from tensorflow.keras.optimizers import Adam, Lion, RMSprop\n",
        "from tensorflow.keras.losses import BinaryCrossentropy\n",
        "from scikeras.wrappers import KerasClassifier, KerasRegressor\n",
        "\n",
        "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, roc_auc_score, make_scorer, accuracy_score\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV, RandomizedSearchCV\n",
        "from sklearn.preprocessing import StandardScaler, RobustScaler\n",
        "\n",
        "from imblearn.over_sampling import SMOTE\n",
        "from imblearn.under_sampling import RandomUnderSampler\n",
        "from imblearn.pipeline import Pipeline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Kb90VkAuTBBL",
        "outputId": "9a99ec18-cba7-4335-8f36-bbdf21f2a7db"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading...\n",
            "From (original): https://drive.google.com/uc?id=1Scb-zICL_-JG4n31I5F5_FM5X53zerWi\n",
            "From (redirected): https://drive.google.com/uc?id=1Scb-zICL_-JG4n31I5F5_FM5X53zerWi&confirm=t&uuid=d277a6e1-a7db-4adf-bf8f-818b7788b33a\n",
            "To: /content/creditcard.csv\n",
            "100% 151M/151M [00:06<00:00, 22.2MB/s]\n"
          ]
        }
      ],
      "source": [
        "# baixando o dataset utilizado\n",
        "!gdown 1Scb-zICL_-JG4n31I5F5_FM5X53zerWi"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EGOztceyTBBM"
      },
      "source": [
        "# Exploratória do Dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rxVYkb_7TBBN"
      },
      "source": [
        "O dataset escolhido foi de Detecção de fraudes em cartões de crédito (https://drive.google.com/file/d/1nriPPuYUMXeB6BkCjz_bQI_45WZfxViC/view?usp=drive_link).\n",
        "\n",
        "Este dataset contém informações sobre jogos disponíveis na plataforma Steam, incluindo o nome do jogo, a descrição, o preço, a data de lançamento, a avaliação dos usuários, entre outras informações."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "thqiOrRgTBBO",
        "outputId": "97fe552a-3ea3-43e8-9052-df7faaf2db99"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "          Time         V1         V2        V3        V4        V5        V6  \\\n",
              "0            0  -1.359807  -0.072781  2.536347  1.378155 -0.338321  0.462388   \n",
              "1            0   1.191857   0.266151  0.166480  0.448154  0.060018 -0.082361   \n",
              "2            1  -1.358354  -1.340163  1.773209  0.379780 -0.503198  1.800499   \n",
              "3            1  -0.966272  -0.185226  1.792993 -0.863291 -0.010309  1.247203   \n",
              "4            2  -1.158233   0.877737  1.548718  0.403034 -0.407193  0.095921   \n",
              "...        ...        ...        ...       ...       ...       ...       ...   \n",
              "284802  172786 -11.881118  10.071785 -9.834783 -2.066656 -5.364473 -2.606837   \n",
              "284803  172787  -0.732789  -0.055080  2.035030 -0.738589  0.868229  1.058415   \n",
              "284804  172788   1.919565  -0.301254 -3.249640 -0.557828  2.630515  3.031260   \n",
              "284805  172788  -0.240440   0.530483  0.702510  0.689799 -0.377961  0.623708   \n",
              "284806  172792  -0.533413  -0.189733  0.703337 -0.506271 -0.012546 -0.649617   \n",
              "\n",
              "              V7        V8        V9  ...       V21       V22       V23  \\\n",
              "0       0.239599  0.098698  0.363787  ... -0.018307  0.277838 -0.110474   \n",
              "1      -0.078803  0.085102 -0.255425  ... -0.225775 -0.638672  0.101288   \n",
              "2       0.791461  0.247676 -1.514654  ...  0.247998  0.771679  0.909412   \n",
              "3       0.237609  0.377436 -1.387024  ... -0.108300  0.005274 -0.190321   \n",
              "4       0.592941 -0.270533  0.817739  ... -0.009431  0.798278 -0.137458   \n",
              "...          ...       ...       ...  ...       ...       ...       ...   \n",
              "284802 -4.918215  7.305334  1.914428  ...  0.213454  0.111864  1.014480   \n",
              "284803  0.024330  0.294869  0.584800  ...  0.214205  0.924384  0.012463   \n",
              "284804 -0.296827  0.708417  0.432454  ...  0.232045  0.578229 -0.037501   \n",
              "284805 -0.686180  0.679145  0.392087  ...  0.265245  0.800049 -0.163298   \n",
              "284806  1.577006 -0.414650  0.486180  ...  0.261057  0.643078  0.376777   \n",
              "\n",
              "             V24       V25       V26       V27       V28  Amount  Class  \n",
              "0       0.066928  0.128539 -0.189115  0.133558 -0.021053  149.62      0  \n",
              "1      -0.339846  0.167170  0.125895 -0.008983  0.014724    2.69      0  \n",
              "2      -0.689281 -0.327642 -0.139097 -0.055353 -0.059752  378.66      0  \n",
              "3      -1.175575  0.647376 -0.221929  0.062723  0.061458  123.50      0  \n",
              "4       0.141267 -0.206010  0.502292  0.219422  0.215153   69.99      0  \n",
              "...          ...       ...       ...       ...       ...     ...    ...  \n",
              "284802 -0.509348  1.436807  0.250034  0.943651  0.823731    0.77      0  \n",
              "284803 -1.016226 -0.606624 -0.395255  0.068472 -0.053527   24.79      0  \n",
              "284804  0.640134  0.265745 -0.087371  0.004455 -0.026561   67.88      0  \n",
              "284805  0.123205 -0.569159  0.546668  0.108821  0.104533   10.00      0  \n",
              "284806  0.008797 -0.473649 -0.818267 -0.002415  0.013649  217.00      0  \n",
              "\n",
              "[284807 rows x 31 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-42a8b27c-cd7f-4a28-aefd-622d2195d46a\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Time</th>\n",
              "      <th>V1</th>\n",
              "      <th>V2</th>\n",
              "      <th>V3</th>\n",
              "      <th>V4</th>\n",
              "      <th>V5</th>\n",
              "      <th>V6</th>\n",
              "      <th>V7</th>\n",
              "      <th>V8</th>\n",
              "      <th>V9</th>\n",
              "      <th>...</th>\n",
              "      <th>V21</th>\n",
              "      <th>V22</th>\n",
              "      <th>V23</th>\n",
              "      <th>V24</th>\n",
              "      <th>V25</th>\n",
              "      <th>V26</th>\n",
              "      <th>V27</th>\n",
              "      <th>V28</th>\n",
              "      <th>Amount</th>\n",
              "      <th>Class</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>-1.359807</td>\n",
              "      <td>-0.072781</td>\n",
              "      <td>2.536347</td>\n",
              "      <td>1.378155</td>\n",
              "      <td>-0.338321</td>\n",
              "      <td>0.462388</td>\n",
              "      <td>0.239599</td>\n",
              "      <td>0.098698</td>\n",
              "      <td>0.363787</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.018307</td>\n",
              "      <td>0.277838</td>\n",
              "      <td>-0.110474</td>\n",
              "      <td>0.066928</td>\n",
              "      <td>0.128539</td>\n",
              "      <td>-0.189115</td>\n",
              "      <td>0.133558</td>\n",
              "      <td>-0.021053</td>\n",
              "      <td>149.62</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>1.191857</td>\n",
              "      <td>0.266151</td>\n",
              "      <td>0.166480</td>\n",
              "      <td>0.448154</td>\n",
              "      <td>0.060018</td>\n",
              "      <td>-0.082361</td>\n",
              "      <td>-0.078803</td>\n",
              "      <td>0.085102</td>\n",
              "      <td>-0.255425</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.225775</td>\n",
              "      <td>-0.638672</td>\n",
              "      <td>0.101288</td>\n",
              "      <td>-0.339846</td>\n",
              "      <td>0.167170</td>\n",
              "      <td>0.125895</td>\n",
              "      <td>-0.008983</td>\n",
              "      <td>0.014724</td>\n",
              "      <td>2.69</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>-1.358354</td>\n",
              "      <td>-1.340163</td>\n",
              "      <td>1.773209</td>\n",
              "      <td>0.379780</td>\n",
              "      <td>-0.503198</td>\n",
              "      <td>1.800499</td>\n",
              "      <td>0.791461</td>\n",
              "      <td>0.247676</td>\n",
              "      <td>-1.514654</td>\n",
              "      <td>...</td>\n",
              "      <td>0.247998</td>\n",
              "      <td>0.771679</td>\n",
              "      <td>0.909412</td>\n",
              "      <td>-0.689281</td>\n",
              "      <td>-0.327642</td>\n",
              "      <td>-0.139097</td>\n",
              "      <td>-0.055353</td>\n",
              "      <td>-0.059752</td>\n",
              "      <td>378.66</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>-0.966272</td>\n",
              "      <td>-0.185226</td>\n",
              "      <td>1.792993</td>\n",
              "      <td>-0.863291</td>\n",
              "      <td>-0.010309</td>\n",
              "      <td>1.247203</td>\n",
              "      <td>0.237609</td>\n",
              "      <td>0.377436</td>\n",
              "      <td>-1.387024</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.108300</td>\n",
              "      <td>0.005274</td>\n",
              "      <td>-0.190321</td>\n",
              "      <td>-1.175575</td>\n",
              "      <td>0.647376</td>\n",
              "      <td>-0.221929</td>\n",
              "      <td>0.062723</td>\n",
              "      <td>0.061458</td>\n",
              "      <td>123.50</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2</td>\n",
              "      <td>-1.158233</td>\n",
              "      <td>0.877737</td>\n",
              "      <td>1.548718</td>\n",
              "      <td>0.403034</td>\n",
              "      <td>-0.407193</td>\n",
              "      <td>0.095921</td>\n",
              "      <td>0.592941</td>\n",
              "      <td>-0.270533</td>\n",
              "      <td>0.817739</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.009431</td>\n",
              "      <td>0.798278</td>\n",
              "      <td>-0.137458</td>\n",
              "      <td>0.141267</td>\n",
              "      <td>-0.206010</td>\n",
              "      <td>0.502292</td>\n",
              "      <td>0.219422</td>\n",
              "      <td>0.215153</td>\n",
              "      <td>69.99</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>284802</th>\n",
              "      <td>172786</td>\n",
              "      <td>-11.881118</td>\n",
              "      <td>10.071785</td>\n",
              "      <td>-9.834783</td>\n",
              "      <td>-2.066656</td>\n",
              "      <td>-5.364473</td>\n",
              "      <td>-2.606837</td>\n",
              "      <td>-4.918215</td>\n",
              "      <td>7.305334</td>\n",
              "      <td>1.914428</td>\n",
              "      <td>...</td>\n",
              "      <td>0.213454</td>\n",
              "      <td>0.111864</td>\n",
              "      <td>1.014480</td>\n",
              "      <td>-0.509348</td>\n",
              "      <td>1.436807</td>\n",
              "      <td>0.250034</td>\n",
              "      <td>0.943651</td>\n",
              "      <td>0.823731</td>\n",
              "      <td>0.77</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>284803</th>\n",
              "      <td>172787</td>\n",
              "      <td>-0.732789</td>\n",
              "      <td>-0.055080</td>\n",
              "      <td>2.035030</td>\n",
              "      <td>-0.738589</td>\n",
              "      <td>0.868229</td>\n",
              "      <td>1.058415</td>\n",
              "      <td>0.024330</td>\n",
              "      <td>0.294869</td>\n",
              "      <td>0.584800</td>\n",
              "      <td>...</td>\n",
              "      <td>0.214205</td>\n",
              "      <td>0.924384</td>\n",
              "      <td>0.012463</td>\n",
              "      <td>-1.016226</td>\n",
              "      <td>-0.606624</td>\n",
              "      <td>-0.395255</td>\n",
              "      <td>0.068472</td>\n",
              "      <td>-0.053527</td>\n",
              "      <td>24.79</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>284804</th>\n",
              "      <td>172788</td>\n",
              "      <td>1.919565</td>\n",
              "      <td>-0.301254</td>\n",
              "      <td>-3.249640</td>\n",
              "      <td>-0.557828</td>\n",
              "      <td>2.630515</td>\n",
              "      <td>3.031260</td>\n",
              "      <td>-0.296827</td>\n",
              "      <td>0.708417</td>\n",
              "      <td>0.432454</td>\n",
              "      <td>...</td>\n",
              "      <td>0.232045</td>\n",
              "      <td>0.578229</td>\n",
              "      <td>-0.037501</td>\n",
              "      <td>0.640134</td>\n",
              "      <td>0.265745</td>\n",
              "      <td>-0.087371</td>\n",
              "      <td>0.004455</td>\n",
              "      <td>-0.026561</td>\n",
              "      <td>67.88</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>284805</th>\n",
              "      <td>172788</td>\n",
              "      <td>-0.240440</td>\n",
              "      <td>0.530483</td>\n",
              "      <td>0.702510</td>\n",
              "      <td>0.689799</td>\n",
              "      <td>-0.377961</td>\n",
              "      <td>0.623708</td>\n",
              "      <td>-0.686180</td>\n",
              "      <td>0.679145</td>\n",
              "      <td>0.392087</td>\n",
              "      <td>...</td>\n",
              "      <td>0.265245</td>\n",
              "      <td>0.800049</td>\n",
              "      <td>-0.163298</td>\n",
              "      <td>0.123205</td>\n",
              "      <td>-0.569159</td>\n",
              "      <td>0.546668</td>\n",
              "      <td>0.108821</td>\n",
              "      <td>0.104533</td>\n",
              "      <td>10.00</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>284806</th>\n",
              "      <td>172792</td>\n",
              "      <td>-0.533413</td>\n",
              "      <td>-0.189733</td>\n",
              "      <td>0.703337</td>\n",
              "      <td>-0.506271</td>\n",
              "      <td>-0.012546</td>\n",
              "      <td>-0.649617</td>\n",
              "      <td>1.577006</td>\n",
              "      <td>-0.414650</td>\n",
              "      <td>0.486180</td>\n",
              "      <td>...</td>\n",
              "      <td>0.261057</td>\n",
              "      <td>0.643078</td>\n",
              "      <td>0.376777</td>\n",
              "      <td>0.008797</td>\n",
              "      <td>-0.473649</td>\n",
              "      <td>-0.818267</td>\n",
              "      <td>-0.002415</td>\n",
              "      <td>0.013649</td>\n",
              "      <td>217.00</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>284807 rows × 31 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-42a8b27c-cd7f-4a28-aefd-622d2195d46a')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-42a8b27c-cd7f-4a28-aefd-622d2195d46a button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-42a8b27c-cd7f-4a28-aefd-622d2195d46a');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-15ca60ab-582c-41dd-9adf-923294ae0980\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-15ca60ab-582c-41dd-9adf-923294ae0980')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-15ca60ab-582c-41dd-9adf-923294ae0980 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_c733c4f0-7538-4880-a74a-127486add394\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('df')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_c733c4f0-7538-4880-a74a-127486add394 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('df');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df"
            }
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "df = pd.read_csv('creditcard.csv')\n",
        "df['Time'] = df['Time'].astype('int64') # fiz essa adaptação pois essa coluna aparenta ser algo como o ID do cliente\n",
        "df"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Aqui temos uma coluna de `Time` que aparenta ser algo como o ID do cliente\n",
        "- Todas as colunas de `Vn`, aparentam ser algo como uma característica que pode ter levado à Fraude\n",
        "- A coluna de `Amount` seria o valor gasto\n",
        "- A coluna de `Class` é se aquele registro foi confirmado ou não como Fraude"
      ],
      "metadata": {
        "id": "WqwRU3ZJcEus"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.info()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lkatxNJ0TvD7",
        "outputId": "fcdcae5c-2926-4b9d-9dfb-38fb2d0113c9"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 284807 entries, 0 to 284806\n",
            "Data columns (total 31 columns):\n",
            " #   Column  Non-Null Count   Dtype  \n",
            "---  ------  --------------   -----  \n",
            " 0   Time    284807 non-null  int64  \n",
            " 1   V1      284807 non-null  float64\n",
            " 2   V2      284807 non-null  float64\n",
            " 3   V3      284807 non-null  float64\n",
            " 4   V4      284807 non-null  float64\n",
            " 5   V5      284807 non-null  float64\n",
            " 6   V6      284807 non-null  float64\n",
            " 7   V7      284807 non-null  float64\n",
            " 8   V8      284807 non-null  float64\n",
            " 9   V9      284807 non-null  float64\n",
            " 10  V10     284807 non-null  float64\n",
            " 11  V11     284807 non-null  float64\n",
            " 12  V12     284807 non-null  float64\n",
            " 13  V13     284807 non-null  float64\n",
            " 14  V14     284807 non-null  float64\n",
            " 15  V15     284807 non-null  float64\n",
            " 16  V16     284807 non-null  float64\n",
            " 17  V17     284807 non-null  float64\n",
            " 18  V18     284807 non-null  float64\n",
            " 19  V19     284807 non-null  float64\n",
            " 20  V20     284807 non-null  float64\n",
            " 21  V21     284807 non-null  float64\n",
            " 22  V22     284807 non-null  float64\n",
            " 23  V23     284807 non-null  float64\n",
            " 24  V24     284807 non-null  float64\n",
            " 25  V25     284807 non-null  float64\n",
            " 26  V26     284807 non-null  float64\n",
            " 27  V27     284807 non-null  float64\n",
            " 28  V28     284807 non-null  float64\n",
            " 29  Amount  284807 non-null  float64\n",
            " 30  Class   284807 non-null  int64  \n",
            "dtypes: float64(29), int64(2)\n",
            "memory usage: 67.4 MB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.describe()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 350
        },
        "id": "jtSGjTe4UxW3",
        "outputId": "14dd83f5-3b92-447a-ab41-c05cbf98fb5c"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                Time            V1            V2            V3            V4  \\\n",
              "count  284807.000000  2.848070e+05  2.848070e+05  2.848070e+05  2.848070e+05   \n",
              "mean    94813.859575  1.168375e-15  3.416908e-16 -1.379537e-15  2.074095e-15   \n",
              "std     47488.145955  1.958696e+00  1.651309e+00  1.516255e+00  1.415869e+00   \n",
              "min         0.000000 -5.640751e+01 -7.271573e+01 -4.832559e+01 -5.683171e+00   \n",
              "25%     54201.500000 -9.203734e-01 -5.985499e-01 -8.903648e-01 -8.486401e-01   \n",
              "50%     84692.000000  1.810880e-02  6.548556e-02  1.798463e-01 -1.984653e-02   \n",
              "75%    139320.500000  1.315642e+00  8.037239e-01  1.027196e+00  7.433413e-01   \n",
              "max    172792.000000  2.454930e+00  2.205773e+01  9.382558e+00  1.687534e+01   \n",
              "\n",
              "                 V5            V6            V7            V8            V9  \\\n",
              "count  2.848070e+05  2.848070e+05  2.848070e+05  2.848070e+05  2.848070e+05   \n",
              "mean   9.604066e-16  1.487313e-15 -5.556467e-16  1.213481e-16 -2.406331e-15   \n",
              "std    1.380247e+00  1.332271e+00  1.237094e+00  1.194353e+00  1.098632e+00   \n",
              "min   -1.137433e+02 -2.616051e+01 -4.355724e+01 -7.321672e+01 -1.343407e+01   \n",
              "25%   -6.915971e-01 -7.682956e-01 -5.540759e-01 -2.086297e-01 -6.430976e-01   \n",
              "50%   -5.433583e-02 -2.741871e-01  4.010308e-02  2.235804e-02 -5.142873e-02   \n",
              "75%    6.119264e-01  3.985649e-01  5.704361e-01  3.273459e-01  5.971390e-01   \n",
              "max    3.480167e+01  7.330163e+01  1.205895e+02  2.000721e+01  1.559499e+01   \n",
              "\n",
              "       ...           V21           V22           V23           V24  \\\n",
              "count  ...  2.848070e+05  2.848070e+05  2.848070e+05  2.848070e+05   \n",
              "mean   ...  1.654067e-16 -3.568593e-16  2.578648e-16  4.473266e-15   \n",
              "std    ...  7.345240e-01  7.257016e-01  6.244603e-01  6.056471e-01   \n",
              "min    ... -3.483038e+01 -1.093314e+01 -4.480774e+01 -2.836627e+00   \n",
              "25%    ... -2.283949e-01 -5.423504e-01 -1.618463e-01 -3.545861e-01   \n",
              "50%    ... -2.945017e-02  6.781943e-03 -1.119293e-02  4.097606e-02   \n",
              "75%    ...  1.863772e-01  5.285536e-01  1.476421e-01  4.395266e-01   \n",
              "max    ...  2.720284e+01  1.050309e+01  2.252841e+01  4.584549e+00   \n",
              "\n",
              "                V25           V26           V27           V28         Amount  \\\n",
              "count  2.848070e+05  2.848070e+05  2.848070e+05  2.848070e+05  284807.000000   \n",
              "mean   5.340915e-16  1.683437e-15 -3.660091e-16 -1.227390e-16      88.349619   \n",
              "std    5.212781e-01  4.822270e-01  4.036325e-01  3.300833e-01     250.120109   \n",
              "min   -1.029540e+01 -2.604551e+00 -2.256568e+01 -1.543008e+01       0.000000   \n",
              "25%   -3.171451e-01 -3.269839e-01 -7.083953e-02 -5.295979e-02       5.600000   \n",
              "50%    1.659350e-02 -5.213911e-02  1.342146e-03  1.124383e-02      22.000000   \n",
              "75%    3.507156e-01  2.409522e-01  9.104512e-02  7.827995e-02      77.165000   \n",
              "max    7.519589e+00  3.517346e+00  3.161220e+01  3.384781e+01   25691.160000   \n",
              "\n",
              "               Class  \n",
              "count  284807.000000  \n",
              "mean        0.001727  \n",
              "std         0.041527  \n",
              "min         0.000000  \n",
              "25%         0.000000  \n",
              "50%         0.000000  \n",
              "75%         0.000000  \n",
              "max         1.000000  \n",
              "\n",
              "[8 rows x 31 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-dd873ede-16c1-4bdf-9995-7a5698d1e298\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Time</th>\n",
              "      <th>V1</th>\n",
              "      <th>V2</th>\n",
              "      <th>V3</th>\n",
              "      <th>V4</th>\n",
              "      <th>V5</th>\n",
              "      <th>V6</th>\n",
              "      <th>V7</th>\n",
              "      <th>V8</th>\n",
              "      <th>V9</th>\n",
              "      <th>...</th>\n",
              "      <th>V21</th>\n",
              "      <th>V22</th>\n",
              "      <th>V23</th>\n",
              "      <th>V24</th>\n",
              "      <th>V25</th>\n",
              "      <th>V26</th>\n",
              "      <th>V27</th>\n",
              "      <th>V28</th>\n",
              "      <th>Amount</th>\n",
              "      <th>Class</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>284807.000000</td>\n",
              "      <td>2.848070e+05</td>\n",
              "      <td>2.848070e+05</td>\n",
              "      <td>2.848070e+05</td>\n",
              "      <td>2.848070e+05</td>\n",
              "      <td>2.848070e+05</td>\n",
              "      <td>2.848070e+05</td>\n",
              "      <td>2.848070e+05</td>\n",
              "      <td>2.848070e+05</td>\n",
              "      <td>2.848070e+05</td>\n",
              "      <td>...</td>\n",
              "      <td>2.848070e+05</td>\n",
              "      <td>2.848070e+05</td>\n",
              "      <td>2.848070e+05</td>\n",
              "      <td>2.848070e+05</td>\n",
              "      <td>2.848070e+05</td>\n",
              "      <td>2.848070e+05</td>\n",
              "      <td>2.848070e+05</td>\n",
              "      <td>2.848070e+05</td>\n",
              "      <td>284807.000000</td>\n",
              "      <td>284807.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>94813.859575</td>\n",
              "      <td>1.168375e-15</td>\n",
              "      <td>3.416908e-16</td>\n",
              "      <td>-1.379537e-15</td>\n",
              "      <td>2.074095e-15</td>\n",
              "      <td>9.604066e-16</td>\n",
              "      <td>1.487313e-15</td>\n",
              "      <td>-5.556467e-16</td>\n",
              "      <td>1.213481e-16</td>\n",
              "      <td>-2.406331e-15</td>\n",
              "      <td>...</td>\n",
              "      <td>1.654067e-16</td>\n",
              "      <td>-3.568593e-16</td>\n",
              "      <td>2.578648e-16</td>\n",
              "      <td>4.473266e-15</td>\n",
              "      <td>5.340915e-16</td>\n",
              "      <td>1.683437e-15</td>\n",
              "      <td>-3.660091e-16</td>\n",
              "      <td>-1.227390e-16</td>\n",
              "      <td>88.349619</td>\n",
              "      <td>0.001727</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>47488.145955</td>\n",
              "      <td>1.958696e+00</td>\n",
              "      <td>1.651309e+00</td>\n",
              "      <td>1.516255e+00</td>\n",
              "      <td>1.415869e+00</td>\n",
              "      <td>1.380247e+00</td>\n",
              "      <td>1.332271e+00</td>\n",
              "      <td>1.237094e+00</td>\n",
              "      <td>1.194353e+00</td>\n",
              "      <td>1.098632e+00</td>\n",
              "      <td>...</td>\n",
              "      <td>7.345240e-01</td>\n",
              "      <td>7.257016e-01</td>\n",
              "      <td>6.244603e-01</td>\n",
              "      <td>6.056471e-01</td>\n",
              "      <td>5.212781e-01</td>\n",
              "      <td>4.822270e-01</td>\n",
              "      <td>4.036325e-01</td>\n",
              "      <td>3.300833e-01</td>\n",
              "      <td>250.120109</td>\n",
              "      <td>0.041527</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>-5.640751e+01</td>\n",
              "      <td>-7.271573e+01</td>\n",
              "      <td>-4.832559e+01</td>\n",
              "      <td>-5.683171e+00</td>\n",
              "      <td>-1.137433e+02</td>\n",
              "      <td>-2.616051e+01</td>\n",
              "      <td>-4.355724e+01</td>\n",
              "      <td>-7.321672e+01</td>\n",
              "      <td>-1.343407e+01</td>\n",
              "      <td>...</td>\n",
              "      <td>-3.483038e+01</td>\n",
              "      <td>-1.093314e+01</td>\n",
              "      <td>-4.480774e+01</td>\n",
              "      <td>-2.836627e+00</td>\n",
              "      <td>-1.029540e+01</td>\n",
              "      <td>-2.604551e+00</td>\n",
              "      <td>-2.256568e+01</td>\n",
              "      <td>-1.543008e+01</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>54201.500000</td>\n",
              "      <td>-9.203734e-01</td>\n",
              "      <td>-5.985499e-01</td>\n",
              "      <td>-8.903648e-01</td>\n",
              "      <td>-8.486401e-01</td>\n",
              "      <td>-6.915971e-01</td>\n",
              "      <td>-7.682956e-01</td>\n",
              "      <td>-5.540759e-01</td>\n",
              "      <td>-2.086297e-01</td>\n",
              "      <td>-6.430976e-01</td>\n",
              "      <td>...</td>\n",
              "      <td>-2.283949e-01</td>\n",
              "      <td>-5.423504e-01</td>\n",
              "      <td>-1.618463e-01</td>\n",
              "      <td>-3.545861e-01</td>\n",
              "      <td>-3.171451e-01</td>\n",
              "      <td>-3.269839e-01</td>\n",
              "      <td>-7.083953e-02</td>\n",
              "      <td>-5.295979e-02</td>\n",
              "      <td>5.600000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>84692.000000</td>\n",
              "      <td>1.810880e-02</td>\n",
              "      <td>6.548556e-02</td>\n",
              "      <td>1.798463e-01</td>\n",
              "      <td>-1.984653e-02</td>\n",
              "      <td>-5.433583e-02</td>\n",
              "      <td>-2.741871e-01</td>\n",
              "      <td>4.010308e-02</td>\n",
              "      <td>2.235804e-02</td>\n",
              "      <td>-5.142873e-02</td>\n",
              "      <td>...</td>\n",
              "      <td>-2.945017e-02</td>\n",
              "      <td>6.781943e-03</td>\n",
              "      <td>-1.119293e-02</td>\n",
              "      <td>4.097606e-02</td>\n",
              "      <td>1.659350e-02</td>\n",
              "      <td>-5.213911e-02</td>\n",
              "      <td>1.342146e-03</td>\n",
              "      <td>1.124383e-02</td>\n",
              "      <td>22.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>139320.500000</td>\n",
              "      <td>1.315642e+00</td>\n",
              "      <td>8.037239e-01</td>\n",
              "      <td>1.027196e+00</td>\n",
              "      <td>7.433413e-01</td>\n",
              "      <td>6.119264e-01</td>\n",
              "      <td>3.985649e-01</td>\n",
              "      <td>5.704361e-01</td>\n",
              "      <td>3.273459e-01</td>\n",
              "      <td>5.971390e-01</td>\n",
              "      <td>...</td>\n",
              "      <td>1.863772e-01</td>\n",
              "      <td>5.285536e-01</td>\n",
              "      <td>1.476421e-01</td>\n",
              "      <td>4.395266e-01</td>\n",
              "      <td>3.507156e-01</td>\n",
              "      <td>2.409522e-01</td>\n",
              "      <td>9.104512e-02</td>\n",
              "      <td>7.827995e-02</td>\n",
              "      <td>77.165000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>172792.000000</td>\n",
              "      <td>2.454930e+00</td>\n",
              "      <td>2.205773e+01</td>\n",
              "      <td>9.382558e+00</td>\n",
              "      <td>1.687534e+01</td>\n",
              "      <td>3.480167e+01</td>\n",
              "      <td>7.330163e+01</td>\n",
              "      <td>1.205895e+02</td>\n",
              "      <td>2.000721e+01</td>\n",
              "      <td>1.559499e+01</td>\n",
              "      <td>...</td>\n",
              "      <td>2.720284e+01</td>\n",
              "      <td>1.050309e+01</td>\n",
              "      <td>2.252841e+01</td>\n",
              "      <td>4.584549e+00</td>\n",
              "      <td>7.519589e+00</td>\n",
              "      <td>3.517346e+00</td>\n",
              "      <td>3.161220e+01</td>\n",
              "      <td>3.384781e+01</td>\n",
              "      <td>25691.160000</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>8 rows × 31 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-dd873ede-16c1-4bdf-9995-7a5698d1e298')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-dd873ede-16c1-4bdf-9995-7a5698d1e298 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-dd873ede-16c1-4bdf-9995-7a5698d1e298');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-3b41dca2-9e36-4c1d-a565-33190db63771\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-3b41dca2-9e36-4c1d-a565-33190db63771')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-3b41dca2-9e36-4c1d-a565-33190db63771 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe"
            }
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- aqui vemos como a mesma quantia gasta se repete diversas vezes"
      ],
      "metadata": {
        "id": "n-98MO9icdlt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df['Amount'].value_counts()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 490
        },
        "id": "7sADPrS3U1x3",
        "outputId": "15732f16-4493-4e0f-c2a4-ec3e82a1b9fa"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Amount\n",
              "1.00       13688\n",
              "1.98        6044\n",
              "0.89        4872\n",
              "9.99        4747\n",
              "15.00       3280\n",
              "           ...  \n",
              "62.09          1\n",
              "552.05         1\n",
              "1467.75        1\n",
              "196.68         1\n",
              "95.63          1\n",
              "Name: count, Length: 32767, dtype: int64"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>count</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Amount</th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1.00</th>\n",
              "      <td>13688</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1.98</th>\n",
              "      <td>6044</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0.89</th>\n",
              "      <td>4872</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9.99</th>\n",
              "      <td>4747</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15.00</th>\n",
              "      <td>3280</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>62.09</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>552.05</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1467.75</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>196.68</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>95.63</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>32767 rows × 1 columns</p>\n",
              "</div><br><label><b>dtype:</b> int64</label>"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Aqui verificamos as quantias gastas presentes em Fraudes"
      ],
      "metadata": {
        "id": "gnpYp9kCgJQw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df['Amount'][df['Class'] == 1].value_counts()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 490
        },
        "id": "Q0-2Hynsf3oo",
        "outputId": "27dc53f3-00ed-4517-b4c9-0d0169e94025"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Amount\n",
              "1.00       113\n",
              "0.00        27\n",
              "99.99       27\n",
              "0.76        17\n",
              "0.77        10\n",
              "          ... \n",
              "294.90       1\n",
              "720.38       1\n",
              "31.91        1\n",
              "1354.25      1\n",
              "42.53        1\n",
              "Name: count, Length: 259, dtype: int64"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>count</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Amount</th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1.00</th>\n",
              "      <td>113</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0.00</th>\n",
              "      <td>27</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>99.99</th>\n",
              "      <td>27</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0.76</th>\n",
              "      <td>17</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0.77</th>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>294.90</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>720.38</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>31.91</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1354.25</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>42.53</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>259 rows × 1 columns</p>\n",
              "</div><br><label><b>dtype:</b> int64</label>"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df['Amount'][df['Class'] == 1].value_counts().head(10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 429
        },
        "id": "PO-GVRP7f-Ju",
        "outputId": "b3817c3c-7b04-40fb-9fe0-10ca4493994b"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Amount\n",
              "1.00     113\n",
              "0.00      27\n",
              "99.99     27\n",
              "0.76      17\n",
              "0.77      10\n",
              "0.01       5\n",
              "2.00       4\n",
              "3.79       4\n",
              "2.28       3\n",
              "12.31      3\n",
              "Name: count, dtype: int64"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>count</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Amount</th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1.00</th>\n",
              "      <td>113</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0.00</th>\n",
              "      <td>27</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>99.99</th>\n",
              "      <td>27</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0.76</th>\n",
              "      <td>17</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0.77</th>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0.01</th>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2.00</th>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3.79</th>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2.28</th>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12.31</th>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div><br><label><b>dtype:</b> int64</label>"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- existe uma disparidade alta entre os valores de Fraude e não Fraude"
      ],
      "metadata": {
        "id": "yE91UZPYclhL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df['Class'].value_counts()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 178
        },
        "id": "MppPvvWMU_Cf",
        "outputId": "c76e20e5-3438-467c-ba51-99aec9fc9ca1"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Class\n",
              "0    284315\n",
              "1       492\n",
              "Name: count, dtype: int64"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>count</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Class</th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>284315</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>492</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div><br><label><b>dtype:</b> int64</label>"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Aqui é possível analisar como o registro do mesmo cliente aparece mais de uma vez"
      ],
      "metadata": {
        "id": "sM6AyO-1crHo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df['Time'].value_counts()[df['Time'].value_counts() > 10]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 490
        },
        "id": "d3umPgYOVUFh",
        "outputId": "8b428674-01fe-4ba0-8d5d-44e69d18049a"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Time\n",
              "163152    36\n",
              "64947     26\n",
              "68780     25\n",
              "3767      21\n",
              "3770      20\n",
              "          ..\n",
              "33534     11\n",
              "127266    11\n",
              "155852    11\n",
              "54329     11\n",
              "3759      11\n",
              "Name: count, Length: 70, dtype: int64"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>count</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Time</th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>163152</th>\n",
              "      <td>36</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>64947</th>\n",
              "      <td>26</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>68780</th>\n",
              "      <td>25</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3767</th>\n",
              "      <td>21</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3770</th>\n",
              "      <td>20</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>33534</th>\n",
              "      <td>11</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>127266</th>\n",
              "      <td>11</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>155852</th>\n",
              "      <td>11</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>54329</th>\n",
              "      <td>11</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3759</th>\n",
              "      <td>11</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>70 rows × 1 columns</p>\n",
              "</div><br><label><b>dtype:</b> int64</label>"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Aqui verificamos a quantidade de vezes que um mesmo registro Fraudou mais de uma vez"
      ],
      "metadata": {
        "id": "5ghfc5MtgcB-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df['Time'][df['Class'] == 1].value_counts()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 490
        },
        "id": "WTV1vdBnbeK_",
        "outputId": "5ac5e09a-f2a9-4770-bc47-c355034f27a7"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Time\n",
              "68207     6\n",
              "93879     4\n",
              "84204     4\n",
              "93853     4\n",
              "93860     4\n",
              "         ..\n",
              "45501     1\n",
              "45463     1\n",
              "44532     1\n",
              "44393     1\n",
              "170348    1\n",
              "Name: count, Length: 468, dtype: int64"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>count</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Time</th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>68207</th>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>93879</th>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>84204</th>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>93853</th>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>93860</th>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>45501</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>45463</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>44532</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>44393</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>170348</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>468 rows × 1 columns</p>\n",
              "</div><br><label><b>dtype:</b> int64</label>"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df['Time'][df['Class'] == 1].value_counts().head(10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 429
        },
        "id": "toPEm5CXeHi_",
        "outputId": "1c2c2223-e8dc-455c-c0d8-cd0ed35a4b0e"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Time\n",
              "68207     6\n",
              "93879     4\n",
              "84204     4\n",
              "93853     4\n",
              "93860     4\n",
              "85285     4\n",
              "94362     4\n",
              "148053    2\n",
              "102542    1\n",
              "102489    1\n",
              "Name: count, dtype: int64"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>count</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Time</th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>68207</th>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>93879</th>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>84204</th>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>93853</th>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>93860</th>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>85285</th>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>94362</th>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>148053</th>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>102542</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>102489</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div><br><label><b>dtype:</b> int64</label>"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Normalização"
      ],
      "metadata": {
        "id": "t6cSLsFA-GcJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def normalize_columns(df, column_name = list):\n",
        "    # Cria uma instância do RobustScaler\n",
        "    scaler = RobustScaler()\n",
        "\n",
        "    # Ajusta o scaler à coluna e transforma os dados\n",
        "    df_normalized = df.copy()\n",
        "    for column in column_name:\n",
        "      df_normalized[column] = scaler.fit_transform(df[[column]])\n",
        "\n",
        "    return df_normalized"
      ],
      "metadata": {
        "id": "Q9Pb9xX9_MHQ"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Seleciona todas as colunas exceto 'Time' e 'Class'\n",
        "columns_to_normalize = df.columns[(df.columns != 'Time') & (df.columns != 'Class')]\n",
        "\n",
        "# Chama a função normalize_columns com as colunas selecionadas\n",
        "normalize_columns(df, columns_to_normalize)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "ljU5luv0_4Mp",
        "outputId": "ac24b957-8834-41d8-cfec-c9213426ea5b"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "          Time        V1        V2        V3        V4        V5        V6  \\\n",
              "0            0 -0.616237 -0.098602  1.228905  0.878152 -0.217859  0.631245   \n",
              "1            0  0.524929  0.143100 -0.006970  0.293974  0.087726  0.164395   \n",
              "2            1 -0.615587 -1.002407  0.830932  0.251024 -0.344345  1.778007   \n",
              "3            1 -0.440239 -0.178789  0.841250 -0.529808  0.033775  1.303832   \n",
              "4            2 -0.526089  0.579239  0.713861  0.265632 -0.270695  0.317183   \n",
              "...        ...       ...       ...       ...       ...       ...       ...   \n",
              "284802  172786 -5.321622  7.135767 -5.222589 -1.285699 -4.073679 -1.999082   \n",
              "284803  172787 -0.335820 -0.085979  0.967471 -0.451476  0.707747  1.142041   \n",
              "284804  172788  0.850377 -0.261532 -1.788463 -0.337932  2.059687  2.832770   \n",
              "284805  172788 -0.115629  0.331602  0.272567  0.445763 -0.248270  0.769496   \n",
              "284806  172792 -0.246654 -0.182004  0.272998 -0.305547  0.032059 -0.321743   \n",
              "\n",
              "              V7         V8        V9  ...       V21       V22       V23  \\\n",
              "0       0.177406   0.142432  0.334787  ...  0.026866  0.253109 -0.320791   \n",
              "1      -0.105740   0.117064 -0.164482  ... -0.473332 -0.602719  0.363442   \n",
              "2       0.668164   0.420388 -1.179796  ...  0.668917  0.714254  2.974603   \n",
              "3       0.175637   0.662489 -1.076888  ... -0.190105 -0.001408 -0.578786   \n",
              "4       0.491625  -0.546463  0.700808  ...  0.048266  0.739092 -0.407980   \n",
              "...          ...        ...       ...  ...       ...       ...       ...   \n",
              "284802 -4.409307  13.588260  1.585066  ...  0.585633  0.098124  3.314091   \n",
              "284803 -0.014027   0.508439  0.512990  ...  0.587444  0.856848  0.076436   \n",
              "284804 -0.299623   1.280019  0.390154  ...  0.630455  0.533612 -0.085005   \n",
              "284805 -0.645865   1.225405  0.357606  ...  0.710499  0.740745 -0.491472   \n",
              "284806  1.366729  -0.815351  0.433472  ...  0.700403  0.594168  1.253585   \n",
              "\n",
              "             V24       V25       V26       V27       V28    Amount  Class  \n",
              "0       0.032681  0.167619 -0.241182  0.816731 -0.246091  1.783274      0  \n",
              "1      -0.479557  0.225462  0.313475 -0.063781  0.026519 -0.269825      0  \n",
              "2      -0.919589 -0.515430 -0.153111 -0.350218 -0.540962  4.983721      0  \n",
              "3      -1.531963  0.944482 -0.298959  0.379163  0.382611  1.418291      0  \n",
              "4       0.126293 -0.333308  0.976221  1.347133  1.553716  0.670579      0  \n",
              "...          ...       ...       ...       ...       ...       ...    ...  \n",
              "284802 -0.693006  2.126512  0.532055  5.820867  6.190862 -0.296653      0  \n",
              "284803 -1.331299 -0.933155 -0.604145  0.414680 -0.493534  0.038986      0  \n",
              "284804  0.754500  0.373060 -0.062034  0.019227 -0.288058  0.641096      0  \n",
              "284805  0.103549 -0.877058  1.054357  0.663921  0.710829 -0.167680      0  \n",
              "284806 -0.040522 -0.734049 -1.348969 -0.023211  0.018326  2.724796      0  \n",
              "\n",
              "[284807 rows x 31 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-eae208b2-8206-4189-afdf-903711dc04fc\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Time</th>\n",
              "      <th>V1</th>\n",
              "      <th>V2</th>\n",
              "      <th>V3</th>\n",
              "      <th>V4</th>\n",
              "      <th>V5</th>\n",
              "      <th>V6</th>\n",
              "      <th>V7</th>\n",
              "      <th>V8</th>\n",
              "      <th>V9</th>\n",
              "      <th>...</th>\n",
              "      <th>V21</th>\n",
              "      <th>V22</th>\n",
              "      <th>V23</th>\n",
              "      <th>V24</th>\n",
              "      <th>V25</th>\n",
              "      <th>V26</th>\n",
              "      <th>V27</th>\n",
              "      <th>V28</th>\n",
              "      <th>Amount</th>\n",
              "      <th>Class</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>-0.616237</td>\n",
              "      <td>-0.098602</td>\n",
              "      <td>1.228905</td>\n",
              "      <td>0.878152</td>\n",
              "      <td>-0.217859</td>\n",
              "      <td>0.631245</td>\n",
              "      <td>0.177406</td>\n",
              "      <td>0.142432</td>\n",
              "      <td>0.334787</td>\n",
              "      <td>...</td>\n",
              "      <td>0.026866</td>\n",
              "      <td>0.253109</td>\n",
              "      <td>-0.320791</td>\n",
              "      <td>0.032681</td>\n",
              "      <td>0.167619</td>\n",
              "      <td>-0.241182</td>\n",
              "      <td>0.816731</td>\n",
              "      <td>-0.246091</td>\n",
              "      <td>1.783274</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>0.524929</td>\n",
              "      <td>0.143100</td>\n",
              "      <td>-0.006970</td>\n",
              "      <td>0.293974</td>\n",
              "      <td>0.087726</td>\n",
              "      <td>0.164395</td>\n",
              "      <td>-0.105740</td>\n",
              "      <td>0.117064</td>\n",
              "      <td>-0.164482</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.473332</td>\n",
              "      <td>-0.602719</td>\n",
              "      <td>0.363442</td>\n",
              "      <td>-0.479557</td>\n",
              "      <td>0.225462</td>\n",
              "      <td>0.313475</td>\n",
              "      <td>-0.063781</td>\n",
              "      <td>0.026519</td>\n",
              "      <td>-0.269825</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>-0.615587</td>\n",
              "      <td>-1.002407</td>\n",
              "      <td>0.830932</td>\n",
              "      <td>0.251024</td>\n",
              "      <td>-0.344345</td>\n",
              "      <td>1.778007</td>\n",
              "      <td>0.668164</td>\n",
              "      <td>0.420388</td>\n",
              "      <td>-1.179796</td>\n",
              "      <td>...</td>\n",
              "      <td>0.668917</td>\n",
              "      <td>0.714254</td>\n",
              "      <td>2.974603</td>\n",
              "      <td>-0.919589</td>\n",
              "      <td>-0.515430</td>\n",
              "      <td>-0.153111</td>\n",
              "      <td>-0.350218</td>\n",
              "      <td>-0.540962</td>\n",
              "      <td>4.983721</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>-0.440239</td>\n",
              "      <td>-0.178789</td>\n",
              "      <td>0.841250</td>\n",
              "      <td>-0.529808</td>\n",
              "      <td>0.033775</td>\n",
              "      <td>1.303832</td>\n",
              "      <td>0.175637</td>\n",
              "      <td>0.662489</td>\n",
              "      <td>-1.076888</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.190105</td>\n",
              "      <td>-0.001408</td>\n",
              "      <td>-0.578786</td>\n",
              "      <td>-1.531963</td>\n",
              "      <td>0.944482</td>\n",
              "      <td>-0.298959</td>\n",
              "      <td>0.379163</td>\n",
              "      <td>0.382611</td>\n",
              "      <td>1.418291</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2</td>\n",
              "      <td>-0.526089</td>\n",
              "      <td>0.579239</td>\n",
              "      <td>0.713861</td>\n",
              "      <td>0.265632</td>\n",
              "      <td>-0.270695</td>\n",
              "      <td>0.317183</td>\n",
              "      <td>0.491625</td>\n",
              "      <td>-0.546463</td>\n",
              "      <td>0.700808</td>\n",
              "      <td>...</td>\n",
              "      <td>0.048266</td>\n",
              "      <td>0.739092</td>\n",
              "      <td>-0.407980</td>\n",
              "      <td>0.126293</td>\n",
              "      <td>-0.333308</td>\n",
              "      <td>0.976221</td>\n",
              "      <td>1.347133</td>\n",
              "      <td>1.553716</td>\n",
              "      <td>0.670579</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>284802</th>\n",
              "      <td>172786</td>\n",
              "      <td>-5.321622</td>\n",
              "      <td>7.135767</td>\n",
              "      <td>-5.222589</td>\n",
              "      <td>-1.285699</td>\n",
              "      <td>-4.073679</td>\n",
              "      <td>-1.999082</td>\n",
              "      <td>-4.409307</td>\n",
              "      <td>13.588260</td>\n",
              "      <td>1.585066</td>\n",
              "      <td>...</td>\n",
              "      <td>0.585633</td>\n",
              "      <td>0.098124</td>\n",
              "      <td>3.314091</td>\n",
              "      <td>-0.693006</td>\n",
              "      <td>2.126512</td>\n",
              "      <td>0.532055</td>\n",
              "      <td>5.820867</td>\n",
              "      <td>6.190862</td>\n",
              "      <td>-0.296653</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>284803</th>\n",
              "      <td>172787</td>\n",
              "      <td>-0.335820</td>\n",
              "      <td>-0.085979</td>\n",
              "      <td>0.967471</td>\n",
              "      <td>-0.451476</td>\n",
              "      <td>0.707747</td>\n",
              "      <td>1.142041</td>\n",
              "      <td>-0.014027</td>\n",
              "      <td>0.508439</td>\n",
              "      <td>0.512990</td>\n",
              "      <td>...</td>\n",
              "      <td>0.587444</td>\n",
              "      <td>0.856848</td>\n",
              "      <td>0.076436</td>\n",
              "      <td>-1.331299</td>\n",
              "      <td>-0.933155</td>\n",
              "      <td>-0.604145</td>\n",
              "      <td>0.414680</td>\n",
              "      <td>-0.493534</td>\n",
              "      <td>0.038986</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>284804</th>\n",
              "      <td>172788</td>\n",
              "      <td>0.850377</td>\n",
              "      <td>-0.261532</td>\n",
              "      <td>-1.788463</td>\n",
              "      <td>-0.337932</td>\n",
              "      <td>2.059687</td>\n",
              "      <td>2.832770</td>\n",
              "      <td>-0.299623</td>\n",
              "      <td>1.280019</td>\n",
              "      <td>0.390154</td>\n",
              "      <td>...</td>\n",
              "      <td>0.630455</td>\n",
              "      <td>0.533612</td>\n",
              "      <td>-0.085005</td>\n",
              "      <td>0.754500</td>\n",
              "      <td>0.373060</td>\n",
              "      <td>-0.062034</td>\n",
              "      <td>0.019227</td>\n",
              "      <td>-0.288058</td>\n",
              "      <td>0.641096</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>284805</th>\n",
              "      <td>172788</td>\n",
              "      <td>-0.115629</td>\n",
              "      <td>0.331602</td>\n",
              "      <td>0.272567</td>\n",
              "      <td>0.445763</td>\n",
              "      <td>-0.248270</td>\n",
              "      <td>0.769496</td>\n",
              "      <td>-0.645865</td>\n",
              "      <td>1.225405</td>\n",
              "      <td>0.357606</td>\n",
              "      <td>...</td>\n",
              "      <td>0.710499</td>\n",
              "      <td>0.740745</td>\n",
              "      <td>-0.491472</td>\n",
              "      <td>0.103549</td>\n",
              "      <td>-0.877058</td>\n",
              "      <td>1.054357</td>\n",
              "      <td>0.663921</td>\n",
              "      <td>0.710829</td>\n",
              "      <td>-0.167680</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>284806</th>\n",
              "      <td>172792</td>\n",
              "      <td>-0.246654</td>\n",
              "      <td>-0.182004</td>\n",
              "      <td>0.272998</td>\n",
              "      <td>-0.305547</td>\n",
              "      <td>0.032059</td>\n",
              "      <td>-0.321743</td>\n",
              "      <td>1.366729</td>\n",
              "      <td>-0.815351</td>\n",
              "      <td>0.433472</td>\n",
              "      <td>...</td>\n",
              "      <td>0.700403</td>\n",
              "      <td>0.594168</td>\n",
              "      <td>1.253585</td>\n",
              "      <td>-0.040522</td>\n",
              "      <td>-0.734049</td>\n",
              "      <td>-1.348969</td>\n",
              "      <td>-0.023211</td>\n",
              "      <td>0.018326</td>\n",
              "      <td>2.724796</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>284807 rows × 31 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-eae208b2-8206-4189-afdf-903711dc04fc')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-eae208b2-8206-4189-afdf-903711dc04fc button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-eae208b2-8206-4189-afdf-903711dc04fc');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-8c2af181-6619-4ffc-a169-69d19bca1ebb\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-8c2af181-6619-4ffc-a169-69d19bca1ebb')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-8c2af181-6619-4ffc-a169-69d19bca1ebb button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe"
            }
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Rede Neural + Hiperparâmetros"
      ],
      "metadata": {
        "id": "PIec_pvmw9U0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Para a aplicação da Rede Neural, foram feitos 3 testes. Sendo eles:\n",
        "1. Sem balanceamento do target;\n",
        "2. Oversample para balanceamento;\n",
        "3. UnderSample para o balanceamento\n",
        "\n",
        "Para construção do modelo, com o otimizados, neuronios e camadas, foi utilizado parecido como aplicado no projeto."
      ],
      "metadata": {
        "id": "5WpMFP5xZ9nd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Para a aplicação de hiperparâmetros, foram feitos testes alterando e utilizando diferentes aspectos e características dos tópicos abaixo:\n",
        "- Número de camadas ocultas: No inicio trabalhei com 5 camadas ocultas, depois permaneci com 3.\n",
        "- Número de neurônios em cada camada: Enquanto eu estava com 5 camadas, trabalhei com 256/128/64/32/16, agora estou somente com 64/32/16.\n",
        "- Taxa de aprendizado: fui fazendo diferentes testes com a taxa de aprendizado\n",
        "- Batch size: foram testados diferentes tamanhos de batch sizes na hora de rodar.\n",
        "- Otimizador: foi testado primeiro o Lion e depois o Adam\n",
        "\n",
        "Os códigos abaixo podem até não apresentar essa variedade de testes, porém, fiz uma estrutura de função e utilização do `RandomizedSearchCV` para aplicar essa variabilidade"
      ],
      "metadata": {
        "id": "OE_zdlneZ5qK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def create_model(x_train, optimizer='adam', learn_rate=0.01):\n",
        "  # Define a arquitetura do modelo (arquitetura em pirâmide)\n",
        "  model = Sequential([\n",
        "    Input(shape=(x_train.shape[1],)),\n",
        "    Dense(64, activation='relu'),\n",
        "    Dense(32, activation='relu'),\n",
        "    Dense(16, activation='relu'),\n",
        "    Dense(1, activation='sigmoid')\n",
        "  ])\n",
        "\n",
        "  if optimizer == 'adam':\n",
        "    optimizer = Adam(learning_rate=learn_rate)\n",
        "  elif optimizer == 'lion':\n",
        "    optimizer = Lion(learning_rate=learn_rate)\n",
        "  else:\n",
        "    print('Otimizador não reconhecido')\n",
        "    return None\n",
        "\n",
        "  model.compile(\n",
        "      optimizer=optimizer,\n",
        "      loss='binary_crossentropy',\n",
        "      metrics=[Accuracy(),\n",
        "                Precision(),\n",
        "                Recall(),\n",
        "                AUC()])\n",
        "\n",
        "  return model"
      ],
      "metadata": {
        "id": "lTDiexvbzVsH"
      },
      "execution_count": 95,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X = df.drop(columns=['Time', 'Class'], axis=1)\n",
        "y = df['Class']"
      ],
      "metadata": {
        "id": "F27SSEsQxOUG"
      },
      "execution_count": 96,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Modelo sem balanceamento"
      ],
      "metadata": {
        "id": "D9P238eM28lK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "fig = px.bar(y.value_counts(), title='Distribuição das Classes')\n",
        "fig.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 542
        },
        "id": "q7fN4n-ayB2o",
        "outputId": "410cfac7-315d-4cac-bd5f-fc86e7e6ca4a"
      },
      "execution_count": 97,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script charset=\"utf-8\" src=\"https://cdn.plot.ly/plotly-2.24.1.min.js\"></script>                <div id=\"e6dcdf65-52a3-4a0c-93d3-0e95b3d80aa8\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"e6dcdf65-52a3-4a0c-93d3-0e95b3d80aa8\")) {                    Plotly.newPlot(                        \"e6dcdf65-52a3-4a0c-93d3-0e95b3d80aa8\",                        [{\"alignmentgroup\":\"True\",\"hovertemplate\":\"variable=count\\u003cbr\\u003eClass=%{x}\\u003cbr\\u003evalue=%{y}\\u003cextra\\u003e\\u003c\\u002fextra\\u003e\",\"legendgroup\":\"count\",\"marker\":{\"color\":\"#636efa\",\"pattern\":{\"shape\":\"\"}},\"name\":\"count\",\"offsetgroup\":\"count\",\"orientation\":\"v\",\"showlegend\":true,\"textposition\":\"auto\",\"x\":[0,1],\"xaxis\":\"x\",\"y\":[284315,492],\"yaxis\":\"y\",\"type\":\"bar\"}],                        {\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmapgl\":[{\"type\":\"heatmapgl\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"type\":\"scattergl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"bgcolor\":\"#E5ECF6\",\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"#E5ECF6\",\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"subunitcolor\":\"white\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"white\"},\"title\":{\"x\":0.05},\"mapbox\":{\"style\":\"light\"}}},\"xaxis\":{\"anchor\":\"y\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"Class\"}},\"yaxis\":{\"anchor\":\"x\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"value\"}},\"legend\":{\"title\":{\"text\":\"variable\"},\"tracegroupgap\":0},\"title\":{\"text\":\"Distribui\\u00e7\\u00e3o das Classes\"},\"barmode\":\"relative\"},                        {\"responsive\": true}                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('e6dcdf65-52a3-4a0c-93d3-0e95b3d80aa8');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })                };                            </script>        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)"
      ],
      "metadata": {
        "id": "fg0c_Z3my9AI"
      },
      "execution_count": 98,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = create_model(X_train)\n",
        "\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 257
        },
        "id": "wCSvBIMZzxeq",
        "outputId": "39824a7e-a84d-40dd-919b-6a4f21992a64"
      },
      "execution_count": 99,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential_48\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_48\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ dense_186 (\u001b[38;5;33mDense\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                  │           \u001b[38;5;34m1,920\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_187 (\u001b[38;5;33mDense\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)                  │           \u001b[38;5;34m2,080\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_188 (\u001b[38;5;33mDense\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m)                  │             \u001b[38;5;34m528\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_189 (\u001b[38;5;33mDense\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)                   │              \u001b[38;5;34m17\u001b[0m │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ dense_186 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                  │           <span style=\"color: #00af00; text-decoration-color: #00af00\">1,920</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_187 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)                  │           <span style=\"color: #00af00; text-decoration-color: #00af00\">2,080</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_188 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)                  │             <span style=\"color: #00af00; text-decoration-color: #00af00\">528</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_189 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)                   │              <span style=\"color: #00af00; text-decoration-color: #00af00\">17</span> │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m4,545\u001b[0m (17.75 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">4,545</span> (17.75 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m4,545\u001b[0m (17.75 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">4,545</span> (17.75 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(X_train,\n",
        "                    y_train.to_numpy(),\n",
        "                    epochs=30,\n",
        "                    batch_size=64,\n",
        "                    verbose=1,\n",
        "                    validation_data=(X_test, y_test))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dsoQnNFB0ZdY",
        "outputId": "f41e6f90-ca22-4a23-9c5d-a66585c6918f"
      },
      "execution_count": 100,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30\n",
            "\u001b[1m3116/3116\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 3ms/step - accuracy: 0.0886 - auc_27: 0.7439 - loss: 0.0310 - precision_27: 0.6368 - recall_27: 0.1751 - val_accuracy: 0.0000e+00 - val_auc_27: 0.8778 - val_loss: 0.0050 - val_precision_27: 0.8252 - val_recall_27: 0.6250\n",
            "Epoch 2/30\n",
            "\u001b[1m3116/3116\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 3ms/step - accuracy: 0.0019 - auc_27: 0.8941 - loss: 0.0074 - precision_27: 0.6402 - recall_27: 0.2773 - val_accuracy: 0.0000e+00 - val_auc_27: 0.8777 - val_loss: 0.0057 - val_precision_27: 0.0000e+00 - val_recall_27: 0.0000e+00\n",
            "Epoch 3/30\n",
            "\u001b[1m3116/3116\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 6ms/step - accuracy: 4.8951e-04 - auc_27: 0.8481 - loss: 0.0067 - precision_27: 0.6565 - recall_27: 0.1953 - val_accuracy: 5.8519e-05 - val_auc_27: 0.8343 - val_loss: 0.0062 - val_precision_27: 0.7596 - val_recall_27: 0.5809\n",
            "Epoch 4/30\n",
            "\u001b[1m3116/3116\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 3ms/step - accuracy: 0.0090 - auc_27: 0.8328 - loss: 0.0110 - precision_27: 0.7502 - recall_27: 0.6548 - val_accuracy: 0.0016 - val_auc_27: 0.8491 - val_loss: 0.0054 - val_precision_27: 0.7787 - val_recall_27: 0.6985\n",
            "Epoch 5/30\n",
            "\u001b[1m3116/3116\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 5ms/step - accuracy: 0.0650 - auc_27: 0.8249 - loss: 0.0218 - precision_27: 0.7914 - recall_27: 0.6421 - val_accuracy: 0.0588 - val_auc_27: 0.8269 - val_loss: 0.0075 - val_precision_27: 0.7664 - val_recall_27: 0.6029\n",
            "Epoch 6/30\n",
            "\u001b[1m3116/3116\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 5ms/step - accuracy: 0.0362 - auc_27: 0.8402 - loss: 0.0108 - precision_27: 0.8119 - recall_27: 0.6586 - val_accuracy: 0.0343 - val_auc_27: 0.8525 - val_loss: 0.0054 - val_precision_27: 0.7385 - val_recall_27: 0.7059\n",
            "Epoch 7/30\n",
            "\u001b[1m3116/3116\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 3ms/step - accuracy: 0.0642 - auc_27: 0.8404 - loss: 0.0044 - precision_27: 0.7551 - recall_27: 0.6885 - val_accuracy: 0.0413 - val_auc_27: 0.8528 - val_loss: 0.0049 - val_precision_27: 0.7805 - val_recall_27: 0.7059\n",
            "Epoch 8/30\n",
            "\u001b[1m3116/3116\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 3ms/step - accuracy: 0.0388 - auc_27: 0.8290 - loss: 0.0051 - precision_27: 0.7887 - recall_27: 0.6574 - val_accuracy: 0.0369 - val_auc_27: 0.8528 - val_loss: 0.0052 - val_precision_27: 0.7805 - val_recall_27: 0.7059\n",
            "Epoch 9/30\n",
            "\u001b[1m3116/3116\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 3ms/step - accuracy: 0.1336 - auc_27: 0.8529 - loss: 0.0291 - precision_27: 0.7076 - recall_27: 0.7047 - val_accuracy: 0.1209 - val_auc_27: 0.7829 - val_loss: 0.0063 - val_precision_27: 0.7600 - val_recall_27: 0.5588\n",
            "Epoch 10/30\n",
            "\u001b[1m3116/3116\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 4ms/step - accuracy: 0.1379 - auc_27: 0.7822 - loss: 0.0161 - precision_27: 0.7975 - recall_27: 0.5649 - val_accuracy: 0.0868 - val_auc_27: 0.8344 - val_loss: 0.0051 - val_precision_27: 0.7692 - val_recall_27: 0.6618\n",
            "Epoch 11/30\n",
            "\u001b[1m3116/3116\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 6ms/step - accuracy: 0.1125 - auc_27: 0.8059 - loss: 0.0090 - precision_27: 0.8138 - recall_27: 0.6151 - val_accuracy: 0.1492 - val_auc_27: 0.8491 - val_loss: 0.0051 - val_precision_27: 0.7787 - val_recall_27: 0.6985\n",
            "Epoch 12/30\n",
            "\u001b[1m3116/3116\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 6ms/step - accuracy: 0.2008 - auc_27: 0.8442 - loss: 0.0066 - precision_27: 0.7532 - recall_27: 0.6875 - val_accuracy: 0.1688 - val_auc_27: 0.8601 - val_loss: 0.0050 - val_precision_27: 0.7778 - val_recall_27: 0.7206\n",
            "Epoch 13/30\n",
            "\u001b[1m3116/3116\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 4ms/step - accuracy: 0.1828 - auc_27: 0.8683 - loss: 0.0052 - precision_27: 0.8754 - recall_27: 0.7376 - val_accuracy: 0.2281 - val_auc_27: 0.8858 - val_loss: 0.0048 - val_precision_27: 0.7609 - val_recall_27: 0.7721\n",
            "Epoch 14/30\n",
            "\u001b[1m3116/3116\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 3ms/step - accuracy: 0.2286 - auc_27: 0.8643 - loss: 0.0048 - precision_27: 0.8355 - recall_27: 0.7320 - val_accuracy: 0.2136 - val_auc_27: 0.8418 - val_loss: 0.0059 - val_precision_27: 0.7750 - val_recall_27: 0.6838\n",
            "Epoch 15/30\n",
            "\u001b[1m3116/3116\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 3ms/step - accuracy: 0.2363 - auc_27: 0.7994 - loss: 0.0096 - precision_27: 0.8367 - recall_27: 0.6016 - val_accuracy: 0.0305 - val_auc_27: 0.8001 - val_loss: 0.0069 - val_precision_27: 0.7685 - val_recall_27: 0.6103\n",
            "Epoch 16/30\n",
            "\u001b[1m3116/3116\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 4ms/step - accuracy: 0.0941 - auc_27: 0.8536 - loss: 0.0067 - precision_27: 0.8578 - recall_27: 0.7009 - val_accuracy: 0.1308 - val_auc_27: 0.8418 - val_loss: 0.0052 - val_precision_27: 0.7750 - val_recall_27: 0.6838\n",
            "Epoch 17/30\n",
            "\u001b[1m3116/3116\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 3ms/step - accuracy: 0.2011 - auc_27: 0.8399 - loss: 0.0240 - precision_27: 0.7008 - recall_27: 0.6443 - val_accuracy: 0.2200 - val_auc_27: 0.8160 - val_loss: 0.0063 - val_precision_27: 0.7658 - val_recall_27: 0.6250\n",
            "Epoch 18/30\n",
            "\u001b[1m3116/3116\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 3ms/step - accuracy: 0.1938 - auc_27: 0.8182 - loss: 0.0136 - precision_27: 0.6829 - recall_27: 0.6419 - val_accuracy: 0.2017 - val_auc_27: 0.8087 - val_loss: 0.0065 - val_precision_27: 0.7636 - val_recall_27: 0.6176\n",
            "Epoch 19/30\n",
            "\u001b[1m3116/3116\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 2ms/step - accuracy: 0.1902 - auc_27: 0.8002 - loss: 0.0072 - precision_27: 0.8685 - recall_27: 0.6112 - val_accuracy: 0.2056 - val_auc_27: 0.7682 - val_loss: 0.0074 - val_precision_27: 0.7526 - val_recall_27: 0.5368\n",
            "Epoch 20/30\n",
            "\u001b[1m3116/3116\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 3ms/step - accuracy: 0.2943 - auc_27: 0.7879 - loss: 0.0138 - precision_27: 0.8085 - recall_27: 0.5340 - val_accuracy: 0.2061 - val_auc_27: 0.7683 - val_loss: 0.0070 - val_precision_27: 0.0000e+00 - val_recall_27: 0.0000e+00\n",
            "Epoch 21/30\n",
            "\u001b[1m3116/3116\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 4ms/step - accuracy: 0.2103 - auc_27: 0.7997 - loss: 0.0065 - precision_27: 0.7000 - recall_27: 0.3208 - val_accuracy: 0.2321 - val_auc_27: 0.8381 - val_loss: 0.0058 - val_precision_27: 0.7731 - val_recall_27: 0.6765\n",
            "Epoch 22/30\n",
            "\u001b[1m3116/3116\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 3ms/step - accuracy: 0.2466 - auc_27: 0.8205 - loss: 0.0055 - precision_27: 0.8477 - recall_27: 0.6441 - val_accuracy: 0.1430 - val_auc_27: 0.8344 - val_loss: 0.0053 - val_precision_27: 0.7712 - val_recall_27: 0.6691\n",
            "Epoch 23/30\n",
            "\u001b[1m3116/3116\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 3ms/step - accuracy: 0.1293 - auc_27: 0.8339 - loss: 0.0057 - precision_27: 0.8466 - recall_27: 0.6733 - val_accuracy: 0.1474 - val_auc_27: 0.8344 - val_loss: 0.0063 - val_precision_27: 0.7712 - val_recall_27: 0.6691\n",
            "Epoch 24/30\n",
            "\u001b[1m3116/3116\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 4ms/step - accuracy: 0.3183 - auc_27: 0.8375 - loss: 0.0265 - precision_27: 0.6494 - recall_27: 0.6277 - val_accuracy: 0.1848 - val_auc_27: 0.8292 - val_loss: 0.0059 - val_precision_27: 0.7692 - val_recall_27: 0.6618\n",
            "Epoch 25/30\n",
            "\u001b[1m3116/3116\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 3ms/step - accuracy: 0.2109 - auc_27: 0.8349 - loss: 0.0054 - precision_27: 0.8269 - recall_27: 0.6723 - val_accuracy: 0.2472 - val_auc_27: 0.8307 - val_loss: 0.0058 - val_precision_27: 0.7692 - val_recall_27: 0.6618\n",
            "Epoch 26/30\n",
            "\u001b[1m3116/3116\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 3ms/step - accuracy: 0.2549 - auc_27: 0.8426 - loss: 0.0052 - precision_27: 0.8214 - recall_27: 0.6856 - val_accuracy: 0.2238 - val_auc_27: 0.8159 - val_loss: 0.0074 - val_precision_27: 0.7679 - val_recall_27: 0.6324\n",
            "Epoch 27/30\n",
            "\u001b[1m3116/3116\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 3ms/step - accuracy: 0.2480 - auc_27: 0.8113 - loss: 0.0064 - precision_27: 0.8088 - recall_27: 0.6236 - val_accuracy: 0.7913 - val_auc_27: 0.8381 - val_loss: 0.3597 - val_precision_27: 0.7731 - val_recall_27: 0.6765\n",
            "Epoch 28/30\n",
            "\u001b[1m3116/3116\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 4ms/step - accuracy: 0.3222 - auc_27: 0.8390 - loss: 0.0109 - precision_27: 0.8245 - recall_27: 0.6760 - val_accuracy: 0.2768 - val_auc_27: 0.8307 - val_loss: 0.0061 - val_precision_27: 0.7692 - val_recall_27: 0.6618\n",
            "Epoch 29/30\n",
            "\u001b[1m3116/3116\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 3ms/step - accuracy: 0.3610 - auc_27: 0.8131 - loss: 0.0139 - precision_27: 0.6918 - recall_27: 0.6233 - val_accuracy: 0.0412 - val_auc_27: 0.8050 - val_loss: 0.0061 - val_precision_27: 0.7685 - val_recall_27: 0.6103\n",
            "Epoch 30/30\n",
            "\u001b[1m3116/3116\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 3ms/step - accuracy: 0.0528 - auc_27: 0.8007 - loss: 0.0250 - precision_27: 0.7726 - recall_27: 0.5195 - val_accuracy: 0.1284 - val_auc_27: 0.8160 - val_loss: 0.0063 - val_precision_27: 0.7679 - val_recall_27: 0.6324\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "loss, accuracy, f1_score, precision, recall = model.evaluate(X_test, y_test)\n",
        "print(f'Loss: {loss}, Accuracy: {accuracy}, F1-Score: {f1_score}, Precision: {precision}, Recall: {recall}, AUC: {roc_auc_score(y_test, model.predict(X_test))}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2I2xJor21lyi",
        "outputId": "e4864873-8211-4b9b-e3bf-a51921099270"
      },
      "execution_count": 101,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m2671/2671\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 1ms/step - accuracy: 0.1269 - auc_27: 0.7622 - loss: 0.0075 - precision_27: 0.7315 - recall_27: 0.5248\n",
            "\u001b[1m2671/2671\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step\n",
            "Loss: 0.006330190692096949, Accuracy: 0.12836627662181854, F1-Score: 0.7678571343421936, Precision: 0.6323529481887817, Recall: 0.8160154819488525, AUC: 0.8665349854056527\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Construção do Modelo - OverSampler"
      ],
      "metadata": {
        "id": "XaXMF9Klwbh0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "smote = SMOTE(random_state=42)\n",
        "X_resampled_s, y_resampled_s = smote.fit_resample(X, y)"
      ],
      "metadata": {
        "id": "ObU9wMVrwiCy"
      },
      "execution_count": 102,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fig = px.bar(y_resampled_s.value_counts(), title='Distribuição das Classes - OverSampler')\n",
        "fig.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 542
        },
        "id": "RX1gRRpLybzH",
        "outputId": "94558f89-f013-4177-e101-174d1887ccf2"
      },
      "execution_count": 103,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script charset=\"utf-8\" src=\"https://cdn.plot.ly/plotly-2.24.1.min.js\"></script>                <div id=\"c5411e8a-c03d-4854-a47a-8bb1141accad\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"c5411e8a-c03d-4854-a47a-8bb1141accad\")) {                    Plotly.newPlot(                        \"c5411e8a-c03d-4854-a47a-8bb1141accad\",                        [{\"alignmentgroup\":\"True\",\"hovertemplate\":\"variable=count\\u003cbr\\u003eClass=%{x}\\u003cbr\\u003evalue=%{y}\\u003cextra\\u003e\\u003c\\u002fextra\\u003e\",\"legendgroup\":\"count\",\"marker\":{\"color\":\"#636efa\",\"pattern\":{\"shape\":\"\"}},\"name\":\"count\",\"offsetgroup\":\"count\",\"orientation\":\"v\",\"showlegend\":true,\"textposition\":\"auto\",\"x\":[0,1],\"xaxis\":\"x\",\"y\":[284315,284315],\"yaxis\":\"y\",\"type\":\"bar\"}],                        {\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmapgl\":[{\"type\":\"heatmapgl\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"type\":\"scattergl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"bgcolor\":\"#E5ECF6\",\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"#E5ECF6\",\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"subunitcolor\":\"white\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"white\"},\"title\":{\"x\":0.05},\"mapbox\":{\"style\":\"light\"}}},\"xaxis\":{\"anchor\":\"y\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"Class\"}},\"yaxis\":{\"anchor\":\"x\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"value\"}},\"legend\":{\"title\":{\"text\":\"variable\"},\"tracegroupgap\":0},\"title\":{\"text\":\"Distribui\\u00e7\\u00e3o das Classes - OverSampler\"},\"barmode\":\"relative\"},                        {\"responsive\": true}                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('c5411e8a-c03d-4854-a47a-8bb1141accad');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })                };                            </script>        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train_s, X_test_s, y_train_s, y_test_s = train_test_split(X_resampled_s, y_resampled_s, test_size=0.3, random_state=42)"
      ],
      "metadata": {
        "id": "ChNDUwKey8fQ"
      },
      "execution_count": 104,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = create_model(X_train_s)\n",
        "\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 257
        },
        "id": "twZZzlPJzWSH",
        "outputId": "0aca4710-d451-449b-e617-6985bd422b87"
      },
      "execution_count": 105,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential_49\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_49\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ dense_190 (\u001b[38;5;33mDense\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                  │           \u001b[38;5;34m1,920\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_191 (\u001b[38;5;33mDense\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)                  │           \u001b[38;5;34m2,080\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_192 (\u001b[38;5;33mDense\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m)                  │             \u001b[38;5;34m528\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_193 (\u001b[38;5;33mDense\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)                   │              \u001b[38;5;34m17\u001b[0m │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ dense_190 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                  │           <span style=\"color: #00af00; text-decoration-color: #00af00\">1,920</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_191 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)                  │           <span style=\"color: #00af00; text-decoration-color: #00af00\">2,080</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_192 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)                  │             <span style=\"color: #00af00; text-decoration-color: #00af00\">528</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_193 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)                   │              <span style=\"color: #00af00; text-decoration-color: #00af00\">17</span> │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m4,545\u001b[0m (17.75 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">4,545</span> (17.75 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m4,545\u001b[0m (17.75 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">4,545</span> (17.75 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(X_train_s,\n",
        "                    y_train_s.to_numpy(),\n",
        "                    epochs=30,\n",
        "                    batch_size=50,\n",
        "                    verbose=1,\n",
        "                    validation_data=(X_test_s, y_test_s))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wZzX0zIm3Eea",
        "outputId": "18c8dc73-c032-44b4-8c24-ed5d778ad89d"
      },
      "execution_count": 106,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30\n",
            "\u001b[1m7961/7961\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 3ms/step - accuracy: 0.2123 - auc_28: 0.9914 - loss: 0.1121 - precision_28: 0.9761 - recall_28: 0.9638 - val_accuracy: 0.3921 - val_auc_28: 0.9982 - val_loss: 0.0511 - val_precision_28: 0.9803 - val_recall_28: 0.9966\n",
            "Epoch 2/30\n",
            "\u001b[1m7961/7961\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 3ms/step - accuracy: 0.2901 - auc_28: 0.9971 - loss: 0.0599 - precision_28: 0.9922 - recall_28: 0.9685 - val_accuracy: 0.4813 - val_auc_28: 0.9965 - val_loss: 0.0585 - val_precision_28: 0.9980 - val_recall_28: 0.9635\n",
            "Epoch 3/30\n",
            "\u001b[1m7961/7961\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 4ms/step - accuracy: 0.5308 - auc_28: 0.9976 - loss: 0.0502 - precision_28: 0.9953 - recall_28: 0.9746 - val_accuracy: 0.4220 - val_auc_28: 0.9989 - val_loss: 0.0300 - val_precision_28: 0.9978 - val_recall_28: 0.9836\n",
            "Epoch 4/30\n",
            "\u001b[1m7961/7961\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 3ms/step - accuracy: 0.6222 - auc_28: 0.9906 - loss: 0.1358 - precision_28: 0.9741 - recall_28: 0.9246 - val_accuracy: 0.6831 - val_auc_28: 0.9916 - val_loss: 0.1067 - val_precision_28: 0.9978 - val_recall_28: 0.9128\n",
            "Epoch 5/30\n",
            "\u001b[1m7961/7961\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 3ms/step - accuracy: 0.7465 - auc_28: 0.9941 - loss: 0.0937 - precision_28: 0.9982 - recall_28: 0.9439 - val_accuracy: 0.5990 - val_auc_28: 0.9988 - val_loss: 0.0287 - val_precision_28: 0.9967 - val_recall_28: 0.9904\n",
            "Epoch 6/30\n",
            "\u001b[1m7961/7961\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 4ms/step - accuracy: 0.7154 - auc_28: 0.9957 - loss: 0.0831 - precision_28: 0.9936 - recall_28: 0.9512 - val_accuracy: 0.7681 - val_auc_28: 0.9928 - val_loss: 0.1438 - val_precision_28: 0.9969 - val_recall_28: 0.9680\n",
            "Epoch 7/30\n",
            "\u001b[1m7961/7961\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 3ms/step - accuracy: 0.7414 - auc_28: 0.9941 - loss: 0.1009 - precision_28: 0.9974 - recall_28: 0.9567 - val_accuracy: 0.8270 - val_auc_28: 0.9965 - val_loss: 0.0593 - val_precision_28: 0.9985 - val_recall_28: 0.9776\n",
            "Epoch 8/30\n",
            "\u001b[1m7961/7961\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 3ms/step - accuracy: 0.7267 - auc_28: 0.9967 - loss: 0.0609 - precision_28: 0.9970 - recall_28: 0.9726 - val_accuracy: 0.6940 - val_auc_28: 0.9978 - val_loss: 0.0418 - val_precision_28: 0.9877 - val_recall_28: 0.9971\n",
            "Epoch 9/30\n",
            "\u001b[1m7961/7961\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 3ms/step - accuracy: 0.7404 - auc_28: 0.9962 - loss: 0.0736 - precision_28: 0.9975 - recall_28: 0.9634 - val_accuracy: 0.7832 - val_auc_28: 0.9875 - val_loss: 0.1180 - val_precision_28: 0.9988 - val_recall_28: 0.9274\n",
            "Epoch 10/30\n",
            "\u001b[1m7961/7961\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 3ms/step - accuracy: 0.7793 - auc_28: 0.9937 - loss: 0.0968 - precision_28: 0.9987 - recall_28: 0.9470 - val_accuracy: 0.7294 - val_auc_28: 0.9930 - val_loss: 0.0762 - val_precision_28: 0.9988 - val_recall_28: 0.9464\n",
            "Epoch 11/30\n",
            "\u001b[1m7961/7961\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 3ms/step - accuracy: 0.7517 - auc_28: 0.9948 - loss: 0.0871 - precision_28: 0.9875 - recall_28: 0.9500 - val_accuracy: 0.7447 - val_auc_28: 0.9957 - val_loss: 0.0545 - val_precision_28: 0.9990 - val_recall_28: 0.9737\n",
            "Epoch 12/30\n",
            "\u001b[1m7961/7961\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 4ms/step - accuracy: 0.8024 - auc_28: 0.9889 - loss: 0.1376 - precision_28: 0.9926 - recall_28: 0.9028 - val_accuracy: 0.7034 - val_auc_28: 0.9678 - val_loss: 0.1920 - val_precision_28: 0.9992 - val_recall_28: 0.7934\n",
            "Epoch 13/30\n",
            "\u001b[1m7961/7961\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 3ms/step - accuracy: 0.7852 - auc_28: 0.9889 - loss: 0.1645 - precision_28: 0.9863 - recall_28: 0.8973 - val_accuracy: 0.8203 - val_auc_28: 0.9898 - val_loss: 0.1031 - val_precision_28: 0.9993 - val_recall_28: 0.9235\n",
            "Epoch 14/30\n",
            "\u001b[1m7961/7961\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 3ms/step - accuracy: 0.8177 - auc_28: 0.9941 - loss: 0.0957 - precision_28: 0.9990 - recall_28: 0.9427 - val_accuracy: 0.7830 - val_auc_28: 0.9932 - val_loss: 0.0799 - val_precision_28: 0.9992 - val_recall_28: 0.9335\n",
            "Epoch 15/30\n",
            "\u001b[1m7961/7961\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 3ms/step - accuracy: 0.7961 - auc_28: 0.9928 - loss: 0.1104 - precision_28: 0.9993 - recall_28: 0.9324 - val_accuracy: 0.5546 - val_auc_28: 0.9124 - val_loss: 0.3159 - val_precision_28: 0.7542 - val_recall_28: 0.9997\n",
            "Epoch 16/30\n",
            "\u001b[1m7961/7961\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 3ms/step - accuracy: 0.7313 - auc_28: 0.9723 - loss: 0.1905 - precision_28: 0.9291 - recall_28: 0.8575 - val_accuracy: 0.8503 - val_auc_28: 0.9922 - val_loss: 0.0943 - val_precision_28: 0.9991 - val_recall_28: 0.9327\n",
            "Epoch 17/30\n",
            "\u001b[1m7961/7961\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 3ms/step - accuracy: 0.8093 - auc_28: 0.9945 - loss: 0.1259 - precision_28: 0.9942 - recall_28: 0.9450 - val_accuracy: 0.8540 - val_auc_28: 0.9903 - val_loss: 0.1058 - val_precision_28: 0.9993 - val_recall_28: 0.8852\n",
            "Epoch 18/30\n",
            "\u001b[1m7961/7961\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 3ms/step - accuracy: 0.7802 - auc_28: 0.9921 - loss: 0.1106 - precision_28: 0.9993 - recall_28: 0.9218 - val_accuracy: 0.7392 - val_auc_28: 0.9748 - val_loss: 0.1548 - val_precision_28: 0.9996 - val_recall_28: 0.8580\n",
            "Epoch 19/30\n",
            "\u001b[1m7961/7961\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 3ms/step - accuracy: 0.7666 - auc_28: 0.9872 - loss: 0.1404 - precision_28: 0.9994 - recall_28: 0.8989 - val_accuracy: 0.7063 - val_auc_28: 0.9938 - val_loss: 0.0653 - val_precision_28: 0.9994 - val_recall_28: 0.9661\n",
            "Epoch 20/30\n",
            "\u001b[1m7961/7961\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 3ms/step - accuracy: 0.7436 - auc_28: 0.9913 - loss: 0.1186 - precision_28: 0.9992 - recall_28: 0.9307 - val_accuracy: 0.7768 - val_auc_28: 0.9815 - val_loss: 0.1456 - val_precision_28: 0.9991 - val_recall_28: 0.8885\n",
            "Epoch 21/30\n",
            "\u001b[1m7961/7961\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 3ms/step - accuracy: 0.7674 - auc_28: 0.9858 - loss: 0.1712 - precision_28: 0.9905 - recall_28: 0.9021 - val_accuracy: 0.6495 - val_auc_28: 0.9871 - val_loss: 0.1009 - val_precision_28: 0.9992 - val_recall_28: 0.9322\n",
            "Epoch 22/30\n",
            "\u001b[1m7961/7961\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 3ms/step - accuracy: 0.7276 - auc_28: 0.9877 - loss: 0.1412 - precision_28: 0.9987 - recall_28: 0.9050 - val_accuracy: 0.6441 - val_auc_28: 0.9954 - val_loss: 0.0613 - val_precision_28: 0.9986 - val_recall_28: 0.9692\n",
            "Epoch 23/30\n",
            "\u001b[1m7961/7961\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 3ms/step - accuracy: 0.7742 - auc_28: 0.9905 - loss: 0.1459 - precision_28: 0.9694 - recall_28: 0.9353 - val_accuracy: 0.7878 - val_auc_28: 0.9891 - val_loss: 0.1200 - val_precision_28: 0.9993 - val_recall_28: 0.9325\n",
            "Epoch 24/30\n",
            "\u001b[1m7961/7961\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 3ms/step - accuracy: 0.7721 - auc_28: 0.9867 - loss: 0.1787 - precision_28: 0.9995 - recall_28: 0.8836 - val_accuracy: 0.8602 - val_auc_28: 0.9940 - val_loss: 0.0808 - val_precision_28: 0.9997 - val_recall_28: 0.9082\n",
            "Epoch 25/30\n",
            "\u001b[1m7961/7961\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 3ms/step - accuracy: 0.8139 - auc_28: 0.9915 - loss: 0.1279 - precision_28: 0.9943 - recall_28: 0.9156 - val_accuracy: 0.5756 - val_auc_28: 0.9787 - val_loss: 0.1366 - val_precision_28: 0.9995 - val_recall_28: 0.8869\n",
            "Epoch 26/30\n",
            "\u001b[1m7961/7961\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 3ms/step - accuracy: 0.7523 - auc_28: 0.9877 - loss: 0.1351 - precision_28: 0.9981 - recall_28: 0.9028 - val_accuracy: 0.7502 - val_auc_28: 0.9813 - val_loss: 0.1456 - val_precision_28: 0.9995 - val_recall_28: 0.8975\n",
            "Epoch 27/30\n",
            "\u001b[1m7961/7961\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 4ms/step - accuracy: 0.7692 - auc_28: 0.9879 - loss: 0.1244 - precision_28: 0.9997 - recall_28: 0.9133 - val_accuracy: 0.8267 - val_auc_28: 0.9892 - val_loss: 0.1653 - val_precision_28: 0.9998 - val_recall_28: 0.9065\n",
            "Epoch 28/30\n",
            "\u001b[1m7961/7961\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 3ms/step - accuracy: 0.7847 - auc_28: 0.9853 - loss: 0.1643 - precision_28: 0.9975 - recall_28: 0.8896 - val_accuracy: 0.8275 - val_auc_28: 0.9909 - val_loss: 0.1296 - val_precision_28: 0.9996 - val_recall_28: 0.9357\n",
            "Epoch 29/30\n",
            "\u001b[1m7961/7961\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 3ms/step - accuracy: 0.7691 - auc_28: 0.9851 - loss: 0.1566 - precision_28: 0.9996 - recall_28: 0.8917 - val_accuracy: 0.7462 - val_auc_28: 0.9808 - val_loss: 0.1333 - val_precision_28: 0.9993 - val_recall_28: 0.8930\n",
            "Epoch 30/30\n",
            "\u001b[1m7961/7961\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 3ms/step - accuracy: 0.7422 - auc_28: 0.9818 - loss: 0.5729 - precision_28: 0.9863 - recall_28: 0.8823 - val_accuracy: 0.7837 - val_auc_28: 0.9817 - val_loss: 0.1479 - val_precision_28: 0.9997 - val_recall_28: 0.8763\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "loss, accuracy, f1_score, precision, recall = model.evaluate(X_test_s, y_test_s)\n",
        "print(f'Loss: {loss}, Accuracy: {accuracy}, F1-Score: {f1_score}, Precision: {precision}, Recall: {recall}, AUC: {roc_auc_score(y_test, model.predict(X_test))}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IRKwPBuB3I0k",
        "outputId": "7a177322-1e9c-4fcb-a71a-b7dea83aed5b"
      },
      "execution_count": 107,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m5331/5331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 2ms/step - accuracy: 0.7824 - auc_28: 0.9816 - loss: 0.1481 - precision_28: 0.9997 - recall_28: 0.8772\n",
            "\u001b[1m2671/2671\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step\n",
            "Loss: 0.14785389602184296, Accuracy: 0.7836964726448059, F1-Score: 0.9996528625488281, Precision: 0.8763108849525452, Recall: 0.9816616773605347, AUC: 0.9793549284625287\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Construção do Modelo - UnderSampler"
      ],
      "metadata": {
        "id": "RYOY0SlJwxDT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "rus = RandomUnderSampler(random_state=42)\n",
        "X_resampled_r, y_resampled_r = rus.fit_resample(X, y)"
      ],
      "metadata": {
        "id": "RU5abNFZwz7j"
      },
      "execution_count": 108,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fig = px.bar(y_resampled_r.value_counts(), title='Distribuição das Classes - UnderSampler')\n",
        "fig.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 542
        },
        "id": "vpcDwzM9x0tv",
        "outputId": "7f09e80f-a931-4107-9a3e-e2bd388f3037"
      },
      "execution_count": 109,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script charset=\"utf-8\" src=\"https://cdn.plot.ly/plotly-2.24.1.min.js\"></script>                <div id=\"5f75e2a1-8414-435f-be87-388f420c3fdd\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"5f75e2a1-8414-435f-be87-388f420c3fdd\")) {                    Plotly.newPlot(                        \"5f75e2a1-8414-435f-be87-388f420c3fdd\",                        [{\"alignmentgroup\":\"True\",\"hovertemplate\":\"variable=count\\u003cbr\\u003eClass=%{x}\\u003cbr\\u003evalue=%{y}\\u003cextra\\u003e\\u003c\\u002fextra\\u003e\",\"legendgroup\":\"count\",\"marker\":{\"color\":\"#636efa\",\"pattern\":{\"shape\":\"\"}},\"name\":\"count\",\"offsetgroup\":\"count\",\"orientation\":\"v\",\"showlegend\":true,\"textposition\":\"auto\",\"x\":[0,1],\"xaxis\":\"x\",\"y\":[492,492],\"yaxis\":\"y\",\"type\":\"bar\"}],                        {\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmapgl\":[{\"type\":\"heatmapgl\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"type\":\"scattergl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"bgcolor\":\"#E5ECF6\",\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"#E5ECF6\",\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"subunitcolor\":\"white\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"white\"},\"title\":{\"x\":0.05},\"mapbox\":{\"style\":\"light\"}}},\"xaxis\":{\"anchor\":\"y\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"Class\"}},\"yaxis\":{\"anchor\":\"x\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"value\"}},\"legend\":{\"title\":{\"text\":\"variable\"},\"tracegroupgap\":0},\"title\":{\"text\":\"Distribui\\u00e7\\u00e3o das Classes - UnderSampler\"},\"barmode\":\"relative\"},                        {\"responsive\": true}                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('5f75e2a1-8414-435f-be87-388f420c3fdd');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })                };                            </script>        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train_r, X_test_r, y_train_r, y_test_r = train_test_split(X_resampled_r, y_resampled_r, test_size=0.3, random_state=42)"
      ],
      "metadata": {
        "id": "rZvnvS-8yrhr"
      },
      "execution_count": 110,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = create_model(X_train_r)\n",
        "\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 257
        },
        "id": "7LcCN4ApzXRA",
        "outputId": "e7ccc1de-e6c0-40c7-c8ab-bd305045e45b"
      },
      "execution_count": 111,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential_50\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_50\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ dense_194 (\u001b[38;5;33mDense\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                  │           \u001b[38;5;34m1,920\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_195 (\u001b[38;5;33mDense\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)                  │           \u001b[38;5;34m2,080\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_196 (\u001b[38;5;33mDense\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m)                  │             \u001b[38;5;34m528\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_197 (\u001b[38;5;33mDense\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)                   │              \u001b[38;5;34m17\u001b[0m │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ dense_194 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                  │           <span style=\"color: #00af00; text-decoration-color: #00af00\">1,920</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_195 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)                  │           <span style=\"color: #00af00; text-decoration-color: #00af00\">2,080</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_196 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)                  │             <span style=\"color: #00af00; text-decoration-color: #00af00\">528</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_197 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)                   │              <span style=\"color: #00af00; text-decoration-color: #00af00\">17</span> │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m4,545\u001b[0m (17.75 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">4,545</span> (17.75 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m4,545\u001b[0m (17.75 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">4,545</span> (17.75 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(X_train_r,\n",
        "                    y_train_r.to_numpy(),\n",
        "                    epochs=30,\n",
        "                    batch_size=50,\n",
        "                    verbose=1,\n",
        "                    validation_data=(X_test_r, y_test_r))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IRyRied95ClV",
        "outputId": "09d37364-858f-453a-d412-a1e0e42c3b1b"
      },
      "execution_count": 112,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 42ms/step - accuracy: 0.0738 - auc_29: 0.6538 - loss: 2.5038 - precision_29: 0.6013 - recall_29: 0.7538 - val_accuracy: 0.1047 - val_auc_29: 0.8957 - val_loss: 0.5847 - val_precision_29: 0.8803 - val_recall_29: 0.8562\n",
            "Epoch 2/30\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.1173 - auc_29: 0.9393 - loss: 0.4602 - precision_29: 0.8625 - recall_29: 0.9109 - val_accuracy: 0.1318 - val_auc_29: 0.8337 - val_loss: 1.7268 - val_precision_29: 0.9576 - val_recall_29: 0.7740\n",
            "Epoch 3/30\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.2190 - auc_29: 0.9066 - loss: 0.9772 - precision_29: 0.8968 - recall_29: 0.8780 - val_accuracy: 0.3041 - val_auc_29: 0.9544 - val_loss: 0.5977 - val_precision_29: 0.7853 - val_recall_29: 0.9521\n",
            "Epoch 4/30\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.2502 - auc_29: 0.9396 - loss: 0.5082 - precision_29: 0.8848 - recall_29: 0.9226 - val_accuracy: 0.2838 - val_auc_29: 0.9621 - val_loss: 0.2805 - val_precision_29: 0.8968 - val_recall_29: 0.9521\n",
            "Epoch 5/30\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.2842 - auc_29: 0.9707 - loss: 0.2063 - precision_29: 0.9599 - recall_29: 0.9253 - val_accuracy: 0.2838 - val_auc_29: 0.9257 - val_loss: 0.4400 - val_precision_29: 0.9416 - val_recall_29: 0.8836\n",
            "Epoch 6/30\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.2763 - auc_29: 0.9756 - loss: 0.1937 - precision_29: 0.9683 - recall_29: 0.9329 - val_accuracy: 0.3412 - val_auc_29: 0.9544 - val_loss: 0.4407 - val_precision_29: 0.8485 - val_recall_29: 0.9589\n",
            "Epoch 7/30\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.3341 - auc_29: 0.9777 - loss: 0.2550 - precision_29: 0.9311 - recall_29: 0.9403 - val_accuracy: 0.3142 - val_auc_29: 0.9299 - val_loss: 0.5222 - val_precision_29: 0.9485 - val_recall_29: 0.8836\n",
            "Epoch 8/30\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.3422 - auc_29: 0.9821 - loss: 0.1641 - precision_29: 0.9720 - recall_29: 0.9462 - val_accuracy: 0.3716 - val_auc_29: 0.9470 - val_loss: 0.7763 - val_precision_29: 0.8176 - val_recall_29: 0.9521\n",
            "Epoch 9/30\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.3350 - auc_29: 0.9453 - loss: 0.5831 - precision_29: 0.8625 - recall_29: 0.9417 - val_accuracy: 0.3142 - val_auc_29: 0.9310 - val_loss: 0.5266 - val_precision_29: 0.9420 - val_recall_29: 0.8904\n",
            "Epoch 10/30\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.3355 - auc_29: 0.9762 - loss: 0.1937 - precision_29: 0.9742 - recall_29: 0.9304 - val_accuracy: 0.3108 - val_auc_29: 0.9378 - val_loss: 0.4668 - val_precision_29: 0.9485 - val_recall_29: 0.8836\n",
            "Epoch 11/30\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.3295 - auc_29: 0.9850 - loss: 0.1168 - precision_29: 0.9777 - recall_29: 0.9484 - val_accuracy: 0.3108 - val_auc_29: 0.9175 - val_loss: 1.0593 - val_precision_29: 0.9615 - val_recall_29: 0.8562\n",
            "Epoch 12/30\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.3855 - auc_29: 0.9657 - loss: 0.3149 - precision_29: 0.9895 - recall_29: 0.9266 - val_accuracy: 0.3277 - val_auc_29: 0.9375 - val_loss: 0.5510 - val_precision_29: 0.9627 - val_recall_29: 0.8836\n",
            "Epoch 13/30\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.3762 - auc_29: 0.9869 - loss: 0.1451 - precision_29: 0.9831 - recall_29: 0.9479 - val_accuracy: 0.3581 - val_auc_29: 0.9360 - val_loss: 0.5390 - val_precision_29: 0.9552 - val_recall_29: 0.8767\n",
            "Epoch 14/30\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.4047 - auc_29: 0.9949 - loss: 0.0695 - precision_29: 0.9770 - recall_29: 0.9651 - val_accuracy: 0.3480 - val_auc_29: 0.9380 - val_loss: 0.5524 - val_precision_29: 0.9697 - val_recall_29: 0.8767\n",
            "Epoch 15/30\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.3991 - auc_29: 0.9960 - loss: 0.0771 - precision_29: 0.9925 - recall_29: 0.9432 - val_accuracy: 0.3784 - val_auc_29: 0.9441 - val_loss: 0.4825 - val_precision_29: 0.9771 - val_recall_29: 0.8767\n",
            "Epoch 16/30\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.4099 - auc_29: 0.9968 - loss: 0.0710 - precision_29: 0.9908 - recall_29: 0.9559 - val_accuracy: 0.4054 - val_auc_29: 0.9620 - val_loss: 0.4412 - val_precision_29: 0.9139 - val_recall_29: 0.9452\n",
            "Epoch 17/30\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.3859 - auc_29: 0.9896 - loss: 0.1299 - precision_29: 0.9662 - recall_29: 0.9682 - val_accuracy: 0.3615 - val_auc_29: 0.9491 - val_loss: 0.4575 - val_precision_29: 0.9699 - val_recall_29: 0.8836\n",
            "Epoch 18/30\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.3878 - auc_29: 0.9915 - loss: 0.1188 - precision_29: 0.9926 - recall_29: 0.9460 - val_accuracy: 0.4054 - val_auc_29: 0.9541 - val_loss: 0.4624 - val_precision_29: 0.8854 - val_recall_29: 0.9521\n",
            "Epoch 19/30\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.4349 - auc_29: 0.9730 - loss: 0.2772 - precision_29: 0.9430 - recall_29: 0.9509 - val_accuracy: 0.3919 - val_auc_29: 0.9443 - val_loss: 0.5474 - val_precision_29: 0.9225 - val_recall_29: 0.8973\n",
            "Epoch 20/30\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.4257 - auc_29: 0.9887 - loss: 0.1133 - precision_29: 0.9889 - recall_29: 0.9434 - val_accuracy: 0.4054 - val_auc_29: 0.9478 - val_loss: 0.4559 - val_precision_29: 0.9296 - val_recall_29: 0.9041\n",
            "Epoch 21/30\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.4366 - auc_29: 0.9980 - loss: 0.0503 - precision_29: 0.9810 - recall_29: 0.9744 - val_accuracy: 0.3986 - val_auc_29: 0.9470 - val_loss: 0.4888 - val_precision_29: 0.9420 - val_recall_29: 0.8904\n",
            "Epoch 22/30\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.4049 - auc_29: 0.9944 - loss: 0.0763 - precision_29: 0.9897 - recall_29: 0.9553 - val_accuracy: 0.4223 - val_auc_29: 0.9442 - val_loss: 0.8755 - val_precision_29: 0.8373 - val_recall_29: 0.9521\n",
            "Epoch 23/30\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.4282 - auc_29: 0.9685 - loss: 0.4249 - precision_29: 0.9117 - recall_29: 0.9603 - val_accuracy: 0.3885 - val_auc_29: 0.9565 - val_loss: 0.4779 - val_precision_29: 0.9257 - val_recall_29: 0.9384\n",
            "Epoch 24/30\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4083 - auc_29: 0.9945 - loss: 0.0790 - precision_29: 0.9870 - recall_29: 0.9579 - val_accuracy: 0.3885 - val_auc_29: 0.9570 - val_loss: 0.4844 - val_precision_29: 0.9257 - val_recall_29: 0.9384\n",
            "Epoch 25/30\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.4153 - auc_29: 0.9975 - loss: 0.0622 - precision_29: 0.9842 - recall_29: 0.9699 - val_accuracy: 0.3885 - val_auc_29: 0.9476 - val_loss: 0.5802 - val_precision_29: 0.9562 - val_recall_29: 0.8973\n",
            "Epoch 26/30\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.3868 - auc_29: 0.9966 - loss: 0.0697 - precision_29: 0.9875 - recall_29: 0.9500 - val_accuracy: 0.3649 - val_auc_29: 0.9377 - val_loss: 0.8890 - val_precision_29: 0.9552 - val_recall_29: 0.8767\n",
            "Epoch 27/30\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.3605 - auc_29: 0.9939 - loss: 0.0791 - precision_29: 0.9975 - recall_29: 0.9570 - val_accuracy: 0.3919 - val_auc_29: 0.9377 - val_loss: 0.7330 - val_precision_29: 0.9559 - val_recall_29: 0.8904\n",
            "Epoch 28/30\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.3889 - auc_29: 0.9967 - loss: 0.0646 - precision_29: 0.9890 - recall_29: 0.9521 - val_accuracy: 0.4088 - val_auc_29: 0.9501 - val_loss: 0.6937 - val_precision_29: 0.9493 - val_recall_29: 0.8973\n",
            "Epoch 29/30\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4446 - auc_29: 0.9958 - loss: 0.0803 - precision_29: 0.9825 - recall_29: 0.9592 - val_accuracy: 0.3953 - val_auc_29: 0.9433 - val_loss: 0.7597 - val_precision_29: 0.9556 - val_recall_29: 0.8836\n",
            "Epoch 30/30\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.4106 - auc_29: 0.9977 - loss: 0.0634 - precision_29: 0.9866 - recall_29: 0.9507 - val_accuracy: 0.4020 - val_auc_29: 0.9352 - val_loss: 0.8819 - val_precision_29: 0.9552 - val_recall_29: 0.8767\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "loss, accuracy, f1_score, precision, recall = model.evaluate(X_test_r, y_test_r)\n",
        "print(f'Loss: {loss}, Accuracy: {accuracy}, F1-Score: {f1_score}, Precision: {precision}, Recall: {recall}, AUC: {roc_auc_score(y_test, model.predict(X_test))}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qThGJgUM5CiU",
        "outputId": "2446a9fb-8af9-4a24-f5de-1b177de13027"
      },
      "execution_count": 113,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3772 - auc_29: 0.9151 - loss: 1.2753 - precision_29: 0.9115 - recall_29: 0.8530 \n",
            "\u001b[1m2671/2671\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step\n",
            "Loss: 0.8819458484649658, Accuracy: 0.40202704071998596, F1-Score: 0.9552238583564758, Precision: 0.8767123222351074, Recall: 0.9351826310157776, AUC: 0.9777646514078219\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Hiperparâmetros"
      ],
      "metadata": {
        "id": "sswD-ILDCmnX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = KerasClassifier(model=create_model, x_train=X_train_r, optimizer='adam', learn_rate=0.01)\n",
        "\n",
        "param_dist = {\n",
        "    'model__optimizer': 'adam',\n",
        "    'batch_size': [64, 128],\n",
        "    'epochs': [30, 45],\n",
        "    'model__learn_rate': [0.01, 0.1]\n",
        "}\n",
        "\n",
        "# Define the scoring metrics\n",
        "scoring = {\n",
        "    'accuracy': make_scorer(accuracy_score),\n",
        "    'precision': make_scorer(precision_score),\n",
        "    'recall': make_scorer(recall_score)}\n",
        "\n",
        "random_search = RandomizedSearchCV(\n",
        "    estimator=model,\n",
        "    param_distributions=param_dist,\n",
        "    n_iter=10,\n",
        "    cv=3,\n",
        "    verbose=2,\n",
        "    random_state=42,\n",
        "    n_jobs=1,\n",
        "    scoring=scoring,\n",
        "    refit='accuracy'\n",
        ")\n",
        "\n",
        "random_search.fit(X_train, y_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "6tfj6lGZNmA7",
        "outputId": "7436483a-f94d-496c-95fc-6613f341e4e2"
      },
      "execution_count": 92,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 3 folds for each of 10 candidates, totalling 30 fits\n",
            "Otimizador não reconhecido\n",
            "[CV] END batch_size=64, epochs=20, model__learn_rate=0.001, model__optimizer=rmsprop; total time=   0.1s\n",
            "Otimizador não reconhecido\n",
            "[CV] END batch_size=64, epochs=20, model__learn_rate=0.001, model__optimizer=rmsprop; total time=   0.1s\n",
            "Otimizador não reconhecido\n",
            "[CV] END batch_size=64, epochs=20, model__learn_rate=0.001, model__optimizer=rmsprop; total time=   0.1s\n",
            "Otimizador não reconhecido\n",
            "[CV] END batch_size=128, epochs=45, model__learn_rate=0.001, model__optimizer=rmsprop; total time=   0.1s\n",
            "Otimizador não reconhecido\n",
            "[CV] END batch_size=128, epochs=45, model__learn_rate=0.001, model__optimizer=rmsprop; total time=   0.1s\n",
            "Otimizador não reconhecido\n",
            "[CV] END batch_size=128, epochs=45, model__learn_rate=0.001, model__optimizer=rmsprop; total time=   0.1s\n",
            "Epoch 1/45\n",
            "\u001b[1m1039/1039\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.0209 - auc_11: 0.6578 - loss: 0.9058 - precision_11: 0.0231 - recall_11: 0.3317\n",
            "Epoch 2/45\n",
            "\u001b[1m1039/1039\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.0025 - auc_11: 0.9238 - loss: 0.0073 - precision_11: 0.8070 - recall_11: 0.7402\n",
            "Epoch 3/45\n",
            "\u001b[1m1039/1039\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.0011 - auc_11: 0.9268 - loss: 0.0047 - precision_11: 0.8650 - recall_11: 0.7589\n",
            "Epoch 4/45\n",
            "\u001b[1m1039/1039\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.0035 - auc_11: 0.9280 - loss: 0.0072 - precision_11: 0.8441 - recall_11: 0.7427\n",
            "Epoch 5/45\n",
            "\u001b[1m1039/1039\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.0202 - auc_11: 0.9148 - loss: 0.0104 - precision_11: 0.8708 - recall_11: 0.6675\n",
            "Epoch 6/45\n",
            "\u001b[1m1039/1039\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - accuracy: 0.0013 - auc_11: 0.9576 - loss: 0.0032 - precision_11: 0.8847 - recall_11: 0.7868\n",
            "Epoch 7/45\n",
            "\u001b[1m1039/1039\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.0013 - auc_11: 0.9273 - loss: 0.0051 - precision_11: 0.8658 - recall_11: 0.7344\n",
            "Epoch 8/45\n",
            "\u001b[1m1039/1039\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.0062 - auc_11: 0.9334 - loss: 0.0052 - precision_11: 0.8134 - recall_11: 0.7691\n",
            "Epoch 9/45\n",
            "\u001b[1m1039/1039\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.0117 - auc_11: 0.9116 - loss: 0.0058 - precision_11: 0.8100 - recall_11: 0.7021\n",
            "Epoch 10/45\n",
            "\u001b[1m1039/1039\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 7.8107e-04 - auc_11: 0.9636 - loss: 0.0027 - precision_11: 0.8679 - recall_11: 0.7918\n",
            "Epoch 11/45\n",
            "\u001b[1m1039/1039\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.0018 - auc_11: 0.9666 - loss: 0.0028 - precision_11: 0.9062 - recall_11: 0.8024\n",
            "Epoch 12/45\n",
            "\u001b[1m1039/1039\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 6.7305e-04 - auc_11: 0.9606 - loss: 0.0024 - precision_11: 0.9079 - recall_11: 0.8481\n",
            "Epoch 13/45\n",
            "\u001b[1m1039/1039\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.0026 - auc_11: 0.9346 - loss: 0.0044 - precision_11: 0.9115 - recall_11: 0.8046\n",
            "Epoch 14/45\n",
            "\u001b[1m1039/1039\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.0060 - auc_11: 0.9327 - loss: 0.0059 - precision_11: 0.8647 - recall_11: 0.7050\n",
            "Epoch 15/45\n",
            "\u001b[1m1039/1039\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 3.3832e-04 - auc_11: 0.9275 - loss: 0.0038 - precision_11: 0.8662 - recall_11: 0.7918\n",
            "Epoch 16/45\n",
            "\u001b[1m1039/1039\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - accuracy: 2.1954e-04 - auc_11: 0.9500 - loss: 0.0027 - precision_11: 0.9324 - recall_11: 0.8181\n",
            "Epoch 17/45\n",
            "\u001b[1m1039/1039\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 5.0675e-04 - auc_11: 0.9666 - loss: 0.0020 - precision_11: 0.9452 - recall_11: 0.8499\n",
            "Epoch 18/45\n",
            "\u001b[1m1039/1039\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 5.9498e-04 - auc_11: 0.9476 - loss: 0.0033 - precision_11: 0.9150 - recall_11: 0.8174\n",
            "Epoch 19/45\n",
            "\u001b[1m1039/1039\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 3.8158e-04 - auc_11: 0.9780 - loss: 0.0019 - precision_11: 0.9149 - recall_11: 0.8571\n",
            "Epoch 20/45\n",
            "\u001b[1m1039/1039\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 3.7601e-04 - auc_11: 0.9624 - loss: 0.0026 - precision_11: 0.9382 - recall_11: 0.8197\n",
            "Epoch 21/45\n",
            "\u001b[1m1039/1039\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 7.8817e-04 - auc_11: 0.9467 - loss: 0.0033 - precision_11: 0.9302 - recall_11: 0.8224\n",
            "Epoch 22/45\n",
            "\u001b[1m1039/1039\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 3.6396e-04 - auc_11: 0.9613 - loss: 0.0024 - precision_11: 0.9157 - recall_11: 0.8458\n",
            "Epoch 23/45\n",
            "\u001b[1m1039/1039\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 3.8743e-04 - auc_11: 0.9660 - loss: 0.0016 - precision_11: 0.9255 - recall_11: 0.8279\n",
            "Epoch 24/45\n",
            "\u001b[1m1039/1039\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 7.0244e-04 - auc_11: 0.9732 - loss: 0.0017 - precision_11: 0.9353 - recall_11: 0.8910\n",
            "Epoch 25/45\n",
            "\u001b[1m1039/1039\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - accuracy: 3.6656e-04 - auc_11: 0.9778 - loss: 0.0018 - precision_11: 0.9570 - recall_11: 0.8499\n",
            "Epoch 26/45\n",
            "\u001b[1m1039/1039\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 3.3951e-04 - auc_11: 0.9628 - loss: 0.0026 - precision_11: 0.9316 - recall_11: 0.8185\n",
            "Epoch 27/45\n",
            "\u001b[1m1039/1039\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 2.8181e-04 - auc_11: 0.9591 - loss: 0.0022 - precision_11: 0.9438 - recall_11: 0.8603\n",
            "Epoch 28/45\n",
            "\u001b[1m1039/1039\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 3.9137e-04 - auc_11: 0.9638 - loss: 0.0021 - precision_11: 0.9620 - recall_11: 0.8805\n",
            "Epoch 29/45\n",
            "\u001b[1m1039/1039\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 4.6362e-04 - auc_11: 0.9667 - loss: 0.0016 - precision_11: 0.9587 - recall_11: 0.8802\n",
            "Epoch 30/45\n",
            "\u001b[1m1039/1039\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - accuracy: 0.0031 - auc_11: 0.9709 - loss: 0.0036 - precision_11: 0.8689 - recall_11: 0.8273\n",
            "Epoch 31/45\n",
            "\u001b[1m1039/1039\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 4.0639e-04 - auc_11: 0.9631 - loss: 0.0021 - precision_11: 0.9629 - recall_11: 0.8704\n",
            "Epoch 32/45\n",
            "\u001b[1m1039/1039\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 4.6399e-04 - auc_11: 0.9491 - loss: 0.0020 - precision_11: 0.9456 - recall_11: 0.8361\n",
            "Epoch 33/45\n",
            "\u001b[1m1039/1039\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 3.4933e-04 - auc_11: 0.9801 - loss: 0.0014 - precision_11: 0.9690 - recall_11: 0.8762\n",
            "Epoch 34/45\n",
            "\u001b[1m1039/1039\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 2.6217e-04 - auc_11: 0.9663 - loss: 0.0016 - precision_11: 0.9796 - recall_11: 0.8767\n",
            "Epoch 35/45\n",
            "\u001b[1m1039/1039\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 4.8596e-04 - auc_11: 0.9644 - loss: 0.0021 - precision_11: 0.9593 - recall_11: 0.8556\n",
            "Epoch 36/45\n",
            "\u001b[1m1039/1039\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 8.9814e-04 - auc_11: 0.9665 - loss: 0.0030 - precision_11: 0.9586 - recall_11: 0.8623\n",
            "Epoch 37/45\n",
            "\u001b[1m1039/1039\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 5.4214e-04 - auc_11: 0.9664 - loss: 0.0017 - precision_11: 0.9859 - recall_11: 0.8762\n",
            "Epoch 38/45\n",
            "\u001b[1m1039/1039\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 5.7939e-04 - auc_11: 0.9706 - loss: 0.0017 - precision_11: 0.9425 - recall_11: 0.8988\n",
            "Epoch 39/45\n",
            "\u001b[1m1039/1039\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 8.4994e-04 - auc_11: 0.9613 - loss: 0.0017 - precision_11: 0.9601 - recall_11: 0.8582\n",
            "Epoch 40/45\n",
            "\u001b[1m1039/1039\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - accuracy: 9.5647e-04 - auc_11: 0.9712 - loss: 0.0012 - precision_11: 0.9668 - recall_11: 0.9063\n",
            "Epoch 41/45\n",
            "\u001b[1m1039/1039\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 5.8713e-04 - auc_11: 0.9758 - loss: 0.0020 - precision_11: 0.9527 - recall_11: 0.8628\n",
            "Epoch 42/45\n",
            "\u001b[1m1039/1039\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 5.6884e-04 - auc_11: 0.9860 - loss: 0.0012 - precision_11: 0.9724 - recall_11: 0.8991\n",
            "Epoch 43/45\n",
            "\u001b[1m1039/1039\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 7.4619e-04 - auc_11: 0.9767 - loss: 0.0012 - precision_11: 0.9669 - recall_11: 0.8665\n",
            "Epoch 44/45\n",
            "\u001b[1m1039/1039\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 6.9932e-04 - auc_11: 0.9720 - loss: 0.0014 - precision_11: 0.9829 - recall_11: 0.8906\n",
            "Epoch 45/45\n",
            "\u001b[1m1039/1039\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.0012 - auc_11: 0.9592 - loss: 0.0015 - precision_11: 0.9631 - recall_11: 0.8879\n",
            "\u001b[1m520/520\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step\n",
            "[CV] END batch_size=128, epochs=45, model__learn_rate=0.001, model__optimizer=adam; total time= 2.4min\n",
            "Epoch 1/45\n",
            "\u001b[1m1039/1039\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 2ms/step - accuracy: 0.0278 - auc_12: 0.6783 - loss: 0.0637 - precision_12: 0.3798 - recall_12: 0.3802\n",
            "Epoch 2/45\n",
            "\u001b[1m1039/1039\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.0232 - auc_12: 0.8693 - loss: 0.0170 - precision_12: 0.7951 - recall_12: 0.6223\n",
            "Epoch 3/45\n",
            "\u001b[1m1039/1039\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.0014 - auc_12: 0.9294 - loss: 0.0051 - precision_12: 0.8757 - recall_12: 0.7078\n",
            "Epoch 4/45\n",
            "\u001b[1m1039/1039\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.0011 - auc_12: 0.9473 - loss: 0.0030 - precision_12: 0.8600 - recall_12: 0.7680\n",
            "Epoch 5/45\n",
            "\u001b[1m1039/1039\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.0020 - auc_12: 0.9349 - loss: 0.0041 - precision_12: 0.9024 - recall_12: 0.8055\n",
            "Epoch 6/45\n",
            "\u001b[1m1039/1039\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.0036 - auc_12: 0.9136 - loss: 0.0057 - precision_12: 0.8795 - recall_12: 0.6519\n",
            "Epoch 7/45\n",
            "\u001b[1m1039/1039\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 5.7714e-04 - auc_12: 0.9532 - loss: 0.0037 - precision_12: 0.8817 - recall_12: 0.7683\n",
            "Epoch 8/45\n",
            "\u001b[1m1039/1039\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 7.8077e-04 - auc_12: 0.9444 - loss: 0.0029 - precision_12: 0.9086 - recall_12: 0.7571\n",
            "Epoch 9/45\n",
            "\u001b[1m1039/1039\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.0014 - auc_12: 0.9504 - loss: 0.0028 - precision_12: 0.8794 - recall_12: 0.8083\n",
            "Epoch 10/45\n",
            "\u001b[1m1039/1039\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 1.5254e-04 - auc_12: 0.9462 - loss: 0.0030 - precision_12: 0.9237 - recall_12: 0.8016\n",
            "Epoch 11/45\n",
            "\u001b[1m1039/1039\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.0019 - auc_12: 0.9604 - loss: 0.0028 - precision_12: 0.9303 - recall_12: 0.8233\n",
            "Epoch 12/45\n",
            "\u001b[1m1039/1039\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 7.3434e-04 - auc_12: 0.9607 - loss: 0.0024 - precision_12: 0.9322 - recall_12: 0.8123\n",
            "Epoch 13/45\n",
            "\u001b[1m1039/1039\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - accuracy: 0.0011 - auc_12: 0.9477 - loss: 0.0034 - precision_12: 0.9269 - recall_12: 0.7667\n",
            "Epoch 14/45\n",
            "\u001b[1m1039/1039\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 4.5013e-04 - auc_12: 0.9558 - loss: 0.0028 - precision_12: 0.9229 - recall_12: 0.8214\n",
            "Epoch 15/45\n",
            "\u001b[1m1039/1039\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.0017 - auc_12: 0.9474 - loss: 0.0033 - precision_12: 0.8511 - recall_12: 0.7869\n",
            "Epoch 16/45\n",
            "\u001b[1m1039/1039\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 2.3511e-04 - auc_12: 0.9509 - loss: 0.0029 - precision_12: 0.8890 - recall_12: 0.7712\n",
            "Epoch 17/45\n",
            "\u001b[1m1039/1039\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 1.4441e-04 - auc_12: 0.9583 - loss: 0.0023 - precision_12: 0.9478 - recall_12: 0.8077\n",
            "Epoch 18/45\n",
            "\u001b[1m1039/1039\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - accuracy: 3.4064e-04 - auc_12: 0.9492 - loss: 0.0023 - precision_12: 0.9197 - recall_12: 0.8263\n",
            "Epoch 19/45\n",
            "\u001b[1m1039/1039\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 2.4671e-04 - auc_12: 0.9766 - loss: 0.0020 - precision_12: 0.9101 - recall_12: 0.8348\n",
            "Epoch 20/45\n",
            "\u001b[1m1039/1039\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 3.1177e-04 - auc_12: 0.9511 - loss: 0.0025 - precision_12: 0.9000 - recall_12: 0.8003\n",
            "Epoch 21/45\n",
            "\u001b[1m1039/1039\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 4.6792e-04 - auc_12: 0.9620 - loss: 0.0022 - precision_12: 0.9320 - recall_12: 0.8231\n",
            "Epoch 22/45\n",
            "\u001b[1m1039/1039\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 4.4339e-04 - auc_12: 0.9511 - loss: 0.0027 - precision_12: 0.9379 - recall_12: 0.7638\n",
            "Epoch 23/45\n",
            "\u001b[1m1039/1039\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 4.8603e-04 - auc_12: 0.9683 - loss: 0.0025 - precision_12: 0.9353 - recall_12: 0.8187\n",
            "Epoch 24/45\n",
            "\u001b[1m1039/1039\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 4.3308e-04 - auc_12: 0.9541 - loss: 0.0022 - precision_12: 0.9319 - recall_12: 0.7927\n",
            "Epoch 25/45\n",
            "\u001b[1m1039/1039\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 5.0501e-04 - auc_12: 0.9688 - loss: 0.0016 - precision_12: 0.9533 - recall_12: 0.8756\n",
            "Epoch 26/45\n",
            "\u001b[1m1039/1039\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 8.7573e-04 - auc_12: 0.9701 - loss: 0.0014 - precision_12: 0.9696 - recall_12: 0.8813\n",
            "Epoch 27/45\n",
            "\u001b[1m1039/1039\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 9.4778e-04 - auc_12: 0.9644 - loss: 0.0018 - precision_12: 0.9314 - recall_12: 0.8418\n",
            "Epoch 28/45\n",
            "\u001b[1m1039/1039\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 9.1085e-04 - auc_12: 0.9807 - loss: 0.0015 - precision_12: 0.9534 - recall_12: 0.8432\n",
            "Epoch 29/45\n",
            "\u001b[1m1039/1039\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - accuracy: 0.0020 - auc_12: 0.9680 - loss: 0.0019 - precision_12: 0.9743 - recall_12: 0.8621\n",
            "Epoch 30/45\n",
            "\u001b[1m1039/1039\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 8.8560e-04 - auc_12: 0.9786 - loss: 0.0016 - precision_12: 0.9332 - recall_12: 0.8423\n",
            "Epoch 31/45\n",
            "\u001b[1m1039/1039\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.0015 - auc_12: 0.9685 - loss: 0.0018 - precision_12: 0.9512 - recall_12: 0.8251\n",
            "Epoch 32/45\n",
            "\u001b[1m1039/1039\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.0014 - auc_12: 0.9729 - loss: 0.0015 - precision_12: 0.9510 - recall_12: 0.8311\n",
            "Epoch 33/45\n",
            "\u001b[1m1039/1039\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.0035 - auc_12: 0.9713 - loss: 0.0017 - precision_12: 0.9582 - recall_12: 0.8575\n",
            "Epoch 34/45\n",
            "\u001b[1m1039/1039\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - accuracy: 0.0043 - auc_12: 0.9745 - loss: 0.0014 - precision_12: 0.9498 - recall_12: 0.8729\n",
            "Epoch 35/45\n",
            "\u001b[1m1039/1039\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.0049 - auc_12: 0.9670 - loss: 0.0016 - precision_12: 0.9405 - recall_12: 0.8390\n",
            "Epoch 36/45\n",
            "\u001b[1m1039/1039\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.0045 - auc_12: 0.9737 - loss: 0.0013 - precision_12: 0.9600 - recall_12: 0.8893\n",
            "Epoch 37/45\n",
            "\u001b[1m1039/1039\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.0039 - auc_12: 0.9603 - loss: 0.0017 - precision_12: 0.9307 - recall_12: 0.8140\n",
            "Epoch 38/45\n",
            "\u001b[1m1039/1039\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.0048 - auc_12: 0.9781 - loss: 0.0019 - precision_12: 0.9582 - recall_12: 0.8240\n",
            "Epoch 39/45\n",
            "\u001b[1m1039/1039\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.0046 - auc_12: 0.9741 - loss: 0.0013 - precision_12: 0.9822 - recall_12: 0.8799\n",
            "Epoch 40/45\n",
            "\u001b[1m1039/1039\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.0063 - auc_12: 0.9851 - loss: 0.0011 - precision_12: 0.9797 - recall_12: 0.8929\n",
            "Epoch 41/45\n",
            "\u001b[1m1039/1039\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.0056 - auc_12: 0.9793 - loss: 0.0014 - precision_12: 0.9503 - recall_12: 0.8774\n",
            "Epoch 42/45\n",
            "\u001b[1m1039/1039\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.0053 - auc_12: 0.9740 - loss: 0.0021 - precision_12: 0.9566 - recall_12: 0.8496\n",
            "Epoch 43/45\n",
            "\u001b[1m1039/1039\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.0059 - auc_12: 0.9733 - loss: 0.0015 - precision_12: 0.9892 - recall_12: 0.8748\n",
            "Epoch 44/45\n",
            "\u001b[1m1039/1039\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.0075 - auc_12: 0.9828 - loss: 0.0015 - precision_12: 0.9501 - recall_12: 0.8283\n",
            "Epoch 45/45\n",
            "\u001b[1m1039/1039\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.0069 - auc_12: 0.9824 - loss: 0.0011 - precision_12: 0.9776 - recall_12: 0.8879\n",
            "\u001b[1m520/520\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step\n",
            "[CV] END batch_size=128, epochs=45, model__learn_rate=0.001, model__optimizer=adam; total time= 3.1min\n",
            "Epoch 1/45\n",
            "\u001b[1m1039/1039\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.0280 - auc_13: 0.7527 - loss: 0.0559 - precision_13: 0.5756 - recall_13: 0.3629\n",
            "Epoch 2/45\n",
            "\u001b[1m1039/1039\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - accuracy: 0.0085 - auc_13: 0.9142 - loss: 0.0094 - precision_13: 0.8259 - recall_13: 0.7201\n",
            "Epoch 3/45\n",
            "\u001b[1m1039/1039\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.0073 - auc_13: 0.9032 - loss: 0.0090 - precision_13: 0.8408 - recall_13: 0.6618\n",
            "Epoch 4/45\n",
            "\u001b[1m1039/1039\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.0277 - auc_13: 0.9125 - loss: 0.0094 - precision_13: 0.8340 - recall_13: 0.7382\n",
            "Epoch 5/45\n",
            "\u001b[1m1039/1039\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.0032 - auc_13: 0.9281 - loss: 0.0080 - precision_13: 0.8657 - recall_13: 0.7604\n",
            "Epoch 6/45\n",
            "\u001b[1m1039/1039\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 6.4598e-04 - auc_13: 0.9147 - loss: 0.0056 - precision_13: 0.8202 - recall_13: 0.7334\n",
            "Epoch 7/45\n",
            "\u001b[1m1039/1039\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - accuracy: 0.0013 - auc_13: 0.9317 - loss: 0.0053 - precision_13: 0.8326 - recall_13: 0.7212\n",
            "Epoch 8/45\n",
            "\u001b[1m1039/1039\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.0014 - auc_13: 0.9252 - loss: 0.0056 - precision_13: 0.8155 - recall_13: 0.6879\n",
            "Epoch 9/45\n",
            "\u001b[1m1039/1039\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 6.2253e-04 - auc_13: 0.9463 - loss: 0.0039 - precision_13: 0.8215 - recall_13: 0.7733\n",
            "Epoch 10/45\n",
            "\u001b[1m1039/1039\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.0014 - auc_13: 0.9329 - loss: 0.0042 - precision_13: 0.8767 - recall_13: 0.7650\n",
            "Epoch 11/45\n",
            "\u001b[1m1039/1039\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 3.7740e-04 - auc_13: 0.9360 - loss: 0.0058 - precision_13: 0.9167 - recall_13: 0.7639\n",
            "Epoch 12/45\n",
            "\u001b[1m1039/1039\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.0022 - auc_13: 0.9614 - loss: 0.0032 - precision_13: 0.8818 - recall_13: 0.8044\n",
            "Epoch 13/45\n",
            "\u001b[1m1039/1039\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - accuracy: 3.6366e-04 - auc_13: 0.9423 - loss: 0.0036 - precision_13: 0.8656 - recall_13: 0.7333\n",
            "Epoch 14/45\n",
            "\u001b[1m1039/1039\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.0020 - auc_13: 0.9437 - loss: 0.0038 - precision_13: 0.8562 - recall_13: 0.7686\n",
            "Epoch 15/45\n",
            "\u001b[1m1039/1039\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 2.8241e-04 - auc_13: 0.9596 - loss: 0.0033 - precision_13: 0.8618 - recall_13: 0.7817\n",
            "Epoch 16/45\n",
            "\u001b[1m1039/1039\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 5.1171e-04 - auc_13: 0.9571 - loss: 0.0033 - precision_13: 0.8761 - recall_13: 0.8329\n",
            "Epoch 17/45\n",
            "\u001b[1m1039/1039\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 5.9004e-05 - auc_13: 0.9560 - loss: 0.0025 - precision_13: 0.9240 - recall_13: 0.8103\n",
            "Epoch 18/45\n",
            "\u001b[1m1039/1039\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - accuracy: 2.4830e-04 - auc_13: 0.9707 - loss: 0.0026 - precision_13: 0.9073 - recall_13: 0.8080\n",
            "Epoch 19/45\n",
            "\u001b[1m1039/1039\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 2.6775e-04 - auc_13: 0.9540 - loss: 0.0026 - precision_13: 0.9333 - recall_13: 0.8482\n",
            "Epoch 20/45\n",
            "\u001b[1m1039/1039\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 2.8423e-04 - auc_13: 0.9481 - loss: 0.0035 - precision_13: 0.9142 - recall_13: 0.7538\n",
            "Epoch 21/45\n",
            "\u001b[1m1039/1039\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 9.7193e-04 - auc_13: 0.9661 - loss: 0.0031 - precision_13: 0.9189 - recall_13: 0.7839\n",
            "Epoch 22/45\n",
            "\u001b[1m1039/1039\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 8.5927e-04 - auc_13: 0.9535 - loss: 0.0036 - precision_13: 0.9540 - recall_13: 0.7965\n",
            "Epoch 23/45\n",
            "\u001b[1m1039/1039\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - accuracy: 4.0902e-04 - auc_13: 0.9612 - loss: 0.0026 - precision_13: 0.9416 - recall_13: 0.7924\n",
            "Epoch 24/45\n",
            "\u001b[1m1039/1039\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 1.4426e-04 - auc_13: 0.9697 - loss: 0.0021 - precision_13: 0.9255 - recall_13: 0.8261\n",
            "Epoch 25/45\n",
            "\u001b[1m1039/1039\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 3.3103e-04 - auc_13: 0.9766 - loss: 0.0016 - precision_13: 0.9336 - recall_13: 0.8811\n",
            "Epoch 26/45\n",
            "\u001b[1m1039/1039\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 3.6414e-04 - auc_13: 0.9379 - loss: 0.0035 - precision_13: 0.9438 - recall_13: 0.7776\n",
            "Epoch 27/45\n",
            "\u001b[1m1039/1039\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 4.7058e-04 - auc_13: 0.9692 - loss: 0.0020 - precision_13: 0.9626 - recall_13: 0.8196\n",
            "Epoch 28/45\n",
            "\u001b[1m1039/1039\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - accuracy: 3.1854e-04 - auc_13: 0.9613 - loss: 0.0023 - precision_13: 0.9329 - recall_13: 0.8418\n",
            "Epoch 29/45\n",
            "\u001b[1m1039/1039\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 4.5063e-04 - auc_13: 0.9653 - loss: 0.0018 - precision_13: 0.9219 - recall_13: 0.8457\n",
            "Epoch 30/45\n",
            "\u001b[1m1039/1039\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 6.2117e-04 - auc_13: 0.9698 - loss: 0.0017 - precision_13: 0.9622 - recall_13: 0.8422\n",
            "Epoch 31/45\n",
            "\u001b[1m1039/1039\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 6.8802e-04 - auc_13: 0.9714 - loss: 0.0018 - precision_13: 0.9444 - recall_13: 0.8173\n",
            "Epoch 32/45\n",
            "\u001b[1m1039/1039\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 8.4113e-04 - auc_13: 0.9717 - loss: 0.0029 - precision_13: 0.9395 - recall_13: 0.7395\n",
            "Epoch 33/45\n",
            "\u001b[1m1039/1039\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.0012 - auc_13: 0.9887 - loss: 0.0010 - precision_13: 0.9420 - recall_13: 0.8758\n",
            "Epoch 34/45\n",
            "\u001b[1m1039/1039\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 9.2710e-04 - auc_13: 0.9630 - loss: 0.0023 - precision_13: 0.9244 - recall_13: 0.8437\n",
            "Epoch 35/45\n",
            "\u001b[1m1039/1039\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 9.2362e-04 - auc_13: 0.9683 - loss: 0.0023 - precision_13: 0.9719 - recall_13: 0.8507\n",
            "Epoch 36/45\n",
            "\u001b[1m1039/1039\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.0014 - auc_13: 0.9601 - loss: 0.0023 - precision_13: 0.9027 - recall_13: 0.7861\n",
            "Epoch 37/45\n",
            "\u001b[1m1039/1039\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - accuracy: 0.0012 - auc_13: 0.9709 - loss: 0.0019 - precision_13: 0.9800 - recall_13: 0.8550\n",
            "Epoch 38/45\n",
            "\u001b[1m1039/1039\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.0013 - auc_13: 0.9762 - loss: 0.0020 - precision_13: 0.9661 - recall_13: 0.8942\n",
            "Epoch 39/45\n",
            "\u001b[1m1039/1039\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.0014 - auc_13: 0.9626 - loss: 0.0016 - precision_13: 0.9603 - recall_13: 0.8586\n",
            "Epoch 40/45\n",
            "\u001b[1m1039/1039\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.0018 - auc_13: 0.9695 - loss: 0.0019 - precision_13: 0.9405 - recall_13: 0.8043\n",
            "Epoch 41/45\n",
            "\u001b[1m1039/1039\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.0036 - auc_13: 0.9690 - loss: 0.0013 - precision_13: 0.9604 - recall_13: 0.8527\n",
            "Epoch 42/45\n",
            "\u001b[1m1039/1039\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - accuracy: 0.0040 - auc_13: 0.9603 - loss: 0.0015 - precision_13: 0.9596 - recall_13: 0.8610\n",
            "Epoch 43/45\n",
            "\u001b[1m1039/1039\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.0022 - auc_13: 0.9731 - loss: 0.0023 - precision_13: 0.9594 - recall_13: 0.8663\n",
            "Epoch 44/45\n",
            "\u001b[1m1039/1039\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.0028 - auc_13: 0.9606 - loss: 0.0016 - precision_13: 0.9853 - recall_13: 0.8586\n",
            "Epoch 45/45\n",
            "\u001b[1m1039/1039\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.0032 - auc_13: 0.9683 - loss: 0.0014 - precision_13: 0.9555 - recall_13: 0.8767\n",
            "\u001b[1m520/520\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step\n",
            "[CV] END batch_size=128, epochs=45, model__learn_rate=0.001, model__optimizer=adam; total time= 2.3min\n",
            "Epoch 1/45\n",
            "\u001b[1m4154/4154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 3ms/step - accuracy: 0.0252 - auc_14: 0.7794 - loss: 0.0415 - precision_14: 0.6882 - recall_14: 0.4655\n",
            "Epoch 2/45\n",
            "\u001b[1m4154/4154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 3ms/step - accuracy: 0.0061 - auc_14: 0.9241 - loss: 0.0121 - precision_14: 0.8039 - recall_14: 0.6706\n",
            "Epoch 3/45\n",
            "\u001b[1m4154/4154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 3ms/step - accuracy: 0.0020 - auc_14: 0.9201 - loss: 0.0057 - precision_14: 0.7997 - recall_14: 0.6792\n",
            "Epoch 4/45\n",
            "\u001b[1m4154/4154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 3ms/step - accuracy: 6.3105e-04 - auc_14: 0.9277 - loss: 0.0046 - precision_14: 0.8488 - recall_14: 0.7255\n",
            "Epoch 5/45\n",
            "\u001b[1m4154/4154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 3ms/step - accuracy: 5.1352e-04 - auc_14: 0.9338 - loss: 0.0041 - precision_14: 0.8396 - recall_14: 0.6564\n",
            "Epoch 6/45\n",
            "\u001b[1m4154/4154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 3ms/step - accuracy: 4.9076e-04 - auc_14: 0.9457 - loss: 0.0035 - precision_14: 0.8328 - recall_14: 0.7610\n",
            "Epoch 7/45\n",
            "\u001b[1m4154/4154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 2ms/step - accuracy: 5.1715e-04 - auc_14: 0.9658 - loss: 0.0040 - precision_14: 0.8299 - recall_14: 0.6893\n",
            "Epoch 8/45\n",
            "\u001b[1m4154/4154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 3ms/step - accuracy: 0.0010 - auc_14: 0.9514 - loss: 0.0040 - precision_14: 0.8425 - recall_14: 0.7310\n",
            "Epoch 9/45\n",
            "\u001b[1m4154/4154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 3ms/step - accuracy: 3.2310e-04 - auc_14: 0.9442 - loss: 0.0033 - precision_14: 0.8727 - recall_14: 0.7630\n",
            "Epoch 10/45\n",
            "\u001b[1m4154/4154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 3ms/step - accuracy: 2.3948e-04 - auc_14: 0.9592 - loss: 0.0027 - precision_14: 0.9148 - recall_14: 0.7616\n",
            "Epoch 11/45\n",
            "\u001b[1m4154/4154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 3ms/step - accuracy: 5.4788e-04 - auc_14: 0.9621 - loss: 0.0039 - precision_14: 0.9012 - recall_14: 0.7320\n",
            "Epoch 12/45\n",
            "\u001b[1m4154/4154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 3ms/step - accuracy: 2.3650e-04 - auc_14: 0.9581 - loss: 0.0037 - precision_14: 0.9328 - recall_14: 0.7305\n",
            "Epoch 13/45\n",
            "\u001b[1m4154/4154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 2ms/step - accuracy: 2.6893e-04 - auc_14: 0.9519 - loss: 0.0035 - precision_14: 0.9211 - recall_14: 0.7964\n",
            "Epoch 14/45\n",
            "\u001b[1m4154/4154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 2ms/step - accuracy: 0.0011 - auc_14: 0.9668 - loss: 0.0027 - precision_14: 0.9122 - recall_14: 0.8165\n",
            "Epoch 15/45\n",
            "\u001b[1m4154/4154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 3ms/step - accuracy: 4.4314e-04 - auc_14: 0.9513 - loss: 0.0034 - precision_14: 0.8992 - recall_14: 0.7394\n",
            "Epoch 16/45\n",
            "\u001b[1m4154/4154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 2ms/step - accuracy: 2.0652e-04 - auc_14: 0.9504 - loss: 0.0026 - precision_14: 0.9489 - recall_14: 0.7917\n",
            "Epoch 17/45\n",
            "\u001b[1m4154/4154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 3ms/step - accuracy: 2.9285e-04 - auc_14: 0.9636 - loss: 0.0022 - precision_14: 0.9248 - recall_14: 0.8180\n",
            "Epoch 18/45\n",
            "\u001b[1m4154/4154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 3ms/step - accuracy: 4.7475e-04 - auc_14: 0.9595 - loss: 0.0020 - precision_14: 0.9563 - recall_14: 0.8523\n",
            "Epoch 19/45\n",
            "\u001b[1m4154/4154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 2ms/step - accuracy: 0.0015 - auc_14: 0.9637 - loss: 0.0027 - precision_14: 0.9554 - recall_14: 0.8083\n",
            "Epoch 20/45\n",
            "\u001b[1m4154/4154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 3ms/step - accuracy: 3.7098e-04 - auc_14: 0.9630 - loss: 0.0021 - precision_14: 0.9582 - recall_14: 0.8225\n",
            "Epoch 21/45\n",
            "\u001b[1m4154/4154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 3ms/step - accuracy: 3.7480e-04 - auc_14: 0.9594 - loss: 0.0026 - precision_14: 0.9316 - recall_14: 0.8135\n",
            "Epoch 22/45\n",
            "\u001b[1m4154/4154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 3ms/step - accuracy: 5.5785e-04 - auc_14: 0.9640 - loss: 0.0020 - precision_14: 0.9347 - recall_14: 0.8283\n",
            "Epoch 23/45\n",
            "\u001b[1m4154/4154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 2ms/step - accuracy: 0.0015 - auc_14: 0.9628 - loss: 0.0021 - precision_14: 0.9376 - recall_14: 0.7894\n",
            "Epoch 24/45\n",
            "\u001b[1m4154/4154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 2ms/step - accuracy: 0.0029 - auc_14: 0.9736 - loss: 0.0020 - precision_14: 0.9670 - recall_14: 0.8990\n",
            "Epoch 25/45\n",
            "\u001b[1m4154/4154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 4ms/step - accuracy: 0.0023 - auc_14: 0.9618 - loss: 0.0025 - precision_14: 0.9377 - recall_14: 0.8709\n",
            "Epoch 26/45\n",
            "\u001b[1m4154/4154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 3ms/step - accuracy: 9.9164e-04 - auc_14: 0.9849 - loss: 0.0020 - precision_14: 0.9602 - recall_14: 0.8378\n",
            "Epoch 27/45\n",
            "\u001b[1m4154/4154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 3ms/step - accuracy: 0.0011 - auc_14: 0.9715 - loss: 0.0018 - precision_14: 0.9496 - recall_14: 0.8573\n",
            "Epoch 28/45\n",
            "\u001b[1m4154/4154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 2ms/step - accuracy: 0.0032 - auc_14: 0.9569 - loss: 0.0023 - precision_14: 0.9687 - recall_14: 0.8542\n",
            "Epoch 29/45\n",
            "\u001b[1m4154/4154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 3ms/step - accuracy: 0.0019 - auc_14: 0.9754 - loss: 0.0015 - precision_14: 0.9577 - recall_14: 0.8682\n",
            "Epoch 30/45\n",
            "\u001b[1m4154/4154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 3ms/step - accuracy: 0.0017 - auc_14: 0.9714 - loss: 0.0021 - precision_14: 0.9661 - recall_14: 0.8782\n",
            "Epoch 31/45\n",
            "\u001b[1m4154/4154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 3ms/step - accuracy: 0.0023 - auc_14: 0.9678 - loss: 0.0024 - precision_14: 0.9499 - recall_14: 0.7838\n",
            "Epoch 32/45\n",
            "\u001b[1m4154/4154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 3ms/step - accuracy: 0.0049 - auc_14: 0.9619 - loss: 0.0029 - precision_14: 0.8993 - recall_14: 0.8215\n",
            "Epoch 33/45\n",
            "\u001b[1m4154/4154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 2ms/step - accuracy: 0.0119 - auc_14: 0.9538 - loss: 0.0022 - precision_14: 0.9514 - recall_14: 0.8395\n",
            "Epoch 34/45\n",
            "\u001b[1m4154/4154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 3ms/step - accuracy: 0.0032 - auc_14: 0.9490 - loss: 0.0022 - precision_14: 0.9512 - recall_14: 0.8791\n",
            "Epoch 35/45\n",
            "\u001b[1m4154/4154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 2ms/step - accuracy: 0.0052 - auc_14: 0.9238 - loss: 0.0023 - precision_14: 0.9422 - recall_14: 0.8118\n",
            "Epoch 36/45\n",
            "\u001b[1m4154/4154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 3ms/step - accuracy: 0.0232 - auc_14: 0.9526 - loss: 0.0029 - precision_14: 0.9368 - recall_14: 0.8389\n",
            "Epoch 37/45\n",
            "\u001b[1m4154/4154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 2ms/step - accuracy: 0.0040 - auc_14: 0.9302 - loss: 0.0024 - precision_14: 0.9434 - recall_14: 0.8361\n",
            "Epoch 38/45\n",
            "\u001b[1m4154/4154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 3ms/step - accuracy: 0.0114 - auc_14: 0.9558 - loss: 0.0025 - precision_14: 0.9322 - recall_14: 0.8439\n",
            "Epoch 39/45\n",
            "\u001b[1m4154/4154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 3ms/step - accuracy: 0.0015 - auc_14: 0.9563 - loss: 0.0017 - precision_14: 0.9712 - recall_14: 0.8840\n",
            "Epoch 40/45\n",
            "\u001b[1m4154/4154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 2ms/step - accuracy: 0.0106 - auc_14: 0.9461 - loss: 0.0022 - precision_14: 0.9536 - recall_14: 0.8519\n",
            "Epoch 41/45\n",
            "\u001b[1m4154/4154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 3ms/step - accuracy: 0.1374 - auc_14: 0.9565 - loss: 0.0021 - precision_14: 0.9537 - recall_14: 0.8587\n",
            "Epoch 42/45\n",
            "\u001b[1m4154/4154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 2ms/step - accuracy: 0.1471 - auc_14: 0.9392 - loss: 0.0025 - precision_14: 0.9647 - recall_14: 0.8359\n",
            "Epoch 43/45\n",
            "\u001b[1m4154/4154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 3ms/step - accuracy: 0.0013 - auc_14: 0.9581 - loss: 0.0017 - precision_14: 0.9497 - recall_14: 0.8753\n",
            "Epoch 44/45\n",
            "\u001b[1m4154/4154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 3ms/step - accuracy: 0.0264 - auc_14: 0.9273 - loss: 0.0030 - precision_14: 0.9478 - recall_14: 0.8036\n",
            "Epoch 45/45\n",
            "\u001b[1m4154/4154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 2ms/step - accuracy: 0.1031 - auc_14: 0.9393 - loss: 0.0028 - precision_14: 0.9125 - recall_14: 0.7899\n",
            "\u001b[1m2077/2077\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step\n",
            "[CV] END batch_size=32, epochs=45, model__learn_rate=0.001, model__optimizer=adam; total time=10.7min\n",
            "Epoch 1/45\n",
            "\u001b[1m4154/4154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 2ms/step - accuracy: 0.0262 - auc_15: 0.7692 - loss: 0.0427 - precision_15: 0.6822 - recall_15: 0.4140\n",
            "Epoch 2/45\n",
            "\u001b[1m4154/4154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 2ms/step - accuracy: 0.0043 - auc_15: 0.9160 - loss: 0.0075 - precision_15: 0.8035 - recall_15: 0.7371\n",
            "Epoch 3/45\n",
            "\u001b[1m4154/4154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 3ms/step - accuracy: 0.0068 - auc_15: 0.9109 - loss: 0.0095 - precision_15: 0.8501 - recall_15: 0.6959\n",
            "Epoch 4/45\n",
            "\u001b[1m4154/4154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 2ms/step - accuracy: 0.0017 - auc_15: 0.9329 - loss: 0.0076 - precision_15: 0.8849 - recall_15: 0.7448\n",
            "Epoch 5/45\n",
            "\u001b[1m4154/4154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 3ms/step - accuracy: 0.0016 - auc_15: 0.9360 - loss: 0.0041 - precision_15: 0.8440 - recall_15: 0.7614\n",
            "Epoch 6/45\n",
            "\u001b[1m4154/4154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 2ms/step - accuracy: 0.0010 - auc_15: 0.9333 - loss: 0.0047 - precision_15: 0.8171 - recall_15: 0.7803\n",
            "Epoch 7/45\n",
            "\u001b[1m4154/4154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 2ms/step - accuracy: 8.0790e-04 - auc_15: 0.9460 - loss: 0.0032 - precision_15: 0.8808 - recall_15: 0.7411\n",
            "Epoch 8/45\n",
            "\u001b[1m4154/4154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 3ms/step - accuracy: 4.4758e-04 - auc_15: 0.9266 - loss: 0.0041 - precision_15: 0.8600 - recall_15: 0.7133\n",
            "Epoch 9/45\n",
            "\u001b[1m4154/4154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 2ms/step - accuracy: 0.0017 - auc_15: 0.9358 - loss: 0.0049 - precision_15: 0.8365 - recall_15: 0.7647\n",
            "Epoch 10/45\n",
            "\u001b[1m4154/4154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 2ms/step - accuracy: 5.4503e-04 - auc_15: 0.9529 - loss: 0.0023 - precision_15: 0.8638 - recall_15: 0.7875\n",
            "Epoch 11/45\n",
            "\u001b[1m4154/4154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 3ms/step - accuracy: 6.2218e-04 - auc_15: 0.9491 - loss: 0.0034 - precision_15: 0.9129 - recall_15: 0.7958\n",
            "Epoch 12/45\n",
            "\u001b[1m4154/4154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 2ms/step - accuracy: 2.4206e-04 - auc_15: 0.9371 - loss: 0.0029 - precision_15: 0.9158 - recall_15: 0.7734\n",
            "Epoch 13/45\n",
            "\u001b[1m4154/4154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 3ms/step - accuracy: 5.9731e-04 - auc_15: 0.9319 - loss: 0.0033 - precision_15: 0.9338 - recall_15: 0.7100\n",
            "Epoch 14/45\n",
            "\u001b[1m4154/4154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 3ms/step - accuracy: 7.8631e-04 - auc_15: 0.9408 - loss: 0.0034 - precision_15: 0.9014 - recall_15: 0.7316\n",
            "Epoch 15/45\n",
            "\u001b[1m4154/4154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 2ms/step - accuracy: 0.0011 - auc_15: 0.9576 - loss: 0.0029 - precision_15: 0.9211 - recall_15: 0.8144\n",
            "Epoch 16/45\n",
            "\u001b[1m4154/4154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 3ms/step - accuracy: 3.2437e-04 - auc_15: 0.9597 - loss: 0.0025 - precision_15: 0.9440 - recall_15: 0.8178\n",
            "Epoch 17/45\n",
            "\u001b[1m4154/4154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 3ms/step - accuracy: 5.7725e-04 - auc_15: 0.9302 - loss: 0.0028 - precision_15: 0.9356 - recall_15: 0.7731\n",
            "Epoch 18/45\n",
            "\u001b[1m4154/4154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 4ms/step - accuracy: 3.7159e-04 - auc_15: 0.9569 - loss: 0.0022 - precision_15: 0.9265 - recall_15: 0.7974\n",
            "Epoch 19/45\n",
            "\u001b[1m4154/4154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 3ms/step - accuracy: 0.0011 - auc_15: 0.9461 - loss: 0.0027 - precision_15: 0.8985 - recall_15: 0.7878\n",
            "Epoch 20/45\n",
            "\u001b[1m4154/4154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 3ms/step - accuracy: 5.3472e-04 - auc_15: 0.9419 - loss: 0.0024 - precision_15: 0.9324 - recall_15: 0.7805\n",
            "Epoch 21/45\n",
            "\u001b[1m4154/4154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 3ms/step - accuracy: 5.0616e-04 - auc_15: 0.9629 - loss: 0.0026 - precision_15: 0.9223 - recall_15: 0.7964\n",
            "Epoch 22/45\n",
            "\u001b[1m4154/4154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 3ms/step - accuracy: 4.3611e-04 - auc_15: 0.9445 - loss: 0.0022 - precision_15: 0.9241 - recall_15: 0.8096\n",
            "Epoch 23/45\n",
            "\u001b[1m4154/4154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 3ms/step - accuracy: 7.6534e-04 - auc_15: 0.9483 - loss: 0.0028 - precision_15: 0.9595 - recall_15: 0.8005\n",
            "Epoch 24/45\n",
            "\u001b[1m4154/4154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 2ms/step - accuracy: 0.0010 - auc_15: 0.9520 - loss: 0.0029 - precision_15: 0.9556 - recall_15: 0.7292\n",
            "Epoch 25/45\n",
            "\u001b[1m4154/4154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 2ms/step - accuracy: 8.8290e-04 - auc_15: 0.9537 - loss: 0.0028 - precision_15: 0.9338 - recall_15: 0.8043\n",
            "Epoch 26/45\n",
            "\u001b[1m4154/4154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 3ms/step - accuracy: 0.0011 - auc_15: 0.9668 - loss: 0.0022 - precision_15: 0.9521 - recall_15: 0.8035\n",
            "Epoch 27/45\n",
            "\u001b[1m4154/4154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 2ms/step - accuracy: 7.5832e-04 - auc_15: 0.9770 - loss: 0.0021 - precision_15: 0.9527 - recall_15: 0.8355\n",
            "Epoch 28/45\n",
            "\u001b[1m4154/4154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 2ms/step - accuracy: 0.0012 - auc_15: 0.9409 - loss: 0.0018 - precision_15: 0.9339 - recall_15: 0.8098\n",
            "Epoch 29/45\n",
            "\u001b[1m4154/4154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 3ms/step - accuracy: 0.0021 - auc_15: 0.9464 - loss: 0.0029 - precision_15: 0.9248 - recall_15: 0.7385\n",
            "Epoch 30/45\n",
            "\u001b[1m4154/4154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 2ms/step - accuracy: 0.0024 - auc_15: 0.9725 - loss: 0.0018 - precision_15: 0.9498 - recall_15: 0.8390\n",
            "Epoch 31/45\n",
            "\u001b[1m4154/4154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 2ms/step - accuracy: 0.0038 - auc_15: 0.9683 - loss: 0.0021 - precision_15: 0.9583 - recall_15: 0.7782\n",
            "Epoch 32/45\n",
            "\u001b[1m4154/4154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 3ms/step - accuracy: 0.0011 - auc_15: 0.9598 - loss: 0.0034 - precision_15: 0.9344 - recall_15: 0.8244\n",
            "Epoch 33/45\n",
            "\u001b[1m4154/4154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 2ms/step - accuracy: 0.0019 - auc_15: 0.9770 - loss: 0.0017 - precision_15: 0.9643 - recall_15: 0.8264\n",
            "Epoch 34/45\n",
            "\u001b[1m4154/4154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 2ms/step - accuracy: 0.0046 - auc_15: 0.9620 - loss: 0.0020 - precision_15: 0.9113 - recall_15: 0.8068\n",
            "Epoch 35/45\n",
            "\u001b[1m4154/4154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 3ms/step - accuracy: 0.0068 - auc_15: 0.9620 - loss: 0.0028 - precision_15: 0.9447 - recall_15: 0.8561\n",
            "Epoch 36/45\n",
            "\u001b[1m4154/4154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 2ms/step - accuracy: 0.0046 - auc_15: 0.9713 - loss: 0.0028 - precision_15: 0.9184 - recall_15: 0.8041\n",
            "Epoch 37/45\n",
            "\u001b[1m4154/4154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 2ms/step - accuracy: 0.0019 - auc_15: 0.9686 - loss: 0.0022 - precision_15: 0.9680 - recall_15: 0.8369\n",
            "Epoch 38/45\n",
            "\u001b[1m4154/4154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 3ms/step - accuracy: 0.0017 - auc_15: 0.9693 - loss: 0.0021 - precision_15: 0.9567 - recall_15: 0.8090\n",
            "Epoch 39/45\n",
            "\u001b[1m4154/4154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 2ms/step - accuracy: 0.0062 - auc_15: 0.9641 - loss: 0.0028 - precision_15: 0.9437 - recall_15: 0.8339\n",
            "Epoch 40/45\n",
            "\u001b[1m4154/4154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 2ms/step - accuracy: 0.0062 - auc_15: 0.9629 - loss: 0.0020 - precision_15: 0.9535 - recall_15: 0.8224\n",
            "Epoch 41/45\n",
            "\u001b[1m4154/4154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 3ms/step - accuracy: 0.0077 - auc_15: 0.9711 - loss: 0.0016 - precision_15: 0.9706 - recall_15: 0.8700\n",
            "Epoch 42/45\n",
            "\u001b[1m4154/4154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 2ms/step - accuracy: 0.0128 - auc_15: 0.9639 - loss: 0.0019 - precision_15: 0.9385 - recall_15: 0.7995\n",
            "Epoch 43/45\n",
            "\u001b[1m4154/4154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 3ms/step - accuracy: 0.0177 - auc_15: 0.9858 - loss: 0.0015 - precision_15: 0.9497 - recall_15: 0.9109\n",
            "Epoch 44/45\n",
            "\u001b[1m4154/4154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 3ms/step - accuracy: 0.0714 - auc_15: 0.9711 - loss: 0.0016 - precision_15: 0.9314 - recall_15: 0.8730\n",
            "Epoch 45/45\n",
            "\u001b[1m4154/4154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 2ms/step - accuracy: 0.0616 - auc_15: 0.9815 - loss: 0.0017 - precision_15: 0.9641 - recall_15: 0.8624\n",
            "\u001b[1m2077/2077\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step\n",
            "[CV] END batch_size=32, epochs=45, model__learn_rate=0.001, model__optimizer=adam; total time= 9.3min\n",
            "Epoch 1/45\n",
            "\u001b[1m4154/4154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 2ms/step - accuracy: 0.0519 - auc_16: 0.7526 - loss: 0.0407 - precision_16: 0.6149 - recall_16: 0.3516\n",
            "Epoch 2/45\n",
            "\u001b[1m4154/4154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 3ms/step - accuracy: 0.0064 - auc_16: 0.8860 - loss: 0.0139 - precision_16: 0.8708 - recall_16: 0.6319\n",
            "Epoch 3/45\n",
            "\u001b[1m4154/4154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 2ms/step - accuracy: 0.0026 - auc_16: 0.9134 - loss: 0.0069 - precision_16: 0.8368 - recall_16: 0.7241\n",
            "Epoch 4/45\n",
            "\u001b[1m4154/4154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 3ms/step - accuracy: 0.0024 - auc_16: 0.9112 - loss: 0.0067 - precision_16: 0.8201 - recall_16: 0.6663\n",
            "Epoch 5/45\n",
            "\u001b[1m4154/4154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 2ms/step - accuracy: 0.0010 - auc_16: 0.9186 - loss: 0.0057 - precision_16: 0.8472 - recall_16: 0.6968\n",
            "Epoch 6/45\n",
            "\u001b[1m4154/4154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 2ms/step - accuracy: 0.0018 - auc_16: 0.9469 - loss: 0.0065 - precision_16: 0.8309 - recall_16: 0.7026\n",
            "Epoch 7/45\n",
            "\u001b[1m4154/4154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 3ms/step - accuracy: 2.5996e-04 - auc_16: 0.9495 - loss: 0.0032 - precision_16: 0.8837 - recall_16: 0.8113\n",
            "Epoch 8/45\n",
            "\u001b[1m4154/4154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 2ms/step - accuracy: 5.4387e-04 - auc_16: 0.9450 - loss: 0.0048 - precision_16: 0.8687 - recall_16: 0.7075\n",
            "Epoch 9/45\n",
            "\u001b[1m4154/4154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 2ms/step - accuracy: 8.8854e-04 - auc_16: 0.9487 - loss: 0.0037 - precision_16: 0.8803 - recall_16: 0.7509\n",
            "Epoch 10/45\n",
            "\u001b[1m4154/4154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 3ms/step - accuracy: 5.3648e-04 - auc_16: 0.9592 - loss: 0.0032 - precision_16: 0.8840 - recall_16: 0.7942\n",
            "Epoch 11/45\n",
            "\u001b[1m4154/4154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 3ms/step - accuracy: 3.1594e-04 - auc_16: 0.9523 - loss: 0.0037 - precision_16: 0.9238 - recall_16: 0.7941\n",
            "Epoch 12/45\n",
            "\u001b[1m4154/4154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 4ms/step - accuracy: 1.3355e-04 - auc_16: 0.9415 - loss: 0.0033 - precision_16: 0.8361 - recall_16: 0.7580\n",
            "Epoch 13/45\n",
            "\u001b[1m4154/4154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 2ms/step - accuracy: 0.0145 - auc_16: 0.9469 - loss: 0.0035 - precision_16: 0.8923 - recall_16: 0.7798\n",
            "Epoch 14/45\n",
            "\u001b[1m4154/4154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 3ms/step - accuracy: 5.6850e-04 - auc_16: 0.9121 - loss: 0.0032 - precision_16: 0.8935 - recall_16: 0.6781\n",
            "Epoch 15/45\n",
            "\u001b[1m4154/4154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 2ms/step - accuracy: 2.9001e-05 - auc_16: 0.9424 - loss: 0.0029 - precision_16: 0.9218 - recall_16: 0.7825\n",
            "Epoch 16/45\n",
            "\u001b[1m4154/4154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 2ms/step - accuracy: 2.0086e-04 - auc_16: 0.9437 - loss: 0.0036 - precision_16: 0.9168 - recall_16: 0.7825\n",
            "Epoch 17/45\n",
            "\u001b[1m4154/4154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 3ms/step - accuracy: 4.6820e-04 - auc_16: 0.9628 - loss: 0.0023 - precision_16: 0.9057 - recall_16: 0.8150\n",
            "Epoch 18/45\n",
            "\u001b[1m4154/4154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 2ms/step - accuracy: 1.2756e-04 - auc_16: 0.9483 - loss: 0.0024 - precision_16: 0.9387 - recall_16: 0.8283\n",
            "Epoch 19/45\n",
            "\u001b[1m4154/4154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 2ms/step - accuracy: 7.7147e-04 - auc_16: 0.9558 - loss: 0.0028 - precision_16: 0.9448 - recall_16: 0.8219\n",
            "Epoch 20/45\n",
            "\u001b[1m4154/4154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 3ms/step - accuracy: 2.3920e-04 - auc_16: 0.9477 - loss: 0.0031 - precision_16: 0.9046 - recall_16: 0.7455\n",
            "Epoch 21/45\n",
            "\u001b[1m4154/4154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 3ms/step - accuracy: 3.8734e-04 - auc_16: 0.9717 - loss: 0.0025 - precision_16: 0.9129 - recall_16: 0.8285\n",
            "Epoch 22/45\n",
            "\u001b[1m4154/4154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 2ms/step - accuracy: 2.7017e-04 - auc_16: 0.9338 - loss: 0.0027 - precision_16: 0.9199 - recall_16: 0.7523\n",
            "Epoch 23/45\n",
            "\u001b[1m4154/4154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 3ms/step - accuracy: 2.3726e-04 - auc_16: 0.9585 - loss: 0.0039 - precision_16: 0.9274 - recall_16: 0.7415\n",
            "Epoch 24/45\n",
            "\u001b[1m4154/4154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 2ms/step - accuracy: 5.4333e-04 - auc_16: 0.9560 - loss: 0.0028 - precision_16: 0.9022 - recall_16: 0.7994\n",
            "Epoch 25/45\n",
            "\u001b[1m4154/4154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 3ms/step - accuracy: 6.1476e-04 - auc_16: 0.9617 - loss: 0.0026 - precision_16: 0.9090 - recall_16: 0.8366\n",
            "Epoch 26/45\n",
            "\u001b[1m4154/4154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 2ms/step - accuracy: 2.5621e-04 - auc_16: 0.9605 - loss: 0.0026 - precision_16: 0.9472 - recall_16: 0.8252\n",
            "Epoch 27/45\n",
            "\u001b[1m4154/4154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 2ms/step - accuracy: 6.0749e-04 - auc_16: 0.9719 - loss: 0.0025 - precision_16: 0.9465 - recall_16: 0.8057\n",
            "Epoch 28/45\n",
            "\u001b[1m4154/4154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 3ms/step - accuracy: 2.4372e-04 - auc_16: 0.9715 - loss: 0.0030 - precision_16: 0.9575 - recall_16: 0.8509\n",
            "Epoch 29/45\n",
            "\u001b[1m4154/4154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 2ms/step - accuracy: 0.0014 - auc_16: 0.9735 - loss: 0.0025 - precision_16: 0.9260 - recall_16: 0.7914\n",
            "Epoch 30/45\n",
            "\u001b[1m4154/4154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 2ms/step - accuracy: 8.5469e-04 - auc_16: 0.9742 - loss: 0.0017 - precision_16: 0.9320 - recall_16: 0.8315\n",
            "Epoch 31/45\n",
            "\u001b[1m4154/4154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 3ms/step - accuracy: 0.0034 - auc_16: 0.9702 - loss: 0.0018 - precision_16: 0.9557 - recall_16: 0.8806\n",
            "Epoch 32/45\n",
            "\u001b[1m4154/4154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 2ms/step - accuracy: 0.0026 - auc_16: 0.9477 - loss: 0.0038 - precision_16: 0.9307 - recall_16: 0.7522\n",
            "Epoch 33/45\n",
            "\u001b[1m4154/4154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 2ms/step - accuracy: 0.0022 - auc_16: 0.9544 - loss: 0.0032 - precision_16: 0.8773 - recall_16: 0.8261\n",
            "Epoch 34/45\n",
            "\u001b[1m4154/4154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 3ms/step - accuracy: 0.0024 - auc_16: 0.9476 - loss: 0.0053 - precision_16: 0.9489 - recall_16: 0.8393\n",
            "Epoch 35/45\n",
            "\u001b[1m4154/4154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 2ms/step - accuracy: 4.8001e-04 - auc_16: 0.9512 - loss: 0.0030 - precision_16: 0.8981 - recall_16: 0.8393\n",
            "Epoch 36/45\n",
            "\u001b[1m4154/4154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 3ms/step - accuracy: 0.0010 - auc_16: 0.9647 - loss: 0.0020 - precision_16: 0.9306 - recall_16: 0.8505\n",
            "Epoch 37/45\n",
            "\u001b[1m4154/4154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 3ms/step - accuracy: 5.7402e-04 - auc_16: 0.9559 - loss: 0.0027 - precision_16: 0.9499 - recall_16: 0.8100\n",
            "Epoch 38/45\n",
            "\u001b[1m4154/4154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 3ms/step - accuracy: 4.8883e-04 - auc_16: 0.9600 - loss: 0.0019 - precision_16: 0.9657 - recall_16: 0.8599\n",
            "Epoch 39/45\n",
            "\u001b[1m4154/4154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 2ms/step - accuracy: 0.0010 - auc_16: 0.9724 - loss: 0.0019 - precision_16: 0.9187 - recall_16: 0.8504\n",
            "Epoch 40/45\n",
            "\u001b[1m4154/4154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 3ms/step - accuracy: 6.2037e-04 - auc_16: 0.9710 - loss: 0.0021 - precision_16: 0.9482 - recall_16: 0.8246\n",
            "Epoch 41/45\n",
            "\u001b[1m4154/4154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 2ms/step - accuracy: 8.6852e-04 - auc_16: 0.9647 - loss: 0.0020 - precision_16: 0.9621 - recall_16: 0.8877\n",
            "Epoch 42/45\n",
            "\u001b[1m4154/4154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 3ms/step - accuracy: 0.0017 - auc_16: 0.9690 - loss: 0.0016 - precision_16: 0.9320 - recall_16: 0.8405\n",
            "Epoch 43/45\n",
            "\u001b[1m4154/4154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 2ms/step - accuracy: 0.0015 - auc_16: 0.9650 - loss: 0.0023 - precision_16: 0.9581 - recall_16: 0.8778\n",
            "Epoch 44/45\n",
            "\u001b[1m4154/4154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 2ms/step - accuracy: 0.0024 - auc_16: 0.9486 - loss: 0.0024 - precision_16: 0.9192 - recall_16: 0.8024\n",
            "Epoch 45/45\n",
            "\u001b[1m4154/4154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 3ms/step - accuracy: 0.0016 - auc_16: 0.9565 - loss: 0.0019 - precision_16: 0.9220 - recall_16: 0.8500\n",
            "\u001b[1m2077/2077\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step\n",
            "[CV] END batch_size=32, epochs=45, model__learn_rate=0.001, model__optimizer=adam; total time= 9.3min\n",
            "Epoch 1/30\n",
            "\u001b[1m1039/1039\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.0778 - auc_17: 0.7997 - loss: 0.0542 - precision_17: 0.3759 - recall_17: 0.3907\n",
            "Epoch 2/30\n",
            "\u001b[1m1039/1039\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.0025 - auc_17: 0.9221 - loss: 0.0071 - precision_17: 0.8971 - recall_17: 0.5610\n",
            "Epoch 3/30\n",
            "\u001b[1m1039/1039\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.0099 - auc_17: 0.8879 - loss: 0.0158 - precision_17: 0.8090 - recall_17: 0.4277\n",
            "Epoch 4/30\n",
            "\u001b[1m1039/1039\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 2.8817e-04 - auc_17: 0.9447 - loss: 0.0046 - precision_17: 0.8950 - recall_17: 0.6613\n",
            "Epoch 5/30\n",
            "\u001b[1m1039/1039\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.0053 - auc_17: 0.8515 - loss: 0.0138 - precision_17: 0.6283 - recall_17: 0.5329\n",
            "Epoch 6/30\n",
            "\u001b[1m1039/1039\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.0422 - auc_17: 0.8061 - loss: 0.0071 - precision_17: 0.8034 - recall_17: 0.5060\n",
            "Epoch 7/30\n",
            "\u001b[1m1039/1039\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.0833 - auc_17: 0.8296 - loss: 0.0059 - precision_17: 0.8515 - recall_17: 0.5459\n",
            "Epoch 8/30\n",
            "\u001b[1m1039/1039\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.0955 - auc_17: 0.8613 - loss: 0.0052 - precision_17: 0.8644 - recall_17: 0.5749\n",
            "Epoch 9/30\n",
            "\u001b[1m1039/1039\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.1261 - auc_17: 0.8705 - loss: 0.0051 - precision_17: 0.8947 - recall_17: 0.5833\n",
            "Epoch 10/30\n",
            "\u001b[1m1039/1039\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.1386 - auc_17: 0.8775 - loss: 0.0049 - precision_17: 0.8833 - recall_17: 0.6324\n",
            "Epoch 11/30\n",
            "\u001b[1m1039/1039\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - accuracy: 0.1677 - auc_17: 0.8799 - loss: 0.0047 - precision_17: 0.9080 - recall_17: 0.6368\n",
            "Epoch 12/30\n",
            "\u001b[1m1039/1039\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.1968 - auc_17: 0.8426 - loss: 0.0059 - precision_17: 0.8878 - recall_17: 0.5939\n",
            "Epoch 13/30\n",
            "\u001b[1m1039/1039\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.1495 - auc_17: 0.4995 - loss: 0.0120 - precision_17: 0.0000e+00 - recall_17: 0.0000e+00\n",
            "Epoch 14/30\n",
            "\u001b[1m1039/1039\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.2177 - auc_17: 0.4947 - loss: 0.0116 - precision_17: 0.0000e+00 - recall_17: 0.0000e+00\n",
            "Epoch 15/30\n",
            "\u001b[1m1039/1039\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4ms/step - accuracy: 0.1654 - auc_17: 0.4986 - loss: 0.0125 - precision_17: 0.0000e+00 - recall_17: 0.0000e+00\n",
            "Epoch 16/30\n",
            "\u001b[1m1039/1039\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.2152 - auc_17: 0.5000 - loss: 0.0131 - precision_17: 0.0000e+00 - recall_17: 0.0000e+00\n",
            "Epoch 17/30\n",
            "\u001b[1m1039/1039\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.1660 - auc_17: 0.5000 - loss: 0.0177 - precision_17: 0.0000e+00 - recall_17: 0.0000e+00\n",
            "Epoch 18/30\n",
            "\u001b[1m1039/1039\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.1585 - auc_17: 0.4995 - loss: 0.0127 - precision_17: 0.0000e+00 - recall_17: 0.0000e+00\n",
            "Epoch 19/30\n",
            "\u001b[1m1039/1039\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.1865 - auc_17: 0.4995 - loss: 0.0133 - precision_17: 0.0000e+00 - recall_17: 0.0000e+00\n",
            "Epoch 20/30\n",
            "\u001b[1m1039/1039\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - accuracy: 0.1809 - auc_17: 0.4885 - loss: 1.2126 - precision_17: 0.0000e+00 - recall_17: 0.0000e+00\n",
            "Epoch 21/30\n",
            "\u001b[1m1039/1039\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.0909 - auc_17: 0.4981 - loss: 0.0128 - precision_17: 0.0000e+00 - recall_17: 0.0000e+00\n",
            "Epoch 22/30\n",
            "\u001b[1m1039/1039\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.0824 - auc_17: 0.5000 - loss: 0.0134 - precision_17: 0.0000e+00 - recall_17: 0.0000e+00\n",
            "Epoch 23/30\n",
            "\u001b[1m1039/1039\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.0785 - auc_17: 0.4995 - loss: 0.0135 - precision_17: 0.0000e+00 - recall_17: 0.0000e+00\n",
            "Epoch 24/30\n",
            "\u001b[1m1039/1039\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.0954 - auc_17: 0.4971 - loss: 0.0128 - precision_17: 0.0000e+00 - recall_17: 0.0000e+00\n",
            "Epoch 25/30\n",
            "\u001b[1m1039/1039\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - accuracy: 0.1460 - auc_17: 0.5000 - loss: 0.0177 - precision_17: 0.0000e+00 - recall_17: 0.0000e+00\n",
            "Epoch 26/30\n",
            "\u001b[1m1039/1039\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.0657 - auc_17: 0.4990 - loss: 0.0131 - precision_17: 0.0000e+00 - recall_17: 0.0000e+00\n",
            "Epoch 27/30\n",
            "\u001b[1m1039/1039\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.0708 - auc_17: 0.4981 - loss: 0.0131 - precision_17: 0.0000e+00 - recall_17: 0.0000e+00\n",
            "Epoch 28/30\n",
            "\u001b[1m1039/1039\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.0808 - auc_17: 0.4995 - loss: 0.0132 - precision_17: 0.0000e+00 - recall_17: 0.0000e+00\n",
            "Epoch 29/30\n",
            "\u001b[1m1039/1039\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.2694 - auc_17: 0.4988 - loss: 0.3670 - precision_17: 0.0000e+00 - recall_17: 0.0000e+00\n",
            "Epoch 30/30\n",
            "\u001b[1m1039/1039\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - accuracy: 0.0981 - auc_17: 0.5000 - loss: 0.0146 - precision_17: 0.0000e+00 - recall_17: 0.0000e+00\n",
            "\u001b[1m520/520\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step\n",
            "[CV] END batch_size=128, epochs=30, model__learn_rate=0.01, model__optimizer=adam; total time= 1.7min\n",
            "Epoch 1/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning:\n",
            "\n",
            "Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1039/1039\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.0405 - auc_18: 0.8291 - loss: 0.0531 - precision_18: 0.3101 - recall_18: 0.4968\n",
            "Epoch 2/30\n",
            "\u001b[1m1039/1039\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.0022 - auc_18: 0.8991 - loss: 0.0085 - precision_18: 0.8494 - recall_18: 0.6369\n",
            "Epoch 3/30\n",
            "\u001b[1m1039/1039\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.0028 - auc_18: 0.9217 - loss: 0.0052 - precision_18: 0.8719 - recall_18: 0.6674\n",
            "Epoch 4/30\n",
            "\u001b[1m1039/1039\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - accuracy: 8.0897e-04 - auc_18: 0.9155 - loss: 0.0056 - precision_18: 0.8223 - recall_18: 0.6051\n",
            "Epoch 5/30\n",
            "\u001b[1m1039/1039\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.0496 - auc_18: 0.8991 - loss: 0.0141 - precision_18: 0.6528 - recall_18: 0.4892\n",
            "Epoch 6/30\n",
            "\u001b[1m1039/1039\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.0145 - auc_18: 0.9067 - loss: 0.0065 - precision_18: 0.8958 - recall_18: 0.5543\n",
            "Epoch 7/30\n",
            "\u001b[1m1039/1039\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.0012 - auc_18: 0.9390 - loss: 0.0051 - precision_18: 0.8561 - recall_18: 0.6701\n",
            "Epoch 8/30\n",
            "\u001b[1m1039/1039\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.0189 - auc_18: 0.8637 - loss: 0.0067 - precision_18: 0.8435 - recall_18: 0.5092\n",
            "Epoch 9/30\n",
            "\u001b[1m1039/1039\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - accuracy: 0.0325 - auc_18: 0.6050 - loss: 0.0121 - precision_18: 0.4973 - recall_18: 0.1298\n",
            "Epoch 10/30\n",
            "\u001b[1m1039/1039\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.1757 - auc_18: 0.7920 - loss: 0.0077 - precision_18: 0.8198 - recall_18: 0.4187\n",
            "Epoch 11/30\n",
            "\u001b[1m1039/1039\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.3215 - auc_18: 0.5158 - loss: 0.0155 - precision_18: 0.0000e+00 - recall_18: 0.0000e+00\n",
            "Epoch 12/30\n",
            "\u001b[1m1039/1039\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.2848 - auc_18: 0.5886 - loss: 0.0209 - precision_18: 0.0000e+00 - recall_18: 0.0000e+00\n",
            "Epoch 13/30\n",
            "\u001b[1m1039/1039\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.2653 - auc_18: 0.5037 - loss: 0.0121 - precision_18: 0.0000e+00 - recall_18: 0.0000e+00\n",
            "Epoch 14/30\n",
            "\u001b[1m1039/1039\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - accuracy: 0.3538 - auc_18: 0.5023 - loss: 0.1786 - precision_18: 0.0000e+00 - recall_18: 0.0000e+00\n",
            "Epoch 15/30\n",
            "\u001b[1m1039/1039\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.3590 - auc_18: 0.4995 - loss: 0.0159 - precision_18: 0.0000e+00 - recall_18: 0.0000e+00\n",
            "Epoch 16/30\n",
            "\u001b[1m1039/1039\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.3250 - auc_18: 0.6186 - loss: 0.0138 - precision_18: 0.0000e+00 - recall_18: 0.0000e+00\n",
            "Epoch 17/30\n",
            "\u001b[1m1039/1039\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.0506 - auc_18: 0.4990 - loss: 0.0140 - precision_18: 0.0000e+00 - recall_18: 0.0000e+00\n",
            "Epoch 18/30\n",
            "\u001b[1m1039/1039\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.2644 - auc_18: 0.4995 - loss: 0.0220 - precision_18: 0.0000e+00 - recall_18: 0.0000e+00\n",
            "Epoch 19/30\n",
            "\u001b[1m1039/1039\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - accuracy: 0.1581 - auc_18: 0.4970 - loss: 0.0224 - precision_18: 0.0000e+00 - recall_18: 0.0000e+00\n",
            "Epoch 20/30\n",
            "\u001b[1m1039/1039\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.2396 - auc_18: 0.4995 - loss: 0.0134 - precision_18: 0.0000e+00 - recall_18: 0.0000e+00\n",
            "Epoch 21/30\n",
            "\u001b[1m1039/1039\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.2658 - auc_18: 0.5000 - loss: 0.0120 - precision_18: 0.0000e+00 - recall_18: 0.0000e+00\n",
            "Epoch 22/30\n",
            "\u001b[1m1039/1039\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.3935 - auc_18: 0.4961 - loss: 0.0324 - precision_18: 0.0000e+00 - recall_18: 0.0000e+00\n",
            "Epoch 23/30\n",
            "\u001b[1m1039/1039\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.2188 - auc_18: 0.4966 - loss: 0.0193 - precision_18: 0.0000e+00 - recall_18: 0.0000e+00\n",
            "Epoch 24/30\n",
            "\u001b[1m1039/1039\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - accuracy: 0.1723 - auc_18: 0.4976 - loss: 0.0132 - precision_18: 0.0000e+00 - recall_18: 0.0000e+00\n",
            "Epoch 25/30\n",
            "\u001b[1m1039/1039\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.1806 - auc_18: 0.4947 - loss: 0.0133 - precision_18: 0.0000e+00 - recall_18: 0.0000e+00\n",
            "Epoch 26/30\n",
            "\u001b[1m1039/1039\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.2616 - auc_18: 0.4952 - loss: 0.2186 - precision_18: 0.0000e+00 - recall_18: 0.0000e+00\n",
            "Epoch 27/30\n",
            "\u001b[1m1039/1039\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.2447 - auc_18: 0.4971 - loss: 0.0203 - precision_18: 0.0000e+00 - recall_18: 0.0000e+00\n",
            "Epoch 28/30\n",
            "\u001b[1m1039/1039\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.2405 - auc_18: 0.5000 - loss: 0.0131 - precision_18: 0.0000e+00 - recall_18: 0.0000e+00\n",
            "Epoch 29/30\n",
            "\u001b[1m1039/1039\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - accuracy: 0.3132 - auc_18: 0.4986 - loss: 0.0137 - precision_18: 0.0000e+00 - recall_18: 0.0000e+00\n",
            "Epoch 30/30\n",
            "\u001b[1m1039/1039\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.2910 - auc_18: 0.4961 - loss: 0.0263 - precision_18: 0.0000e+00 - recall_18: 0.0000e+00\n",
            "\u001b[1m520/520\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step\n",
            "[CV] END batch_size=128, epochs=30, model__learn_rate=0.01, model__optimizer=adam; total time= 1.6min\n",
            "Epoch 1/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning:\n",
            "\n",
            "Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1039/1039\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.0400 - auc_19: 0.7840 - loss: 0.1034 - precision_19: 0.1761 - recall_19: 0.1800\n",
            "Epoch 2/30\n",
            "\u001b[1m1039/1039\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.0019 - auc_19: 0.8940 - loss: 0.0090 - precision_19: 0.0000e+00 - recall_19: 0.0000e+00\n",
            "Epoch 3/30\n",
            "\u001b[1m1039/1039\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.0015 - auc_19: 0.9230 - loss: 0.0069 - precision_19: 0.0000e+00 - recall_19: 0.0000e+00\n",
            "Epoch 4/30\n",
            "\u001b[1m1039/1039\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.0018 - auc_19: 0.9531 - loss: 0.0051 - precision_19: 0.4983 - recall_19: 0.1312\n",
            "Epoch 5/30\n",
            "\u001b[1m1039/1039\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 5.2730e-04 - auc_19: 0.9245 - loss: 0.0060 - precision_19: 0.8689 - recall_19: 0.5532\n",
            "Epoch 6/30\n",
            "\u001b[1m1039/1039\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.0056 - auc_19: 0.9329 - loss: 0.0055 - precision_19: 0.8821 - recall_19: 0.5741\n",
            "Epoch 7/30\n",
            "\u001b[1m1039/1039\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.0015 - auc_19: 0.8913 - loss: 0.0057 - precision_19: 0.8040 - recall_19: 0.4376\n",
            "Epoch 8/30\n",
            "\u001b[1m1039/1039\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - accuracy: 9.9037e-05 - auc_19: 0.8907 - loss: 0.0046 - precision_19: 0.8893 - recall_19: 0.6114\n",
            "Epoch 9/30\n",
            "\u001b[1m1039/1039\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 4.0965e-04 - auc_19: 0.9226 - loss: 0.0036 - precision_19: 0.8770 - recall_19: 0.6197\n",
            "Epoch 10/30\n",
            "\u001b[1m1039/1039\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.0017 - auc_19: 0.9301 - loss: 0.0043 - precision_19: 0.8888 - recall_19: 0.7241\n",
            "Epoch 11/30\n",
            "\u001b[1m1039/1039\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 9.5441e-05 - auc_19: 0.9243 - loss: 0.0043 - precision_19: 0.8622 - recall_19: 0.6400\n",
            "Epoch 12/30\n",
            "\u001b[1m1039/1039\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.0070 - auc_19: 0.9227 - loss: 0.0044 - precision_19: 0.8386 - recall_19: 0.6516\n",
            "Epoch 13/30\n",
            "\u001b[1m1039/1039\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.0798 - auc_19: 0.9221 - loss: 0.0091 - precision_19: 0.7650 - recall_19: 0.3591\n",
            "Epoch 14/30\n",
            "\u001b[1m1039/1039\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.0249 - auc_19: 0.8915 - loss: 0.0048 - precision_19: 0.8135 - recall_19: 0.5722\n",
            "Epoch 15/30\n",
            "\u001b[1m1039/1039\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.0211 - auc_19: 0.9031 - loss: 0.0037 - precision_19: 0.9160 - recall_19: 0.7242\n",
            "Epoch 16/30\n",
            "\u001b[1m1039/1039\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.0272 - auc_19: 0.9143 - loss: 0.0036 - precision_19: 0.8866 - recall_19: 0.6879\n",
            "Epoch 17/30\n",
            "\u001b[1m1039/1039\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.0863 - auc_19: 0.8924 - loss: 0.0080 - precision_19: 0.8582 - recall_19: 0.6716\n",
            "Epoch 18/30\n",
            "\u001b[1m1039/1039\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.0308 - auc_19: 0.8944 - loss: 0.0045 - precision_19: 0.8410 - recall_19: 0.5763\n",
            "Epoch 19/30\n",
            "\u001b[1m1039/1039\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.0338 - auc_19: 0.9041 - loss: 0.0046 - precision_19: 0.8463 - recall_19: 0.6435\n",
            "Epoch 20/30\n",
            "\u001b[1m1039/1039\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.0870 - auc_19: 0.9240 - loss: 0.0036 - precision_19: 0.8678 - recall_19: 0.7145\n",
            "Epoch 21/30\n",
            "\u001b[1m1039/1039\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.0921 - auc_19: 0.9168 - loss: 0.0038 - precision_19: 0.8831 - recall_19: 0.6327\n",
            "Epoch 22/30\n",
            "\u001b[1m1039/1039\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.0250 - auc_19: 0.8874 - loss: 0.0120 - precision_19: 0.7379 - recall_19: 0.6699\n",
            "Epoch 23/30\n",
            "\u001b[1m1039/1039\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.1612 - auc_19: 0.8973 - loss: 0.0161 - precision_19: 0.8372 - recall_19: 0.5573\n",
            "Epoch 24/30\n",
            "\u001b[1m1039/1039\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.1790 - auc_19: 0.8868 - loss: 0.0077 - precision_19: 0.2090 - recall_19: 0.0365\n",
            "Epoch 25/30\n",
            "\u001b[1m1039/1039\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.1283 - auc_19: 0.8779 - loss: 0.0074 - precision_19: 0.5970 - recall_19: 0.4858\n",
            "Epoch 26/30\n",
            "\u001b[1m1039/1039\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.0873 - auc_19: 0.8546 - loss: 0.0105 - precision_19: 0.8414 - recall_19: 0.7092\n",
            "Epoch 27/30\n",
            "\u001b[1m1039/1039\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.1023 - auc_19: 0.8852 - loss: 0.0045 - precision_19: 0.7992 - recall_19: 0.7640\n",
            "Epoch 28/30\n",
            "\u001b[1m1039/1039\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.2098 - auc_19: 0.8737 - loss: 0.0119 - precision_19: 0.8346 - recall_19: 0.7327\n",
            "Epoch 29/30\n",
            "\u001b[1m1039/1039\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.3037 - auc_19: 0.8526 - loss: 0.0102 - precision_19: 0.8370 - recall_19: 0.7159\n",
            "Epoch 30/30\n",
            "\u001b[1m1039/1039\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.3000 - auc_19: 0.8834 - loss: 0.0042 - precision_19: 0.8489 - recall_19: 0.7681\n",
            "\u001b[1m520/520\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step\n",
            "[CV] END batch_size=128, epochs=30, model__learn_rate=0.01, model__optimizer=adam; total time= 1.5min\n",
            "Otimizador não reconhecido\n",
            "[CV] END batch_size=32, epochs=20, model__learn_rate=0.1, model__optimizer=rmsprop; total time=   0.1s\n",
            "Otimizador não reconhecido\n",
            "[CV] END batch_size=32, epochs=20, model__learn_rate=0.1, model__optimizer=rmsprop; total time=   0.1s\n",
            "Otimizador não reconhecido\n",
            "[CV] END batch_size=32, epochs=20, model__learn_rate=0.1, model__optimizer=rmsprop; total time=   0.1s\n",
            "Otimizador não reconhecido\n",
            "[CV] END batch_size=32, epochs=45, model__learn_rate=0.1, model__optimizer=rmsprop; total time=   0.1s\n",
            "Otimizador não reconhecido\n",
            "[CV] END batch_size=32, epochs=45, model__learn_rate=0.1, model__optimizer=rmsprop; total time=   0.1s\n",
            "Otimizador não reconhecido\n",
            "[CV] END batch_size=32, epochs=45, model__learn_rate=0.1, model__optimizer=rmsprop; total time=   0.1s\n",
            "Epoch 1/45\n",
            "\u001b[1m1039/1039\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.1295 - auc_20: 0.5396 - loss: 1.2109 - precision_20: 0.0000e+00 - recall_20: 0.0000e+00\n",
            "Epoch 2/45\n",
            "\u001b[1m1039/1039\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 2.9508e-06 - auc_20: 0.4962 - loss: 0.0131 - precision_20: 0.0000e+00 - recall_20: 0.0000e+00\n",
            "Epoch 3/45\n",
            "\u001b[1m1039/1039\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 3.8086e-05 - auc_20: 0.4995 - loss: 0.0124 - precision_20: 0.0000e+00 - recall_20: 0.0000e+00\n",
            "Epoch 4/45\n",
            "\u001b[1m1039/1039\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 4.3202e-05 - auc_20: 0.5000 - loss: 0.0137 - precision_20: 0.0000e+00 - recall_20: 0.0000e+00\n",
            "Epoch 5/45\n",
            "\u001b[1m1039/1039\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.0123 - auc_20: 0.4990 - loss: 0.0778 - precision_20: 0.0000e+00 - recall_20: 0.0000e+00\n",
            "Epoch 6/45\n",
            "\u001b[1m1039/1039\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.0000e+00 - auc_20: 0.4995 - loss: 0.0135 - precision_20: 0.0000e+00 - recall_20: 0.0000e+00\n",
            "Epoch 7/45\n",
            "\u001b[1m1039/1039\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.0000e+00 - auc_20: 0.5000 - loss: 0.0147 - precision_20: 0.0000e+00 - recall_20: 0.0000e+00\n",
            "Epoch 8/45\n",
            "\u001b[1m1039/1039\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.0000e+00 - auc_20: 0.4966 - loss: 0.0137 - precision_20: 0.0000e+00 - recall_20: 0.0000e+00\n",
            "Epoch 9/45\n",
            "\u001b[1m1039/1039\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 7.3305e-05 - auc_20: 0.5000 - loss: 0.0132 - precision_20: 0.0000e+00 - recall_20: 0.0000e+00\n",
            "Epoch 10/45\n",
            "\u001b[1m1039/1039\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.0000e+00 - auc_20: 0.4990 - loss: 0.0127 - precision_20: 0.0000e+00 - recall_20: 0.0000e+00\n",
            "Epoch 11/45\n",
            "\u001b[1m1039/1039\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.0000e+00 - auc_20: 0.4995 - loss: 0.0132 - precision_20: 0.0000e+00 - recall_20: 0.0000e+00\n",
            "Epoch 12/45\n",
            "\u001b[1m1039/1039\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.0000e+00 - auc_20: 0.4981 - loss: 0.0139 - precision_20: 0.0000e+00 - recall_20: 0.0000e+00\n",
            "Epoch 13/45\n",
            "\u001b[1m1039/1039\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.0000e+00 - auc_20: 0.4966 - loss: 0.0127 - precision_20: 0.0000e+00 - recall_20: 0.0000e+00\n",
            "Epoch 14/45\n",
            "\u001b[1m1039/1039\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.0000e+00 - auc_20: 0.5000 - loss: 0.0135 - precision_20: 0.0000e+00 - recall_20: 0.0000e+00\n",
            "Epoch 15/45\n",
            "\u001b[1m1039/1039\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.0000e+00 - auc_20: 0.4990 - loss: 0.0131 - precision_20: 0.0000e+00 - recall_20: 0.0000e+00\n",
            "Epoch 16/45\n",
            "\u001b[1m1039/1039\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.0000e+00 - auc_20: 0.4962 - loss: 0.0130 - precision_20: 0.0000e+00 - recall_20: 0.0000e+00\n",
            "Epoch 17/45\n",
            "\u001b[1m1039/1039\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.0000e+00 - auc_20: 0.4962 - loss: 0.0123 - precision_20: 0.0000e+00 - recall_20: 0.0000e+00\n",
            "Epoch 18/45\n",
            "\u001b[1m1039/1039\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.0000e+00 - auc_20: 0.4947 - loss: 0.0129 - precision_20: 0.0000e+00 - recall_20: 0.0000e+00\n",
            "Epoch 19/45\n",
            "\u001b[1m1039/1039\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.0000e+00 - auc_20: 0.4990 - loss: 0.0138 - precision_20: 0.0000e+00 - recall_20: 0.0000e+00\n",
            "Epoch 20/45\n",
            "\u001b[1m1039/1039\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.0000e+00 - auc_20: 0.5000 - loss: 0.0137 - precision_20: 0.0000e+00 - recall_20: 0.0000e+00\n",
            "Epoch 21/45\n",
            "\u001b[1m1039/1039\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.0000e+00 - auc_20: 0.4976 - loss: 0.0133 - precision_20: 0.0000e+00 - recall_20: 0.0000e+00\n",
            "Epoch 22/45\n",
            "\u001b[1m1039/1039\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.0000e+00 - auc_20: 0.4986 - loss: 0.0130 - precision_20: 0.0000e+00 - recall_20: 0.0000e+00\n",
            "Epoch 23/45\n",
            "\u001b[1m1039/1039\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.0000e+00 - auc_20: 0.4986 - loss: 0.0119 - precision_20: 0.0000e+00 - recall_20: 0.0000e+00\n",
            "Epoch 24/45\n",
            "\u001b[1m1039/1039\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.0000e+00 - auc_20: 0.4971 - loss: 0.0129 - precision_20: 0.0000e+00 - recall_20: 0.0000e+00\n",
            "Epoch 25/45\n",
            "\u001b[1m1039/1039\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.0000e+00 - auc_20: 0.5000 - loss: 0.0136 - precision_20: 0.0000e+00 - recall_20: 0.0000e+00\n",
            "Epoch 26/45\n",
            "\u001b[1m1039/1039\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.0000e+00 - auc_20: 0.4990 - loss: 0.0133 - precision_20: 0.0000e+00 - recall_20: 0.0000e+00\n",
            "Epoch 27/45\n",
            "\u001b[1m1039/1039\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - accuracy: 0.0000e+00 - auc_20: 0.5000 - loss: 0.0130 - precision_20: 0.0000e+00 - recall_20: 0.0000e+00\n",
            "Epoch 28/45\n",
            "\u001b[1m1039/1039\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.0000e+00 - auc_20: 0.4981 - loss: 0.0132 - precision_20: 0.0000e+00 - recall_20: 0.0000e+00\n",
            "Epoch 29/45\n",
            "\u001b[1m1039/1039\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.0000e+00 - auc_20: 0.5000 - loss: 0.0125 - precision_20: 0.0000e+00 - recall_20: 0.0000e+00\n",
            "Epoch 30/45\n",
            "\u001b[1m1039/1039\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.0000e+00 - auc_20: 0.4942 - loss: 0.0137 - precision_20: 0.0000e+00 - recall_20: 0.0000e+00\n",
            "Epoch 31/45\n",
            "\u001b[1m1039/1039\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.0000e+00 - auc_20: 0.4986 - loss: 0.0132 - precision_20: 0.0000e+00 - recall_20: 0.0000e+00\n",
            "Epoch 32/45\n",
            "\u001b[1m1039/1039\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - accuracy: 0.0000e+00 - auc_20: 0.4990 - loss: 0.0140 - precision_20: 0.0000e+00 - recall_20: 0.0000e+00\n",
            "Epoch 33/45\n",
            "\u001b[1m1039/1039\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.0000e+00 - auc_20: 0.4928 - loss: 0.0121 - precision_20: 0.0000e+00 - recall_20: 0.0000e+00\n",
            "Epoch 34/45\n",
            "\u001b[1m1039/1039\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.0000e+00 - auc_20: 0.5000 - loss: 0.0125 - precision_20: 0.0000e+00 - recall_20: 0.0000e+00\n",
            "Epoch 35/45\n",
            "\u001b[1m1039/1039\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.0000e+00 - auc_20: 0.5000 - loss: 0.0137 - precision_20: 0.0000e+00 - recall_20: 0.0000e+00\n",
            "Epoch 36/45\n",
            "\u001b[1m1039/1039\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.0000e+00 - auc_20: 0.4966 - loss: 0.0128 - precision_20: 0.0000e+00 - recall_20: 0.0000e+00\n",
            "Epoch 37/45\n",
            "\u001b[1m1039/1039\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.0000e+00 - auc_20: 0.5000 - loss: 0.0123 - precision_20: 0.0000e+00 - recall_20: 0.0000e+00\n",
            "Epoch 38/45\n",
            "\u001b[1m1039/1039\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - accuracy: 0.0000e+00 - auc_20: 0.4986 - loss: 0.0139 - precision_20: 0.0000e+00 - recall_20: 0.0000e+00\n",
            "Epoch 39/45\n",
            "\u001b[1m1039/1039\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.0000e+00 - auc_20: 0.4981 - loss: 0.0122 - precision_20: 0.0000e+00 - recall_20: 0.0000e+00\n",
            "Epoch 40/45\n",
            "\u001b[1m1039/1039\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.0000e+00 - auc_20: 0.4981 - loss: 0.0126 - precision_20: 0.0000e+00 - recall_20: 0.0000e+00\n",
            "Epoch 41/45\n",
            "\u001b[1m1039/1039\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.0000e+00 - auc_20: 0.4957 - loss: 0.0147 - precision_20: 0.0000e+00 - recall_20: 0.0000e+00\n",
            "Epoch 42/45\n",
            "\u001b[1m1039/1039\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.0000e+00 - auc_20: 0.5000 - loss: 0.0144 - precision_20: 0.0000e+00 - recall_20: 0.0000e+00\n",
            "Epoch 43/45\n",
            "\u001b[1m1039/1039\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.0000e+00 - auc_20: 0.4981 - loss: 0.0135 - precision_20: 0.0000e+00 - recall_20: 0.0000e+00\n",
            "Epoch 44/45\n",
            "\u001b[1m1039/1039\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.0000e+00 - auc_20: 0.5000 - loss: 0.0133 - precision_20: 0.0000e+00 - recall_20: 0.0000e+00\n",
            "Epoch 45/45\n",
            "\u001b[1m1039/1039\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.0000e+00 - auc_20: 0.4976 - loss: 0.0117 - precision_20: 0.0000e+00 - recall_20: 0.0000e+00\n",
            "\u001b[1m520/520\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step\n",
            "[CV] END batch_size=128, epochs=45, model__learn_rate=0.1, model__optimizer=adam; total time= 2.2min\n",
            "Epoch 1/45\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning:\n",
            "\n",
            "Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1039/1039\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.0705 - auc_21: 0.5350 - loss: 0.6749 - precision_21: 0.0836 - recall_21: 0.0062\n",
            "Epoch 2/45\n",
            "\u001b[1m1039/1039\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.0000e+00 - auc_21: 0.4932 - loss: 0.0122 - precision_21: 0.0000e+00 - recall_21: 0.0000e+00\n",
            "Epoch 3/45\n",
            "\u001b[1m1039/1039\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.0000e+00 - auc_21: 0.4995 - loss: 0.0126 - precision_21: 0.0000e+00 - recall_21: 0.0000e+00\n",
            "Epoch 4/45\n",
            "\u001b[1m1039/1039\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.0000e+00 - auc_21: 0.4971 - loss: 0.0143 - precision_21: 0.0000e+00 - recall_21: 0.0000e+00\n",
            "Epoch 5/45\n",
            "\u001b[1m1039/1039\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.0000e+00 - auc_21: 0.4995 - loss: 0.0143 - precision_21: 0.0000e+00 - recall_21: 0.0000e+00\n",
            "Epoch 6/45\n",
            "\u001b[1m1039/1039\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.0000e+00 - auc_21: 0.5000 - loss: 0.0142 - precision_21: 0.0000e+00 - recall_21: 0.0000e+00\n",
            "Epoch 7/45\n",
            "\u001b[1m1039/1039\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.0000e+00 - auc_21: 0.4981 - loss: 0.0133 - precision_21: 0.0000e+00 - recall_21: 0.0000e+00\n",
            "Epoch 8/45\n",
            "\u001b[1m1039/1039\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - accuracy: 4.4852e-06 - auc_21: 0.5014 - loss: 0.0127 - precision_21: 0.0692 - recall_21: 9.1009e-04\n",
            "Epoch 9/45\n",
            "\u001b[1m1039/1039\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.0000e+00 - auc_21: 0.4947 - loss: 0.0125 - precision_21: 0.0000e+00 - recall_21: 0.0000e+00\n",
            "Epoch 10/45\n",
            "\u001b[1m1039/1039\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.0000e+00 - auc_21: 0.4976 - loss: 0.0136 - precision_21: 0.0000e+00 - recall_21: 0.0000e+00\n",
            "Epoch 11/45\n",
            "\u001b[1m1039/1039\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.0000e+00 - auc_21: 0.5000 - loss: 0.0129 - precision_21: 0.0000e+00 - recall_21: 0.0000e+00\n",
            "Epoch 12/45\n",
            "\u001b[1m1039/1039\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.0000e+00 - auc_21: 0.4995 - loss: 0.0126 - precision_21: 0.0000e+00 - recall_21: 0.0000e+00\n",
            "Epoch 13/45\n",
            "\u001b[1m1039/1039\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - accuracy: 0.0000e+00 - auc_21: 0.4986 - loss: 0.0138 - precision_21: 0.0000e+00 - recall_21: 0.0000e+00\n",
            "Epoch 14/45\n",
            "\u001b[1m1039/1039\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.0000e+00 - auc_21: 0.4966 - loss: 0.0122 - precision_21: 0.0000e+00 - recall_21: 0.0000e+00\n",
            "Epoch 15/45\n",
            "\u001b[1m1039/1039\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.0000e+00 - auc_21: 0.5000 - loss: 0.0135 - precision_21: 0.0000e+00 - recall_21: 0.0000e+00\n",
            "Epoch 16/45\n",
            "\u001b[1m1039/1039\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.0000e+00 - auc_21: 0.5000 - loss: 0.0125 - precision_21: 0.0000e+00 - recall_21: 0.0000e+00\n",
            "Epoch 17/45\n",
            "\u001b[1m1039/1039\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.0000e+00 - auc_21: 0.5000 - loss: 0.0144 - precision_21: 0.0000e+00 - recall_21: 0.0000e+00\n",
            "Epoch 18/45\n",
            "\u001b[1m1039/1039\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - accuracy: 0.0000e+00 - auc_21: 0.4990 - loss: 0.0152 - precision_21: 0.0000e+00 - recall_21: 0.0000e+00\n",
            "Epoch 19/45\n",
            "\u001b[1m1039/1039\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.0000e+00 - auc_21: 0.4966 - loss: 0.0115 - precision_21: 0.0000e+00 - recall_21: 0.0000e+00\n",
            "Epoch 20/45\n",
            "\u001b[1m1039/1039\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.0000e+00 - auc_21: 0.5000 - loss: 0.0130 - precision_21: 0.0000e+00 - recall_21: 0.0000e+00\n",
            "Epoch 21/45\n",
            "\u001b[1m1039/1039\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.0000e+00 - auc_21: 0.4986 - loss: 0.0126 - precision_21: 0.0000e+00 - recall_21: 0.0000e+00\n",
            "Epoch 22/45\n",
            "\u001b[1m1039/1039\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.0000e+00 - auc_21: 0.5000 - loss: 0.0128 - precision_21: 0.0000e+00 - recall_21: 0.0000e+00\n",
            "Epoch 23/45\n",
            "\u001b[1m1039/1039\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.0000e+00 - auc_21: 0.4957 - loss: 0.0136 - precision_21: 0.0000e+00 - recall_21: 0.0000e+00\n",
            "Epoch 24/45\n",
            "\u001b[1m1039/1039\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.0000e+00 - auc_21: 0.4995 - loss: 0.0129 - precision_21: 0.0000e+00 - recall_21: 0.0000e+00\n",
            "Epoch 25/45\n",
            "\u001b[1m1039/1039\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.0000e+00 - auc_21: 0.4981 - loss: 0.0136 - precision_21: 0.0000e+00 - recall_21: 0.0000e+00\n",
            "Epoch 26/45\n",
            "\u001b[1m1039/1039\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.0000e+00 - auc_21: 0.4928 - loss: 0.0118 - precision_21: 0.0000e+00 - recall_21: 0.0000e+00\n",
            "Epoch 27/45\n",
            "\u001b[1m1039/1039\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.0000e+00 - auc_21: 0.4995 - loss: 0.0126 - precision_21: 0.0000e+00 - recall_21: 0.0000e+00\n",
            "Epoch 28/45\n",
            "\u001b[1m1039/1039\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - accuracy: 0.0000e+00 - auc_21: 0.4938 - loss: 0.0128 - precision_21: 0.0000e+00 - recall_21: 0.0000e+00\n",
            "Epoch 29/45\n",
            "\u001b[1m1039/1039\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.0000e+00 - auc_21: 0.4981 - loss: 0.0139 - precision_21: 0.0000e+00 - recall_21: 0.0000e+00\n",
            "Epoch 30/45\n",
            "\u001b[1m1039/1039\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.0000e+00 - auc_21: 0.4995 - loss: 0.0121 - precision_21: 0.0000e+00 - recall_21: 0.0000e+00\n",
            "Epoch 31/45\n",
            "\u001b[1m1039/1039\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.0000e+00 - auc_21: 0.5000 - loss: 0.0139 - precision_21: 0.0000e+00 - recall_21: 0.0000e+00\n",
            "Epoch 32/45\n",
            "\u001b[1m1039/1039\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.0000e+00 - auc_21: 0.4986 - loss: 0.0139 - precision_21: 0.0000e+00 - recall_21: 0.0000e+00\n",
            "Epoch 33/45\n",
            "\u001b[1m1039/1039\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.0000e+00 - auc_21: 0.4957 - loss: 0.0130 - precision_21: 0.0000e+00 - recall_21: 0.0000e+00\n",
            "Epoch 34/45\n",
            "\u001b[1m1039/1039\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.0000e+00 - auc_21: 0.4990 - loss: 0.0130 - precision_21: 0.0000e+00 - recall_21: 0.0000e+00\n",
            "Epoch 35/45\n",
            "\u001b[1m1039/1039\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.0000e+00 - auc_21: 0.5000 - loss: 0.0143 - precision_21: 0.0000e+00 - recall_21: 0.0000e+00\n",
            "Epoch 36/45\n",
            "\u001b[1m1039/1039\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.0000e+00 - auc_21: 0.5000 - loss: 0.0129 - precision_21: 0.0000e+00 - recall_21: 0.0000e+00\n",
            "Epoch 37/45\n",
            "\u001b[1m1039/1039\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.0000e+00 - auc_21: 0.4896 - loss: 0.0142 - precision_21: 0.0000e+00 - recall_21: 0.0000e+00\n",
            "Epoch 38/45\n",
            "\u001b[1m1039/1039\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - accuracy: 0.0000e+00 - auc_21: 0.4962 - loss: 0.0141 - precision_21: 0.0000e+00 - recall_21: 0.0000e+00\n",
            "Epoch 39/45\n",
            "\u001b[1m1039/1039\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.0000e+00 - auc_21: 0.4976 - loss: 0.0132 - precision_21: 0.0000e+00 - recall_21: 0.0000e+00\n",
            "Epoch 40/45\n",
            "\u001b[1m1039/1039\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.0000e+00 - auc_21: 0.4962 - loss: 0.0124 - precision_21: 0.0000e+00 - recall_21: 0.0000e+00\n",
            "Epoch 41/45\n",
            "\u001b[1m1039/1039\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.0000e+00 - auc_21: 0.4995 - loss: 0.0127 - precision_21: 0.0000e+00 - recall_21: 0.0000e+00\n",
            "Epoch 42/45\n",
            "\u001b[1m1039/1039\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.0000e+00 - auc_21: 0.4981 - loss: 0.0114 - precision_21: 0.0000e+00 - recall_21: 0.0000e+00\n",
            "Epoch 43/45\n",
            "\u001b[1m1039/1039\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - accuracy: 0.0000e+00 - auc_21: 0.4995 - loss: 0.0140 - precision_21: 0.0000e+00 - recall_21: 0.0000e+00\n",
            "Epoch 44/45\n",
            "\u001b[1m1039/1039\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.0000e+00 - auc_21: 0.4986 - loss: 0.0135 - precision_21: 0.0000e+00 - recall_21: 0.0000e+00\n",
            "Epoch 45/45\n",
            "\u001b[1m1039/1039\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.0000e+00 - auc_21: 0.4986 - loss: 0.0130 - precision_21: 0.0000e+00 - recall_21: 0.0000e+00\n",
            "\u001b[1m520/520\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step\n",
            "[CV] END batch_size=128, epochs=45, model__learn_rate=0.1, model__optimizer=adam; total time= 2.3min\n",
            "Epoch 1/45\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning:\n",
            "\n",
            "Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1039/1039\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.1131 - auc_22: 0.5256 - loss: 0.6033 - precision_22: 0.0000e+00 - recall_22: 0.0000e+00\n",
            "Epoch 2/45\n",
            "\u001b[1m1039/1039\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.0408 - auc_22: 0.4995 - loss: 0.0143 - precision_22: 0.0000e+00 - recall_22: 0.0000e+00\n",
            "Epoch 3/45\n",
            "\u001b[1m1039/1039\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.0426 - auc_22: 0.4986 - loss: 0.0129 - precision_22: 0.0000e+00 - recall_22: 0.0000e+00\n",
            "Epoch 4/45\n",
            "\u001b[1m1039/1039\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.0461 - auc_22: 0.4990 - loss: 0.0130 - precision_22: 0.0000e+00 - recall_22: 0.0000e+00\n",
            "Epoch 5/45\n",
            "\u001b[1m1039/1039\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.0428 - auc_22: 0.4957 - loss: 0.0130 - precision_22: 0.0000e+00 - recall_22: 0.0000e+00\n",
            "Epoch 6/45\n",
            "\u001b[1m1039/1039\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.0689 - auc_22: 0.4980 - loss: 0.1428 - precision_22: 0.0000e+00 - recall_22: 0.0000e+00\n",
            "Epoch 7/45\n",
            "\u001b[1m1039/1039\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.0000e+00 - auc_22: 0.4990 - loss: 0.0147 - precision_22: 0.0000e+00 - recall_22: 0.0000e+00\n",
            "Epoch 8/45\n",
            "\u001b[1m1039/1039\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.0000e+00 - auc_22: 0.4981 - loss: 0.0127 - precision_22: 0.0000e+00 - recall_22: 0.0000e+00\n",
            "Epoch 9/45\n",
            "\u001b[1m1039/1039\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.0000e+00 - auc_22: 0.4918 - loss: 0.0128 - precision_22: 0.0000e+00 - recall_22: 0.0000e+00\n",
            "Epoch 10/45\n",
            "\u001b[1m1039/1039\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.0000e+00 - auc_22: 0.5000 - loss: 0.0125 - precision_22: 0.0000e+00 - recall_22: 0.0000e+00\n",
            "Epoch 11/45\n",
            "\u001b[1m1039/1039\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.0000e+00 - auc_22: 0.4990 - loss: 0.0147 - precision_22: 0.0000e+00 - recall_22: 0.0000e+00\n",
            "Epoch 12/45\n",
            "\u001b[1m1039/1039\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.0000e+00 - auc_22: 0.4938 - loss: 0.0130 - precision_22: 0.0000e+00 - recall_22: 0.0000e+00\n",
            "Epoch 13/45\n",
            "\u001b[1m1039/1039\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.0000e+00 - auc_22: 0.4966 - loss: 0.0123 - precision_22: 0.0000e+00 - recall_22: 0.0000e+00\n",
            "Epoch 14/45\n",
            "\u001b[1m1039/1039\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.0000e+00 - auc_22: 0.4986 - loss: 0.0126 - precision_22: 0.0000e+00 - recall_22: 0.0000e+00\n",
            "Epoch 15/45\n",
            "\u001b[1m1039/1039\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.0000e+00 - auc_22: 0.4952 - loss: 0.0126 - precision_22: 0.0000e+00 - recall_22: 0.0000e+00\n",
            "Epoch 16/45\n",
            "\u001b[1m1039/1039\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.0000e+00 - auc_22: 0.4942 - loss: 0.0121 - precision_22: 0.0000e+00 - recall_22: 0.0000e+00\n",
            "Epoch 17/45\n",
            "\u001b[1m1039/1039\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - accuracy: 0.0000e+00 - auc_22: 0.4952 - loss: 0.0130 - precision_22: 0.0000e+00 - recall_22: 0.0000e+00\n",
            "Epoch 18/45\n",
            "\u001b[1m1039/1039\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.0000e+00 - auc_22: 0.4990 - loss: 0.0136 - precision_22: 0.0000e+00 - recall_22: 0.0000e+00\n",
            "Epoch 19/45\n",
            "\u001b[1m1039/1039\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.0000e+00 - auc_22: 0.4995 - loss: 0.0133 - precision_22: 0.0000e+00 - recall_22: 0.0000e+00\n",
            "Epoch 20/45\n",
            "\u001b[1m1039/1039\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.0000e+00 - auc_22: 0.4986 - loss: 0.0120 - precision_22: 0.0000e+00 - recall_22: 0.0000e+00\n",
            "Epoch 21/45\n",
            "\u001b[1m1039/1039\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.0000e+00 - auc_22: 0.4995 - loss: 0.0132 - precision_22: 0.0000e+00 - recall_22: 0.0000e+00\n",
            "Epoch 22/45\n",
            "\u001b[1m1039/1039\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.0000e+00 - auc_22: 0.4981 - loss: 0.0139 - precision_22: 0.0000e+00 - recall_22: 0.0000e+00\n",
            "Epoch 23/45\n",
            "\u001b[1m1039/1039\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - accuracy: 0.0000e+00 - auc_22: 0.4995 - loss: 0.0140 - precision_22: 0.0000e+00 - recall_22: 0.0000e+00\n",
            "Epoch 24/45\n",
            "\u001b[1m1039/1039\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.0000e+00 - auc_22: 0.4995 - loss: 0.0130 - precision_22: 0.0000e+00 - recall_22: 0.0000e+00\n",
            "Epoch 25/45\n",
            "\u001b[1m1039/1039\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.0000e+00 - auc_22: 0.4990 - loss: 0.0132 - precision_22: 0.0000e+00 - recall_22: 0.0000e+00\n",
            "Epoch 26/45\n",
            "\u001b[1m1039/1039\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.0000e+00 - auc_22: 0.4976 - loss: 0.0128 - precision_22: 0.0000e+00 - recall_22: 0.0000e+00\n",
            "Epoch 27/45\n",
            "\u001b[1m1039/1039\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.0000e+00 - auc_22: 0.5000 - loss: 0.0130 - precision_22: 0.0000e+00 - recall_22: 0.0000e+00\n",
            "Epoch 28/45\n",
            "\u001b[1m1039/1039\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.0000e+00 - auc_22: 0.4995 - loss: 0.0136 - precision_22: 0.0000e+00 - recall_22: 0.0000e+00\n",
            "Epoch 29/45\n",
            "\u001b[1m1039/1039\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.0000e+00 - auc_22: 0.5000 - loss: 0.0141 - precision_22: 0.0000e+00 - recall_22: 0.0000e+00\n",
            "Epoch 30/45\n",
            "\u001b[1m1039/1039\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.0000e+00 - auc_22: 0.4962 - loss: 0.0113 - precision_22: 0.0000e+00 - recall_22: 0.0000e+00\n",
            "Epoch 31/45\n",
            "\u001b[1m1039/1039\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.0000e+00 - auc_22: 0.4995 - loss: 0.0141 - precision_22: 0.0000e+00 - recall_22: 0.0000e+00\n",
            "Epoch 32/45\n",
            "\u001b[1m1039/1039\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.0000e+00 - auc_22: 0.5000 - loss: 0.0137 - precision_22: 0.0000e+00 - recall_22: 0.0000e+00\n",
            "Epoch 33/45\n",
            "\u001b[1m1039/1039\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.0000e+00 - auc_22: 0.4966 - loss: 0.0130 - precision_22: 0.0000e+00 - recall_22: 0.0000e+00\n",
            "Epoch 34/45\n",
            "\u001b[1m1039/1039\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - accuracy: 0.0000e+00 - auc_22: 0.4990 - loss: 0.0131 - precision_22: 0.0000e+00 - recall_22: 0.0000e+00\n",
            "Epoch 35/45\n",
            "\u001b[1m1039/1039\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.0000e+00 - auc_22: 0.5000 - loss: 0.0137 - precision_22: 0.0000e+00 - recall_22: 0.0000e+00\n",
            "Epoch 36/45\n",
            "\u001b[1m1039/1039\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.0000e+00 - auc_22: 0.4962 - loss: 0.0136 - precision_22: 0.0000e+00 - recall_22: 0.0000e+00\n",
            "Epoch 37/45\n",
            "\u001b[1m1039/1039\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.0000e+00 - auc_22: 0.4976 - loss: 0.0127 - precision_22: 0.0000e+00 - recall_22: 0.0000e+00\n",
            "Epoch 38/45\n",
            "\u001b[1m1039/1039\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.0000e+00 - auc_22: 0.5000 - loss: 0.0135 - precision_22: 0.0000e+00 - recall_22: 0.0000e+00\n",
            "Epoch 39/45\n",
            "\u001b[1m1039/1039\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.0000e+00 - auc_22: 0.4986 - loss: 0.0134 - precision_22: 0.0000e+00 - recall_22: 0.0000e+00\n",
            "Epoch 40/45\n",
            "\u001b[1m1039/1039\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.0000e+00 - auc_22: 0.4966 - loss: 0.0135 - precision_22: 0.0000e+00 - recall_22: 0.0000e+00\n",
            "Epoch 41/45\n",
            "\u001b[1m1039/1039\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.0000e+00 - auc_22: 0.4976 - loss: 0.0124 - precision_22: 0.0000e+00 - recall_22: 0.0000e+00\n",
            "Epoch 42/45\n",
            "\u001b[1m1039/1039\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.0000e+00 - auc_22: 0.5000 - loss: 0.0136 - precision_22: 0.0000e+00 - recall_22: 0.0000e+00\n",
            "Epoch 43/45\n",
            "\u001b[1m1039/1039\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.0000e+00 - auc_22: 0.5000 - loss: 0.0141 - precision_22: 0.0000e+00 - recall_22: 0.0000e+00\n",
            "Epoch 44/45\n",
            "\u001b[1m1039/1039\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.0000e+00 - auc_22: 0.4966 - loss: 0.0121 - precision_22: 0.0000e+00 - recall_22: 0.0000e+00\n",
            "Epoch 45/45\n",
            "\u001b[1m1039/1039\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.0000e+00 - auc_22: 0.4952 - loss: 0.0125 - precision_22: 0.0000e+00 - recall_22: 0.0000e+00\n",
            "\u001b[1m520/520\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning:\n",
            "\n",
            "Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV] END batch_size=128, epochs=45, model__learn_rate=0.1, model__optimizer=adam; total time= 2.2min\n",
            "Otimizador não reconhecido\n",
            "[CV] END batch_size=32, epochs=20, model__learn_rate=0.01, model__optimizer=rmsprop; total time=   0.1s\n",
            "Otimizador não reconhecido\n",
            "[CV] END batch_size=32, epochs=20, model__learn_rate=0.01, model__optimizer=rmsprop; total time=   0.1s\n",
            "Otimizador não reconhecido\n",
            "[CV] END batch_size=32, epochs=20, model__learn_rate=0.01, model__optimizer=rmsprop; total time=   0.1s\n",
            "Epoch 1/45\n",
            "\u001b[1m2077/2077\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 2ms/step - accuracy: 0.0840 - auc_23: 0.7944 - loss: 0.0835 - precision_23: 0.3492 - recall_23: 0.3965\n",
            "Epoch 2/45\n",
            "\u001b[1m2077/2077\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - accuracy: 0.0018 - auc_23: 0.9087 - loss: 0.0089 - precision_23: 0.8314 - recall_23: 0.5459\n",
            "Epoch 3/45\n",
            "\u001b[1m2077/2077\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 2ms/step - accuracy: 1.4627e-04 - auc_23: 0.9002 - loss: 0.0053 - precision_23: 0.8292 - recall_23: 0.5530\n",
            "Epoch 4/45\n",
            "\u001b[1m2077/2077\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - accuracy: 0.0027 - auc_23: 0.7430 - loss: 0.0149 - precision_23: 0.6986 - recall_23: 0.3890\n",
            "Epoch 5/45\n",
            "\u001b[1m2077/2077\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.0048 - auc_23: 0.8395 - loss: 0.0092 - precision_23: 0.7516 - recall_23: 0.4745\n",
            "Epoch 6/45\n",
            "\u001b[1m2077/2077\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - accuracy: 2.3480e-04 - auc_23: 0.9046 - loss: 0.0053 - precision_23: 0.8612 - recall_23: 0.5939\n",
            "Epoch 7/45\n",
            "\u001b[1m2077/2077\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 1.3278e-04 - auc_23: 0.7723 - loss: 0.0080 - precision_23: 0.8332 - recall_23: 0.4663\n",
            "Epoch 8/45\n",
            "\u001b[1m2077/2077\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 3ms/step - accuracy: 0.0246 - auc_23: 0.8103 - loss: 0.0124 - precision_23: 0.8532 - recall_23: 0.5277\n",
            "Epoch 9/45\n",
            "\u001b[1m2077/2077\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 2ms/step - accuracy: 0.0010 - auc_23: 0.7174 - loss: 0.0101 - precision_23: 0.8664 - recall_23: 0.3444\n",
            "Epoch 10/45\n",
            "\u001b[1m2077/2077\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.0112 - auc_23: 0.7651 - loss: 0.0089 - precision_23: 0.8943 - recall_23: 0.4432\n",
            "Epoch 11/45\n",
            "\u001b[1m2077/2077\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 6.1965e-04 - auc_23: 0.7065 - loss: 0.0088 - precision_23: 0.8451 - recall_23: 0.3691\n",
            "Epoch 12/45\n",
            "\u001b[1m2077/2077\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 3ms/step - accuracy: 0.0541 - auc_23: 0.4945 - loss: 0.0803 - precision_23: 0.0000e+00 - recall_23: 0.0000e+00\n",
            "Epoch 13/45\n",
            "\u001b[1m2077/2077\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.0859 - auc_23: 0.4993 - loss: 0.0197 - precision_23: 0.0000e+00 - recall_23: 0.0000e+00\n",
            "Epoch 14/45\n",
            "\u001b[1m2077/2077\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.0758 - auc_23: 0.4938 - loss: 0.4404 - precision_23: 0.0000e+00 - recall_23: 0.0000e+00\n",
            "Epoch 15/45\n",
            "\u001b[1m2077/2077\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.0990 - auc_23: 0.4989 - loss: 0.1823 - precision_23: 0.0000e+00 - recall_23: 0.0000e+00\n",
            "Epoch 16/45\n",
            "\u001b[1m2077/2077\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - accuracy: 0.0508 - auc_23: 0.4959 - loss: 0.0121 - precision_23: 0.0000e+00 - recall_23: 0.0000e+00\n",
            "Epoch 17/45\n",
            "\u001b[1m2077/2077\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 2ms/step - accuracy: 0.0618 - auc_23: 0.4964 - loss: 0.0122 - precision_23: 0.0000e+00 - recall_23: 0.0000e+00\n",
            "Epoch 18/45\n",
            "\u001b[1m2077/2077\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 2ms/step - accuracy: 0.1036 - auc_23: 0.5000 - loss: 0.0150 - precision_23: 0.0000e+00 - recall_23: 0.0000e+00\n",
            "Epoch 19/45\n",
            "\u001b[1m2077/2077\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - accuracy: 0.1013 - auc_23: 0.4988 - loss: 0.0135 - precision_23: 0.0000e+00 - recall_23: 0.0000e+00\n",
            "Epoch 20/45\n",
            "\u001b[1m2077/2077\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 2ms/step - accuracy: 0.2662 - auc_23: 0.4950 - loss: 0.6302 - precision_23: 0.0000e+00 - recall_23: 0.0000e+00\n",
            "Epoch 21/45\n",
            "\u001b[1m2077/2077\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - accuracy: 0.2476 - auc_23: 0.4920 - loss: 0.0937 - precision_23: 0.0000e+00 - recall_23: 0.0000e+00\n",
            "Epoch 22/45\n",
            "\u001b[1m2077/2077\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 2ms/step - accuracy: 0.0695 - auc_23: 0.4988 - loss: 0.0126 - precision_23: 0.0000e+00 - recall_23: 0.0000e+00\n",
            "Epoch 23/45\n",
            "\u001b[1m2077/2077\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - accuracy: 0.0774 - auc_23: 0.4981 - loss: 0.0853 - precision_23: 0.0000e+00 - recall_23: 0.0000e+00\n",
            "Epoch 24/45\n",
            "\u001b[1m2077/2077\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 2ms/step - accuracy: 0.0712 - auc_23: 0.5000 - loss: 0.0125 - precision_23: 0.0000e+00 - recall_23: 0.0000e+00\n",
            "Epoch 25/45\n",
            "\u001b[1m2077/2077\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - accuracy: 0.0782 - auc_23: 0.4978 - loss: 0.0124 - precision_23: 0.0000e+00 - recall_23: 0.0000e+00\n",
            "Epoch 26/45\n",
            "\u001b[1m2077/2077\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 2ms/step - accuracy: 0.1025 - auc_23: 0.4993 - loss: 0.0132 - precision_23: 0.0000e+00 - recall_23: 0.0000e+00\n",
            "Epoch 27/45\n",
            "\u001b[1m2077/2077\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - accuracy: 0.1368 - auc_23: 0.4986 - loss: 0.0125 - precision_23: 0.0000e+00 - recall_23: 0.0000e+00\n",
            "Epoch 28/45\n",
            "\u001b[1m2077/2077\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.1716 - auc_23: 0.4990 - loss: 0.0149 - precision_23: 0.0000e+00 - recall_23: 0.0000e+00\n",
            "Epoch 29/45\n",
            "\u001b[1m2077/2077\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 3ms/step - accuracy: 0.1676 - auc_23: 0.4958 - loss: 0.2046 - precision_23: 0.0000e+00 - recall_23: 0.0000e+00\n",
            "Epoch 30/45\n",
            "\u001b[1m2077/2077\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 2ms/step - accuracy: 0.1566 - auc_23: 0.4998 - loss: 0.0134 - precision_23: 0.0000e+00 - recall_23: 0.0000e+00\n",
            "Epoch 31/45\n",
            "\u001b[1m2077/2077\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - accuracy: 0.1318 - auc_23: 0.4998 - loss: 0.0123 - precision_23: 0.0000e+00 - recall_23: 0.0000e+00\n",
            "Epoch 32/45\n",
            "\u001b[1m2077/2077\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 2ms/step - accuracy: 0.1344 - auc_23: 0.4976 - loss: 0.0126 - precision_23: 0.0000e+00 - recall_23: 0.0000e+00\n",
            "Epoch 33/45\n",
            "\u001b[1m2077/2077\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - accuracy: 0.1435 - auc_23: 0.4990 - loss: 0.0126 - precision_23: 0.0000e+00 - recall_23: 0.0000e+00\n",
            "Epoch 34/45\n",
            "\u001b[1m2077/2077\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.1701 - auc_23: 0.4995 - loss: 0.0129 - precision_23: 0.0000e+00 - recall_23: 0.0000e+00\n",
            "Epoch 35/45\n",
            "\u001b[1m2077/2077\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 3ms/step - accuracy: 0.1960 - auc_23: 0.4998 - loss: 0.0136 - precision_23: 0.0000e+00 - recall_23: 0.0000e+00\n",
            "Epoch 36/45\n",
            "\u001b[1m2077/2077\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.2267 - auc_23: 0.4993 - loss: 0.7294 - precision_23: 0.0000e+00 - recall_23: 0.0000e+00\n",
            "Epoch 37/45\n",
            "\u001b[1m2077/2077\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 3ms/step - accuracy: 0.2612 - auc_23: 0.4981 - loss: 0.0154 - precision_23: 0.0000e+00 - recall_23: 0.0000e+00\n",
            "Epoch 38/45\n",
            "\u001b[1m2077/2077\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 2ms/step - accuracy: 0.2243 - auc_23: 0.4958 - loss: 0.0239 - precision_23: 0.0000e+00 - recall_23: 0.0000e+00\n",
            "Epoch 39/45\n",
            "\u001b[1m2077/2077\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - accuracy: 0.1815 - auc_23: 0.4995 - loss: 0.0136 - precision_23: 0.0000e+00 - recall_23: 0.0000e+00\n",
            "Epoch 40/45\n",
            "\u001b[1m2077/2077\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 2ms/step - accuracy: 0.1831 - auc_23: 0.4872 - loss: 0.0114 - precision_23: 0.0000e+00 - recall_23: 0.0000e+00\n",
            "Epoch 41/45\n",
            "\u001b[1m2077/2077\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - accuracy: 0.1931 - auc_23: 0.4986 - loss: 0.0130 - precision_23: 0.0000e+00 - recall_23: 0.0000e+00\n",
            "Epoch 42/45\n",
            "\u001b[1m2077/2077\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.2231 - auc_23: 0.4966 - loss: 0.0126 - precision_23: 0.0000e+00 - recall_23: 0.0000e+00\n",
            "Epoch 43/45\n",
            "\u001b[1m2077/2077\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.2556 - auc_23: 0.4990 - loss: 0.0132 - precision_23: 0.0000e+00 - recall_23: 0.0000e+00\n",
            "Epoch 44/45\n",
            "\u001b[1m2077/2077\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - accuracy: 0.2258 - auc_23: 0.4998 - loss: 0.0131 - precision_23: 0.0000e+00 - recall_23: 0.0000e+00\n",
            "Epoch 45/45\n",
            "\u001b[1m2077/2077\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 2ms/step - accuracy: 0.2363 - auc_23: 0.4990 - loss: 0.0452 - precision_23: 0.0000e+00 - recall_23: 0.0000e+00\n",
            "\u001b[1m1039/1039\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning:\n",
            "\n",
            "Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV] END batch_size=64, epochs=45, model__learn_rate=0.01, model__optimizer=adam; total time= 5.4min\n",
            "Epoch 1/45\n",
            "\u001b[1m2077/2077\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 3ms/step - accuracy: 0.0546 - auc_24: 0.7892 - loss: 0.0458 - precision_24: 0.3641 - recall_24: 0.2721\n",
            "Epoch 2/45\n",
            "\u001b[1m2077/2077\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.0038 - auc_24: 0.8977 - loss: 0.0090 - precision_24: 0.8166 - recall_24: 0.5196\n",
            "Epoch 3/45\n",
            "\u001b[1m2077/2077\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - accuracy: 0.0026 - auc_24: 0.8959 - loss: 0.0078 - precision_24: 0.7382 - recall_24: 0.4350\n",
            "Epoch 4/45\n",
            "\u001b[1m2077/2077\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.0927 - auc_24: 0.8681 - loss: 0.0274 - precision_24: 0.6591 - recall_24: 0.4217\n",
            "Epoch 5/45\n",
            "\u001b[1m2077/2077\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.2471 - auc_24: 0.4993 - loss: 0.1625 - precision_24: 0.0040 - recall_24: 3.1524e-04\n",
            "Epoch 6/45\n",
            "\u001b[1m2077/2077\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - accuracy: 0.1786 - auc_24: 0.4949 - loss: 0.0234 - precision_24: 0.0000e+00 - recall_24: 0.0000e+00\n",
            "Epoch 7/45\n",
            "\u001b[1m2077/2077\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.2167 - auc_24: 0.4971 - loss: 0.0139 - precision_24: 0.0000e+00 - recall_24: 0.0000e+00\n",
            "Epoch 8/45\n",
            "\u001b[1m2077/2077\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 3ms/step - accuracy: 0.1663 - auc_24: 0.4924 - loss: 0.0898 - precision_24: 0.0000e+00 - recall_24: 0.0000e+00\n",
            "Epoch 9/45\n",
            "\u001b[1m2077/2077\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.0519 - auc_24: 0.4979 - loss: 0.0270 - precision_24: 0.0000e+00 - recall_24: 0.0000e+00\n",
            "Epoch 10/45\n",
            "\u001b[1m2077/2077\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.0627 - auc_24: 0.4991 - loss: 0.0232 - precision_24: 0.0000e+00 - recall_24: 0.0000e+00\n",
            "Epoch 11/45\n",
            "\u001b[1m2077/2077\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - accuracy: 0.2925 - auc_24: 0.4937 - loss: 0.0291 - precision_24: 0.0000e+00 - recall_24: 0.0000e+00\n",
            "Epoch 12/45\n",
            "\u001b[1m2077/2077\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 2ms/step - accuracy: 0.1688 - auc_24: 0.4998 - loss: 0.0119 - precision_24: 0.0000e+00 - recall_24: 0.0000e+00\n",
            "Epoch 13/45\n",
            "\u001b[1m2077/2077\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - accuracy: 0.2387 - auc_24: 0.4982 - loss: 0.1584 - precision_24: 0.0000e+00 - recall_24: 0.0000e+00\n",
            "Epoch 14/45\n",
            "\u001b[1m2077/2077\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.1427 - auc_24: 0.4998 - loss: 0.0119 - precision_24: 0.0000e+00 - recall_24: 0.0000e+00\n",
            "Epoch 15/45\n",
            "\u001b[1m2077/2077\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.1506 - auc_24: 0.4964 - loss: 0.0129 - precision_24: 0.0000e+00 - recall_24: 0.0000e+00\n",
            "Epoch 16/45\n",
            "\u001b[1m2077/2077\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.1365 - auc_24: 0.4990 - loss: 0.0123 - precision_24: 0.0000e+00 - recall_24: 0.0000e+00\n",
            "Epoch 17/45\n",
            "\u001b[1m2077/2077\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.2306 - auc_24: 0.4942 - loss: 0.0355 - precision_24: 0.0000e+00 - recall_24: 0.0000e+00\n",
            "Epoch 18/45\n",
            "\u001b[1m2077/2077\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.0782 - auc_24: 0.4958 - loss: 0.0234 - precision_24: 0.0000e+00 - recall_24: 0.0000e+00\n",
            "Epoch 19/45\n",
            "\u001b[1m2077/2077\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.0370 - auc_24: 0.4964 - loss: 0.0127 - precision_24: 0.0000e+00 - recall_24: 0.0000e+00\n",
            "Epoch 20/45\n",
            "\u001b[1m2077/2077\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - accuracy: 0.1012 - auc_24: 0.4963 - loss: 0.0320 - precision_24: 0.0000e+00 - recall_24: 0.0000e+00\n",
            "Epoch 21/45\n",
            "\u001b[1m2077/2077\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 2ms/step - accuracy: 0.1240 - auc_24: 0.4995 - loss: 0.0208 - precision_24: 0.0000e+00 - recall_24: 0.0000e+00\n",
            "Epoch 22/45\n",
            "\u001b[1m2077/2077\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - accuracy: 0.0927 - auc_24: 0.4966 - loss: 0.0163 - precision_24: 0.0000e+00 - recall_24: 0.0000e+00\n",
            "Epoch 23/45\n",
            "\u001b[1m2077/2077\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.1207 - auc_24: 0.4983 - loss: 0.0166 - precision_24: 0.0000e+00 - recall_24: 0.0000e+00\n",
            "Epoch 24/45\n",
            "\u001b[1m2077/2077\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.0664 - auc_24: 0.4990 - loss: 0.0125 - precision_24: 0.0000e+00 - recall_24: 0.0000e+00\n",
            "Epoch 25/45\n",
            "\u001b[1m2077/2077\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - accuracy: 0.1059 - auc_24: 0.4990 - loss: 0.0565 - precision_24: 0.0000e+00 - recall_24: 0.0000e+00\n",
            "Epoch 26/45\n",
            "\u001b[1m2077/2077\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 2ms/step - accuracy: 0.0589 - auc_24: 0.4990 - loss: 0.0124 - precision_24: 0.0000e+00 - recall_24: 0.0000e+00\n",
            "Epoch 27/45\n",
            "\u001b[1m2077/2077\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - accuracy: 0.0742 - auc_24: 0.5000 - loss: 0.0126 - precision_24: 0.0000e+00 - recall_24: 0.0000e+00\n",
            "Epoch 28/45\n",
            "\u001b[1m2077/2077\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.0703 - auc_24: 0.4993 - loss: 0.0123 - precision_24: 0.0000e+00 - recall_24: 0.0000e+00\n",
            "Epoch 29/45\n",
            "\u001b[1m2077/2077\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.1195 - auc_24: 0.4988 - loss: 0.0147 - precision_24: 0.0000e+00 - recall_24: 0.0000e+00\n",
            "Epoch 30/45\n",
            "\u001b[1m2077/2077\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 3ms/step - accuracy: 0.0834 - auc_24: 0.5000 - loss: 0.0135 - precision_24: 0.0000e+00 - recall_24: 0.0000e+00\n",
            "Epoch 31/45\n",
            "\u001b[1m2077/2077\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 2ms/step - accuracy: 0.2118 - auc_24: 0.4995 - loss: 0.0303 - precision_24: 0.0000e+00 - recall_24: 0.0000e+00\n",
            "Epoch 32/45\n",
            "\u001b[1m2077/2077\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - accuracy: 0.2066 - auc_24: 0.4966 - loss: 0.0127 - precision_24: 0.0000e+00 - recall_24: 0.0000e+00\n",
            "Epoch 33/45\n",
            "\u001b[1m2077/2077\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 2ms/step - accuracy: 0.3226 - auc_24: 0.4995 - loss: 0.2124 - precision_24: 0.0000e+00 - recall_24: 0.0000e+00\n",
            "Epoch 34/45\n",
            "\u001b[1m2077/2077\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - accuracy: 0.1454 - auc_24: 0.4974 - loss: 0.0125 - precision_24: 0.0000e+00 - recall_24: 0.0000e+00\n",
            "Epoch 35/45\n",
            "\u001b[1m2077/2077\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.1449 - auc_24: 0.5000 - loss: 0.0116 - precision_24: 0.0000e+00 - recall_24: 0.0000e+00\n",
            "Epoch 36/45\n",
            "\u001b[1m2077/2077\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.1501 - auc_24: 0.4995 - loss: 0.0124 - precision_24: 0.0000e+00 - recall_24: 0.0000e+00\n",
            "Epoch 37/45\n",
            "\u001b[1m2077/2077\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - accuracy: 0.1728 - auc_24: 0.4993 - loss: 0.0134 - precision_24: 0.0000e+00 - recall_24: 0.0000e+00\n",
            "Epoch 38/45\n",
            "\u001b[1m2077/2077\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 2ms/step - accuracy: 0.1463 - auc_24: 0.4990 - loss: 0.0412 - precision_24: 0.0000e+00 - recall_24: 0.0000e+00\n",
            "Epoch 39/45\n",
            "\u001b[1m2077/2077\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - accuracy: 0.1505 - auc_24: 0.4937 - loss: 0.0112 - precision_24: 0.0000e+00 - recall_24: 0.0000e+00\n",
            "Epoch 40/45\n",
            "\u001b[1m2077/2077\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.1583 - auc_24: 0.4952 - loss: 0.0116 - precision_24: 0.0000e+00 - recall_24: 0.0000e+00\n",
            "Epoch 41/45\n",
            "\u001b[1m2077/2077\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.1827 - auc_24: 0.4993 - loss: 0.0126 - precision_24: 0.0000e+00 - recall_24: 0.0000e+00\n",
            "Epoch 42/45\n",
            "\u001b[1m2077/2077\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - accuracy: 0.3121 - auc_24: 0.4998 - loss: 0.0119 - precision_24: 0.0000e+00 - recall_24: 0.0000e+00\n",
            "Epoch 43/45\n",
            "\u001b[1m2077/2077\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.2451 - auc_24: 0.4998 - loss: 0.0117 - precision_24: 0.0000e+00 - recall_24: 0.0000e+00\n",
            "Epoch 44/45\n",
            "\u001b[1m2077/2077\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.2132 - auc_24: 0.4988 - loss: 0.0126 - precision_24: 0.0000e+00 - recall_24: 0.0000e+00\n",
            "Epoch 45/45\n",
            "\u001b[1m2077/2077\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.2190 - auc_24: 0.4969 - loss: 0.0132 - precision_24: 0.0000e+00 - recall_24: 0.0000e+00\n",
            "\u001b[1m1039/1039\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step\n",
            "[CV] END batch_size=64, epochs=45, model__learn_rate=0.01, model__optimizer=adam; total time= 4.6min\n",
            "Epoch 1/45\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning:\n",
            "\n",
            "Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m2077/2077\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.0785 - auc_25: 0.7849 - loss: 0.0670 - precision_25: 0.1843 - recall_25: 0.1325\n",
            "Epoch 2/45\n",
            "\u001b[1m2077/2077\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - accuracy: 0.0464 - auc_25: 0.8599 - loss: 0.0215 - precision_25: 0.3133 - recall_25: 0.0991\n",
            "Epoch 3/45\n",
            "\u001b[1m2077/2077\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.0114 - auc_25: 0.4899 - loss: 0.0125 - precision_25: 0.0000e+00 - recall_25: 0.0000e+00\n",
            "Epoch 4/45\n",
            "\u001b[1m2077/2077\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.0060 - auc_25: 0.4981 - loss: 0.0123 - precision_25: 0.0000e+00 - recall_25: 0.0000e+00\n",
            "Epoch 5/45\n",
            "\u001b[1m2077/2077\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - accuracy: 0.0517 - auc_25: 0.5587 - loss: 0.0164 - precision_25: 0.0000e+00 - recall_25: 0.0000e+00\n",
            "Epoch 6/45\n",
            "\u001b[1m2077/2077\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 2ms/step - accuracy: 0.1404 - auc_25: 0.4962 - loss: 0.0165 - precision_25: 0.0000e+00 - recall_25: 0.0000e+00\n",
            "Epoch 7/45\n",
            "\u001b[1m2077/2077\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - accuracy: 0.1157 - auc_25: 0.4980 - loss: 0.0134 - precision_25: 0.0000e+00 - recall_25: 0.0000e+00\n",
            "Epoch 8/45\n",
            "\u001b[1m2077/2077\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 2ms/step - accuracy: 0.1140 - auc_25: 0.4997 - loss: 0.0298 - precision_25: 0.0070 - recall_25: 0.0021\n",
            "Epoch 9/45\n",
            "\u001b[1m2077/2077\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - accuracy: 0.1076 - auc_25: 0.4916 - loss: 0.0116 - precision_25: 0.0000e+00 - recall_25: 0.0000e+00\n",
            "Epoch 10/45\n",
            "\u001b[1m2077/2077\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.1381 - auc_25: 0.4966 - loss: 0.0118 - precision_25: 0.0000e+00 - recall_25: 0.0000e+00\n",
            "Epoch 11/45\n",
            "\u001b[1m2077/2077\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.1127 - auc_25: 0.5000 - loss: 0.0148 - precision_25: 0.0000e+00 - recall_25: 0.0000e+00\n",
            "Epoch 12/45\n",
            "\u001b[1m2077/2077\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 3ms/step - accuracy: 0.2116 - auc_25: 0.4990 - loss: 0.0147 - precision_25: 0.0000e+00 - recall_25: 0.0000e+00\n",
            "Epoch 13/45\n",
            "\u001b[1m2077/2077\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.1739 - auc_25: 0.4958 - loss: 0.1451 - precision_25: 0.0000e+00 - recall_25: 0.0000e+00\n",
            "Epoch 14/45\n",
            "\u001b[1m2077/2077\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.1709 - auc_25: 0.5000 - loss: 0.0371 - precision_25: 0.0000e+00 - recall_25: 0.0000e+00\n",
            "Epoch 15/45\n",
            "\u001b[1m2077/2077\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - accuracy: 0.2465 - auc_25: 0.4978 - loss: 0.0170 - precision_25: 0.0000e+00 - recall_25: 0.0000e+00\n",
            "Epoch 16/45\n",
            "\u001b[1m2077/2077\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.1536 - auc_25: 0.4999 - loss: 0.0439 - precision_25: 0.0000e+00 - recall_25: 0.0000e+00\n",
            "Epoch 17/45\n",
            "\u001b[1m2077/2077\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.0977 - auc_25: 0.4916 - loss: 0.0110 - precision_25: 0.0000e+00 - recall_25: 0.0000e+00\n",
            "Epoch 18/45\n",
            "\u001b[1m2077/2077\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - accuracy: 0.1052 - auc_25: 0.4952 - loss: 0.0131 - precision_25: 0.0000e+00 - recall_25: 0.0000e+00\n",
            "Epoch 19/45\n",
            "\u001b[1m2077/2077\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.1261 - auc_25: 0.4986 - loss: 0.0129 - precision_25: 0.0000e+00 - recall_25: 0.0000e+00\n",
            "Epoch 20/45\n",
            "\u001b[1m2077/2077\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.1625 - auc_25: 0.4998 - loss: 0.0169 - precision_25: 0.0000e+00 - recall_25: 0.0000e+00\n",
            "Epoch 21/45\n",
            "\u001b[1m2077/2077\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - accuracy: 0.1665 - auc_25: 0.4974 - loss: 0.0140 - precision_25: 0.0000e+00 - recall_25: 0.0000e+00\n",
            "Epoch 22/45\n",
            "\u001b[1m2077/2077\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 3ms/step - accuracy: 0.2954 - auc_25: 0.4993 - loss: 0.1757 - precision_25: 0.0000e+00 - recall_25: 0.0000e+00\n",
            "Epoch 23/45\n",
            "\u001b[1m2077/2077\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - accuracy: 0.2917 - auc_25: 0.4998 - loss: 0.0131 - precision_25: 0.0000e+00 - recall_25: 0.0000e+00\n",
            "Epoch 24/45\n",
            "\u001b[1m2077/2077\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 2ms/step - accuracy: 0.3199 - auc_25: 0.4993 - loss: 0.0128 - precision_25: 0.0000e+00 - recall_25: 0.0000e+00\n",
            "Epoch 25/45\n",
            "\u001b[1m2077/2077\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - accuracy: 0.2468 - auc_25: 0.4998 - loss: 0.0130 - precision_25: 0.0000e+00 - recall_25: 0.0000e+00\n",
            "Epoch 26/45\n",
            "\u001b[1m2077/2077\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.1631 - auc_25: 0.5000 - loss: 0.0124 - precision_25: 0.0000e+00 - recall_25: 0.0000e+00\n",
            "Epoch 27/45\n",
            "\u001b[1m2077/2077\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.2293 - auc_25: 0.4990 - loss: 0.6488 - precision_25: 0.0000e+00 - recall_25: 0.0000e+00\n",
            "Epoch 28/45\n",
            "\u001b[1m2077/2077\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - accuracy: 0.0798 - auc_25: 0.4992 - loss: 0.0408 - precision_25: 0.0000e+00 - recall_25: 0.0000e+00\n",
            "Epoch 29/45\n",
            "\u001b[1m2077/2077\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 2ms/step - accuracy: 0.2035 - auc_25: 0.4993 - loss: 0.0123 - precision_25: 0.0000e+00 - recall_25: 0.0000e+00\n",
            "Epoch 30/45\n",
            "\u001b[1m2077/2077\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - accuracy: 0.1879 - auc_25: 0.5000 - loss: 0.0113 - precision_25: 0.0000e+00 - recall_25: 0.0000e+00\n",
            "Epoch 31/45\n",
            "\u001b[1m2077/2077\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 2ms/step - accuracy: 0.1951 - auc_25: 0.5000 - loss: 0.0132 - precision_25: 0.0000e+00 - recall_25: 0.0000e+00\n",
            "Epoch 32/45\n",
            "\u001b[1m2077/2077\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - accuracy: 0.2073 - auc_25: 0.4998 - loss: 0.0132 - precision_25: 0.0000e+00 - recall_25: 0.0000e+00\n",
            "Epoch 33/45\n",
            "\u001b[1m2077/2077\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.2501 - auc_25: 0.4983 - loss: 0.0117 - precision_25: 0.0000e+00 - recall_25: 0.0000e+00\n",
            "Epoch 34/45\n",
            "\u001b[1m2077/2077\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.1728 - auc_25: 0.4986 - loss: 0.0128 - precision_25: 0.0000e+00 - recall_25: 0.0000e+00\n",
            "Epoch 35/45\n",
            "\u001b[1m2077/2077\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - accuracy: 0.1992 - auc_25: 0.4964 - loss: 0.0149 - precision_25: 0.0000e+00 - recall_25: 0.0000e+00\n",
            "Epoch 36/45\n",
            "\u001b[1m2077/2077\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.1494 - auc_25: 0.4976 - loss: 0.0128 - precision_25: 0.0000e+00 - recall_25: 0.0000e+00\n",
            "Epoch 37/45\n",
            "\u001b[1m2077/2077\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.1638 - auc_25: 0.4918 - loss: 0.0262 - precision_25: 0.0000e+00 - recall_25: 0.0000e+00\n",
            "Epoch 38/45\n",
            "\u001b[1m2077/2077\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 2ms/step - accuracy: 0.2017 - auc_25: 0.4990 - loss: 0.0471 - precision_25: 0.0000e+00 - recall_25: 0.0000e+00\n",
            "Epoch 39/45\n",
            "\u001b[1m2077/2077\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - accuracy: 0.1637 - auc_25: 0.4974 - loss: 0.0118 - precision_25: 0.0000e+00 - recall_25: 0.0000e+00\n",
            "Epoch 40/45\n",
            "\u001b[1m2077/2077\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.1761 - auc_25: 0.4974 - loss: 0.0143 - precision_25: 0.0000e+00 - recall_25: 0.0000e+00\n",
            "Epoch 41/45\n",
            "\u001b[1m2077/2077\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.1380 - auc_25: 0.4990 - loss: 0.0265 - precision_25: 0.0000e+00 - recall_25: 0.0000e+00\n",
            "Epoch 42/45\n",
            "\u001b[1m2077/2077\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - accuracy: 0.1552 - auc_25: 0.4964 - loss: 0.0118 - precision_25: 0.0000e+00 - recall_25: 0.0000e+00\n",
            "Epoch 43/45\n",
            "\u001b[1m2077/2077\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 2ms/step - accuracy: 0.1570 - auc_25: 0.4995 - loss: 0.0126 - precision_25: 0.0000e+00 - recall_25: 0.0000e+00\n",
            "Epoch 44/45\n",
            "\u001b[1m2077/2077\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - accuracy: 0.1653 - auc_25: 0.4988 - loss: 0.0120 - precision_25: 0.0000e+00 - recall_25: 0.0000e+00\n",
            "Epoch 45/45\n",
            "\u001b[1m2077/2077\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.1920 - auc_25: 0.5000 - loss: 0.0135 - precision_25: 0.0000e+00 - recall_25: 0.0000e+00\n",
            "\u001b[1m1039/1039\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step\n",
            "[CV] END batch_size=64, epochs=45, model__learn_rate=0.01, model__optimizer=adam; total time= 4.7min\n",
            "Epoch 1/45\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning:\n",
            "\n",
            "Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py:425: FitFailedWarning:\n",
            "\n",
            "\n",
            "15 fits failed out of a total of 30.\n",
            "The score on these train-test partitions for these parameters will be set to nan.\n",
            "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
            "\n",
            "Below are more details about the failures:\n",
            "--------------------------------------------------------------------------------\n",
            "15 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py\", line 729, in _fit_and_score\n",
            "    def _fit_and_score(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/scikeras/wrappers.py\", line 1501, in fit\n",
            "    super().fit(X=X, y=y, sample_weight=sample_weight, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/scikeras/wrappers.py\", line 770, in fit\n",
            "    self._fit(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/scikeras/wrappers.py\", line 928, in _fit\n",
            "    self._ensure_compiled_model()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/scikeras/wrappers.py\", line 439, in _ensure_compiled_model\n",
            "    if not self.model_.compiled:\n",
            "AttributeError: 'NoneType' object has no attribute 'compiled'\n",
            "\n",
            "\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_search.py:979: UserWarning:\n",
            "\n",
            "One or more of the test scores are non-finite: [       nan        nan 0.99934793 0.99928773 0.99859554        nan\n",
            "        nan 0.99821432        nan 0.99821432]\n",
            "\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_search.py:979: UserWarning:\n",
            "\n",
            "One or more of the test scores are non-finite: [       nan        nan 0.87913399 0.82457225 0.2740113         nan\n",
            "        nan 0.                nan 0.        ]\n",
            "\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_search.py:979: UserWarning:\n",
            "\n",
            "One or more of the test scores are non-finite: [       nan        nan 0.73612496 0.7754356  0.2740113         nan\n",
            "        nan 0.                nan 0.        ]\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1558/1558\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - accuracy: 0.0214 - auc_26: 0.8045 - loss: 0.0597 - precision_26: 0.3101 - recall_26: 0.4794\n",
            "Epoch 2/45\n",
            "\u001b[1m1558/1558\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.0106 - auc_26: 0.9123 - loss: 0.0108 - precision_26: 0.8115 - recall_26: 0.7508\n",
            "Epoch 3/45\n",
            "\u001b[1m1558/1558\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.0027 - auc_26: 0.9021 - loss: 0.0089 - precision_26: 0.8398 - recall_26: 0.7027\n",
            "Epoch 4/45\n",
            "\u001b[1m1558/1558\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.0020 - auc_26: 0.9246 - loss: 0.0051 - precision_26: 0.8492 - recall_26: 0.7457\n",
            "Epoch 5/45\n",
            "\u001b[1m1558/1558\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - accuracy: 0.0016 - auc_26: 0.9247 - loss: 0.0055 - precision_26: 0.8567 - recall_26: 0.7291\n",
            "Epoch 6/45\n",
            "\u001b[1m1558/1558\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 4.5931e-04 - auc_26: 0.9491 - loss: 0.0034 - precision_26: 0.8545 - recall_26: 0.7816\n",
            "Epoch 7/45\n",
            "\u001b[1m1558/1558\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.0029 - auc_26: 0.9092 - loss: 0.0065 - precision_26: 0.8308 - recall_26: 0.6760\n",
            "Epoch 8/45\n",
            "\u001b[1m1558/1558\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 4.4425e-04 - auc_26: 0.9407 - loss: 0.0043 - precision_26: 0.8779 - recall_26: 0.7431\n",
            "Epoch 9/45\n",
            "\u001b[1m1558/1558\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.0083 - auc_26: 0.9450 - loss: 0.0063 - precision_26: 0.8617 - recall_26: 0.7633\n",
            "Epoch 10/45\n",
            "\u001b[1m1558/1558\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 2.7716e-04 - auc_26: 0.9404 - loss: 0.0040 - precision_26: 0.8753 - recall_26: 0.7365\n",
            "Epoch 11/45\n",
            "\u001b[1m1558/1558\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 2.4250e-04 - auc_26: 0.9388 - loss: 0.0031 - precision_26: 0.8688 - recall_26: 0.7875\n",
            "Epoch 12/45\n",
            "\u001b[1m1558/1558\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 1.0560e-04 - auc_26: 0.9509 - loss: 0.0027 - precision_26: 0.8861 - recall_26: 0.7682\n",
            "Epoch 13/45\n",
            "\u001b[1m1558/1558\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 2.1278e-04 - auc_26: 0.9548 - loss: 0.0026 - precision_26: 0.9166 - recall_26: 0.7566\n",
            "Epoch 14/45\n",
            "\u001b[1m1558/1558\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 5.8126e-04 - auc_26: 0.9483 - loss: 0.0037 - precision_26: 0.8876 - recall_26: 0.7558\n",
            "Epoch 15/45\n",
            "\u001b[1m1558/1558\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 9.2604e-05 - auc_26: 0.9541 - loss: 0.0026 - precision_26: 0.9410 - recall_26: 0.8377\n",
            "Epoch 16/45\n",
            "\u001b[1m1558/1558\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 2.2055e-04 - auc_26: 0.9597 - loss: 0.0027 - precision_26: 0.9248 - recall_26: 0.7394\n",
            "Epoch 17/45\n",
            "\u001b[1m1558/1558\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 2.3742e-04 - auc_26: 0.9454 - loss: 0.0028 - precision_26: 0.9313 - recall_26: 0.7961\n",
            "Epoch 18/45\n",
            "\u001b[1m1558/1558\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 1.1707e-04 - auc_26: 0.9614 - loss: 0.0024 - precision_26: 0.9236 - recall_26: 0.8062\n",
            "Epoch 19/45\n",
            "\u001b[1m1558/1558\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 1.5505e-04 - auc_26: 0.9653 - loss: 0.0024 - precision_26: 0.9451 - recall_26: 0.7724\n",
            "Epoch 20/45\n",
            "\u001b[1m1558/1558\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 2.2202e-04 - auc_26: 0.9606 - loss: 0.0023 - precision_26: 0.9453 - recall_26: 0.8257\n",
            "Epoch 21/45\n",
            "\u001b[1m1558/1558\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - accuracy: 1.5681e-04 - auc_26: 0.9548 - loss: 0.0023 - precision_26: 0.9236 - recall_26: 0.8243\n",
            "Epoch 22/45\n",
            "\u001b[1m1558/1558\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 1.4613e-04 - auc_26: 0.9642 - loss: 0.0021 - precision_26: 0.9287 - recall_26: 0.8316\n",
            "Epoch 23/45\n",
            "\u001b[1m1558/1558\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 3.0519e-04 - auc_26: 0.9662 - loss: 0.0022 - precision_26: 0.9443 - recall_26: 0.8393\n",
            "Epoch 24/45\n",
            "\u001b[1m1558/1558\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - accuracy: 4.5717e-04 - auc_26: 0.9662 - loss: 0.0019 - precision_26: 0.9534 - recall_26: 0.8620\n",
            "Epoch 25/45\n",
            "\u001b[1m1558/1558\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 2ms/step - accuracy: 4.7819e-04 - auc_26: 0.9618 - loss: 0.0023 - precision_26: 0.9452 - recall_26: 0.8585\n",
            "Epoch 26/45\n",
            "\u001b[1m1558/1558\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 2.7290e-04 - auc_26: 0.9511 - loss: 0.0020 - precision_26: 0.9640 - recall_26: 0.8324\n",
            "Epoch 27/45\n",
            "\u001b[1m1558/1558\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 1.1430e-04 - auc_26: 0.9633 - loss: 0.0022 - precision_26: 0.9436 - recall_26: 0.8280\n",
            "Epoch 28/45\n",
            "\u001b[1m1558/1558\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 2.8616e-04 - auc_26: 0.9589 - loss: 0.0021 - precision_26: 0.9337 - recall_26: 0.8194\n",
            "Epoch 29/45\n",
            "\u001b[1m1558/1558\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 3.1497e-04 - auc_26: 0.9711 - loss: 0.0018 - precision_26: 0.9696 - recall_26: 0.8626\n",
            "Epoch 30/45\n",
            "\u001b[1m1558/1558\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - accuracy: 3.1929e-04 - auc_26: 0.9564 - loss: 0.0023 - precision_26: 0.9626 - recall_26: 0.8236\n",
            "Epoch 31/45\n",
            "\u001b[1m1558/1558\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 8.1851e-04 - auc_26: 0.9643 - loss: 0.0024 - precision_26: 0.9568 - recall_26: 0.8129\n",
            "Epoch 32/45\n",
            "\u001b[1m1558/1558\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - accuracy: 5.5245e-04 - auc_26: 0.9629 - loss: 0.0015 - precision_26: 0.9639 - recall_26: 0.8654\n",
            "Epoch 33/45\n",
            "\u001b[1m1558/1558\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 4.9819e-04 - auc_26: 0.9676 - loss: 0.0022 - precision_26: 0.9566 - recall_26: 0.8303\n",
            "Epoch 34/45\n",
            "\u001b[1m1558/1558\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 5.7526e-04 - auc_26: 0.9718 - loss: 0.0020 - precision_26: 0.9307 - recall_26: 0.8483\n",
            "Epoch 35/45\n",
            "\u001b[1m1558/1558\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 5.6461e-04 - auc_26: 0.9711 - loss: 0.0021 - precision_26: 0.9658 - recall_26: 0.7871\n",
            "Epoch 36/45\n",
            "\u001b[1m1558/1558\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 9.7911e-04 - auc_26: 0.9731 - loss: 0.0014 - precision_26: 0.9535 - recall_26: 0.8509\n",
            "Epoch 37/45\n",
            "\u001b[1m1558/1558\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 6.6704e-04 - auc_26: 0.9576 - loss: 0.0019 - precision_26: 0.9556 - recall_26: 0.8240\n",
            "Epoch 38/45\n",
            "\u001b[1m1558/1558\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - accuracy: 7.5081e-04 - auc_26: 0.9789 - loss: 0.0013 - precision_26: 0.9539 - recall_26: 0.8926\n",
            "Epoch 39/45\n",
            "\u001b[1m1558/1558\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.0013 - auc_26: 0.9566 - loss: 0.0016 - precision_26: 0.9676 - recall_26: 0.8314\n",
            "Epoch 40/45\n",
            "\u001b[1m1558/1558\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 9.4392e-04 - auc_26: 0.9756 - loss: 0.0016 - precision_26: 0.9637 - recall_26: 0.8660\n",
            "Epoch 41/45\n",
            "\u001b[1m1558/1558\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - accuracy: 0.0011 - auc_26: 0.9749 - loss: 0.0016 - precision_26: 0.9583 - recall_26: 0.8586\n",
            "Epoch 42/45\n",
            "\u001b[1m1558/1558\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.0026 - auc_26: 0.9796 - loss: 0.0013 - precision_26: 0.9719 - recall_26: 0.8820\n",
            "Epoch 43/45\n",
            "\u001b[1m1558/1558\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.0025 - auc_26: 0.9733 - loss: 0.0013 - precision_26: 0.9608 - recall_26: 0.8615\n",
            "Epoch 44/45\n",
            "\u001b[1m1558/1558\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - accuracy: 0.0022 - auc_26: 0.9811 - loss: 0.0014 - precision_26: 0.9626 - recall_26: 0.8587\n",
            "Epoch 45/45\n",
            "\u001b[1m1558/1558\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.0031 - auc_26: 0.9831 - loss: 0.0013 - precision_26: 0.9711 - recall_26: 0.8600\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RandomizedSearchCV(cv=3,\n",
              "                   estimator=KerasClassifier(learn_rate=0.01, model=<function create_model at 0x7ade3d0d6f80>, optimizer='adam', x_train=               V1         V2         V3        V4         V5        V6  \\\n",
              "61278    1.482387  -0.588294  -1.804074 -1.826507   1.883006  2.862792   \n",
              "8845    -4.727713   3.044469  -5.598354  5.928191  -2.190770 -1.529323   \n",
              "151007 -26.457745  16.497472 -30.177317  8.904157 -17.892600 -1.227904   \n",
              "6427     0.725646   2.300894  -5.3299...\n",
              "135603   24.18  \n",
              "\n",
              "[688 rows x 29 columns]),\n",
              "                   n_jobs=1,\n",
              "                   param_distributions={'batch_size': [32, 64, 128],\n",
              "                                        'epochs': [20, 30, 45],\n",
              "                                        'model__learn_rate': [0.001, 0.01, 0.1],\n",
              "                                        'model__optimizer': ['adam',\n",
              "                                                             'rmsprop']},\n",
              "                   random_state=42, refit='accuracy',\n",
              "                   scoring={'accuracy': make_scorer(accuracy_score),\n",
              "                            'precision': make_scorer(precision_score),\n",
              "                            'recall': make_scorer(recall_score)},\n",
              "                   verbose=2)"
            ],
            "text/html": [
              "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomizedSearchCV(cv=3,\n",
              "                   estimator=KerasClassifier(learn_rate=0.01, model=&lt;function create_model at 0x7ade3d0d6f80&gt;, optimizer=&#x27;adam&#x27;, x_train=               V1         V2         V3        V4         V5        V6  \\\n",
              "61278    1.482387  -0.588294  -1.804074 -1.826507   1.883006  2.862792   \n",
              "8845    -4.727713   3.044469  -5.598354  5.928191  -2.190770 -1.529323   \n",
              "151007 -26.457745  16.497472 -30.177317  8.904157 -17.892600 -1.227904   \n",
              "6427     0.725646   2.300894  -5.3299...\n",
              "135603   24.18  \n",
              "\n",
              "[688 rows x 29 columns]),\n",
              "                   n_jobs=1,\n",
              "                   param_distributions={&#x27;batch_size&#x27;: [32, 64, 128],\n",
              "                                        &#x27;epochs&#x27;: [20, 30, 45],\n",
              "                                        &#x27;model__learn_rate&#x27;: [0.001, 0.01, 0.1],\n",
              "                                        &#x27;model__optimizer&#x27;: [&#x27;adam&#x27;,\n",
              "                                                             &#x27;rmsprop&#x27;]},\n",
              "                   random_state=42, refit=&#x27;accuracy&#x27;,\n",
              "                   scoring={&#x27;accuracy&#x27;: make_scorer(accuracy_score),\n",
              "                            &#x27;precision&#x27;: make_scorer(precision_score),\n",
              "                            &#x27;recall&#x27;: make_scorer(recall_score)},\n",
              "                   verbose=2)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomizedSearchCV</label><div class=\"sk-toggleable__content\"><pre>RandomizedSearchCV(cv=3,\n",
              "                   estimator=KerasClassifier(learn_rate=0.01, model=&lt;function create_model at 0x7ade3d0d6f80&gt;, optimizer=&#x27;adam&#x27;, x_train=               V1         V2         V3        V4         V5        V6  \\\n",
              "61278    1.482387  -0.588294  -1.804074 -1.826507   1.883006  2.862792   \n",
              "8845    -4.727713   3.044469  -5.598354  5.928191  -2.190770 -1.529323   \n",
              "151007 -26.457745  16.497472 -30.177317  8.904157 -17.892600 -1.227904   \n",
              "6427     0.725646   2.300894  -5.3299...\n",
              "135603   24.18  \n",
              "\n",
              "[688 rows x 29 columns]),\n",
              "                   n_jobs=1,\n",
              "                   param_distributions={&#x27;batch_size&#x27;: [32, 64, 128],\n",
              "                                        &#x27;epochs&#x27;: [20, 30, 45],\n",
              "                                        &#x27;model__learn_rate&#x27;: [0.001, 0.01, 0.1],\n",
              "                                        &#x27;model__optimizer&#x27;: [&#x27;adam&#x27;,\n",
              "                                                             &#x27;rmsprop&#x27;]},\n",
              "                   random_state=42, refit=&#x27;accuracy&#x27;,\n",
              "                   scoring={&#x27;accuracy&#x27;: make_scorer(accuracy_score),\n",
              "                            &#x27;precision&#x27;: make_scorer(precision_score),\n",
              "                            &#x27;recall&#x27;: make_scorer(recall_score)},\n",
              "                   verbose=2)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: KerasClassifier</label><div class=\"sk-toggleable__content\"><pre>KerasClassifier(\n",
              "\tmodel=&lt;function create_model at 0x7ade3d0d6f80&gt;\n",
              "\tbuild_fn=None\n",
              "\twarm_start=False\n",
              "\trandom_state=None\n",
              "\toptimizer=adam\n",
              "\tloss=None\n",
              "\tmetrics=None\n",
              "\tbatch_size=None\n",
              "\tvalidation_batch_size=None\n",
              "\tverbose=1\n",
              "\tcallbacks=None\n",
              "\tvalidation_split=0.0\n",
              "\tshuffle=True\n",
              "\trun_eagerly=False\n",
              "\tepochs=1\n",
              "\tx_train=               V1         V2         V3        V4         V5        V6  \\\n",
              "61278    1.482387  -0.588294  -1.804074 -1.826507   1.883006  2.862792   \n",
              "8845    -4.727713   3.044469  -5.598354  5.928191  -2.190770 -1.529323   \n",
              "151007 -26.457745  16.497472 -30.177317  8.904157 -17.892600 -1.227904   \n",
              "6427     0.725646   2.300894  -5.329976  4.007683  -1.730411 -1.732193   \n",
              "5031    -2.122206   2.501710   0.679881  2.027273  -0.440994  1.174856   \n",
              "...           ...        ...        ...       ...        ...       ...   \n",
              "35123   -2.045484  -0.603428  -0.386028 -3.278179   0.840525  3.868593   \n",
              "84735   -0.377304   0.572787   1.333869 -0.000070   0.304511 -0.084981   \n",
              "189587   0.909124   1.337658  -4.484728  3.245358  -0.417809 -0.762119   \n",
              "175852   1.554783  -1.059409  -0.658570  0.112271  -0.724124 -0.288185   \n",
              "135603  -2.373043   2.563438   0.225781  2.274042  -1.008791 -0.378413   \n",
              "\n",
              "               V7         V8        V9        V10  ...       V20       V21  \\\n",
              "61278   -0.593291   0.586123 -1.286408   0.741492  ...  0.212306  0.143951   \n",
              "8845    -4.487422   0.916392 -1.307010  -4.138891  ... -0.207759  0.650988   \n",
              "151007 -31.197329 -11.438920 -9.462573 -22.187089  ...  2.812241 -8.755698   \n",
              "6427    -3.968593   1.063728 -0.486097  -4.624985  ...  0.504646  0.589669   \n",
              "5031    -0.921126  -2.554824  0.744768  -0.032509  ... -1.063652  2.662282   \n",
              "...           ...        ...       ...        ...  ...       ...       ...   \n",
              "35123    0.785816   1.183953  1.009150  -2.479646  ... -0.125064  0.147327   \n",
              "84735    0.497673   0.022442  0.100338  -0.664655  ...  0.001642 -0.023137   \n",
              "189587  -2.506349   0.694164 -0.467556  -4.565260  ...  0.445573  0.586829   \n",
              "175852  -0.241162  -0.044019  0.879991  -0.121252  ...  0.308820  0.021068   \n",
              "135603  -0.474627   1.555529 -2.365868   0.060909  ... -0.513654 -0.098723   \n",
              "\n",
              "             V22       V23       V24       V25       V26       V27       V28  \\\n",
              "61278   0.173444 -0.209856  1.046919  0.948468 -0.070931 -0.028652 -0.002851   \n",
              "8845    0.254983  0.628843 -0.238128 -0.671332 -0.033590 -1.331777  0.705698   \n",
              "151007  3.460893  0.896538  0.254836 -0.738097 -0.966564 -7.263482 -1.324884   \n",
              "6427    0.109541  0.601045 -0.364700 -1.843078  0.351909  0.594550  0.099372   \n",
              "5031   -1.954434  0.352348 -0.599831  0.091996 -0.227467 -0.481958 -0.334716   \n",
              "...          ...       ...       ...       ...       ...       ...       ...   \n",
              "35123   0.243740 -0.357663  1.052686  1.112681 -0.749815 -0.005714 -0.173156   \n",
              "84735   0.118389 -0.270359 -0.393864 -0.062653  0.510585  0.094780  0.126249   \n",
              "189587  0.594078 -0.252120  0.325439  0.562766 -0.256278  0.652674  0.319879   \n",
              "175852 -0.344273  0.131801 -0.336523 -0.569150 -0.302588 -0.035571 -0.008578   \n",
              "135603 -1.084756  0.388042  0.463112 -0.517477 -0.517094 -0.907652 -0.148523   \n",
              "\n",
              "        Amount  \n",
              "61278    25.00  \n",
              "8845     30.39  \n",
              "151007    1.00  \n",
              "6427      1.00  \n",
              "5031     59.99  \n",
              "...        ...  \n",
              "35123   350.00  \n",
              "84735    12.95  \n",
              "189587   67.90  \n",
              "175852  229.88  \n",
              "135603   24.18  \n",
              "\n",
              "[688 rows x 29 columns]\n",
              "\tlearn_rate=0.01\n",
              "\tclass_weight=None\n",
              ")</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">KerasClassifier</label><div class=\"sk-toggleable__content\"><pre>KerasClassifier(\n",
              "\tmodel=&lt;function create_model at 0x7ade3d0d6f80&gt;\n",
              "\tbuild_fn=None\n",
              "\twarm_start=False\n",
              "\trandom_state=None\n",
              "\toptimizer=adam\n",
              "\tloss=None\n",
              "\tmetrics=None\n",
              "\tbatch_size=None\n",
              "\tvalidation_batch_size=None\n",
              "\tverbose=1\n",
              "\tcallbacks=None\n",
              "\tvalidation_split=0.0\n",
              "\tshuffle=True\n",
              "\trun_eagerly=False\n",
              "\tepochs=1\n",
              "\tx_train=               V1         V2         V3        V4         V5        V6  \\\n",
              "61278    1.482387  -0.588294  -1.804074 -1.826507   1.883006  2.862792   \n",
              "8845    -4.727713   3.044469  -5.598354  5.928191  -2.190770 -1.529323   \n",
              "151007 -26.457745  16.497472 -30.177317  8.904157 -17.892600 -1.227904   \n",
              "6427     0.725646   2.300894  -5.329976  4.007683  -1.730411 -1.732193   \n",
              "5031    -2.122206   2.501710   0.679881  2.027273  -0.440994  1.174856   \n",
              "...           ...        ...        ...       ...        ...       ...   \n",
              "35123   -2.045484  -0.603428  -0.386028 -3.278179   0.840525  3.868593   \n",
              "84735   -0.377304   0.572787   1.333869 -0.000070   0.304511 -0.084981   \n",
              "189587   0.909124   1.337658  -4.484728  3.245358  -0.417809 -0.762119   \n",
              "175852   1.554783  -1.059409  -0.658570  0.112271  -0.724124 -0.288185   \n",
              "135603  -2.373043   2.563438   0.225781  2.274042  -1.008791 -0.378413   \n",
              "\n",
              "               V7         V8        V9        V10  ...       V20       V21  \\\n",
              "61278   -0.593291   0.586123 -1.286408   0.741492  ...  0.212306  0.143951   \n",
              "8845    -4.487422   0.916392 -1.307010  -4.138891  ... -0.207759  0.650988   \n",
              "151007 -31.197329 -11.438920 -9.462573 -22.187089  ...  2.812241 -8.755698   \n",
              "6427    -3.968593   1.063728 -0.486097  -4.624985  ...  0.504646  0.589669   \n",
              "5031    -0.921126  -2.554824  0.744768  -0.032509  ... -1.063652  2.662282   \n",
              "...           ...        ...       ...        ...  ...       ...       ...   \n",
              "35123    0.785816   1.183953  1.009150  -2.479646  ... -0.125064  0.147327   \n",
              "84735    0.497673   0.022442  0.100338  -0.664655  ...  0.001642 -0.023137   \n",
              "189587  -2.506349   0.694164 -0.467556  -4.565260  ...  0.445573  0.586829   \n",
              "175852  -0.241162  -0.044019  0.879991  -0.121252  ...  0.308820  0.021068   \n",
              "135603  -0.474627   1.555529 -2.365868   0.060909  ... -0.513654 -0.098723   \n",
              "\n",
              "             V22       V23       V24       V25       V26       V27       V28  \\\n",
              "61278   0.173444 -0.209856  1.046919  0.948468 -0.070931 -0.028652 -0.002851   \n",
              "8845    0.254983  0.628843 -0.238128 -0.671332 -0.033590 -1.331777  0.705698   \n",
              "151007  3.460893  0.896538  0.254836 -0.738097 -0.966564 -7.263482 -1.324884   \n",
              "6427    0.109541  0.601045 -0.364700 -1.843078  0.351909  0.594550  0.099372   \n",
              "5031   -1.954434  0.352348 -0.599831  0.091996 -0.227467 -0.481958 -0.334716   \n",
              "...          ...       ...       ...       ...       ...       ...       ...   \n",
              "35123   0.243740 -0.357663  1.052686  1.112681 -0.749815 -0.005714 -0.173156   \n",
              "84735   0.118389 -0.270359 -0.393864 -0.062653  0.510585  0.094780  0.126249   \n",
              "189587  0.594078 -0.252120  0.325439  0.562766 -0.256278  0.652674  0.319879   \n",
              "175852 -0.344273  0.131801 -0.336523 -0.569150 -0.302588 -0.035571 -0.008578   \n",
              "135603 -1.084756  0.388042  0.463112 -0.517477 -0.517094 -0.907652 -0.148523   \n",
              "\n",
              "        Amount  \n",
              "61278    25.00  \n",
              "8845     30.39  \n",
              "151007    1.00  \n",
              "6427      1.00  \n",
              "5031     59.99  \n",
              "...        ...  \n",
              "35123   350.00  \n",
              "84735    12.95  \n",
              "189587   67.90  \n",
              "175852  229.88  \n",
              "135603   24.18  \n",
              "\n",
              "[688 rows x 29 columns]\n",
              "\tlearn_rate=0.01\n",
              "\tclass_weight=None\n",
              ")</pre></div></div></div></div></div></div></div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 92
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(random_search.best_params_)\n",
        "best_model = random_search.best_estimator_"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s6GkDR0nNl99",
        "outputId": "9b199188-5823-4122-d5e2-d0df27dd976a"
      },
      "execution_count": 93,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'model__optimizer': 'adam', 'model__learn_rate': 0.001, 'epochs': 45, 'batch_size': 128}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Nova Função de criação do modelo, com base nos hiperparâmetros"
      ],
      "metadata": {
        "id": "R1-mkwQYIFEG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def create_model(x_train, optimizer='adam', learn_rate=0.001):\n",
        "  # Define a arquitetura do modelo (arquitetura em pirâmide)\n",
        "  model = Sequential([\n",
        "    Input(shape=(x_train.shape[1],)),\n",
        "    Dense(64, activation='relu'),\n",
        "    Dense(32, activation='relu'),\n",
        "    Dense(16, activation='relu'),\n",
        "    Dense(1, activation='sigmoid')\n",
        "  ])\n",
        "\n",
        "  optimizer = Adam(learning_rate=learn_rate)\n",
        "\n",
        "  model.compile(\n",
        "      optimizer=optimizer,\n",
        "      loss='binary_crossentropy',\n",
        "      metrics=[Accuracy(),\n",
        "                Precision(),\n",
        "                Recall(),\n",
        "                AUC()])\n",
        "\n",
        "  return model"
      ],
      "metadata": {
        "id": "4fsPM-PfwTll"
      },
      "execution_count": 114,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X = df.drop(columns=['Time', 'Class'], axis=1)\n",
        "y = df['Class']"
      ],
      "metadata": {
        "id": "ZBX4wjXTIKmb"
      },
      "execution_count": 115,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)"
      ],
      "metadata": {
        "id": "vdkmkIoVJCQH"
      },
      "execution_count": 116,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = create_model(X_train)\n",
        "\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 257
        },
        "id": "ww4jnApbJJ8I",
        "outputId": "7a2491a6-18db-4ab1-9d0f-e3897123f318"
      },
      "execution_count": 117,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential_51\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_51\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ dense_198 (\u001b[38;5;33mDense\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                  │           \u001b[38;5;34m1,920\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_199 (\u001b[38;5;33mDense\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)                  │           \u001b[38;5;34m2,080\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_200 (\u001b[38;5;33mDense\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m)                  │             \u001b[38;5;34m528\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_201 (\u001b[38;5;33mDense\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)                   │              \u001b[38;5;34m17\u001b[0m │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ dense_198 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                  │           <span style=\"color: #00af00; text-decoration-color: #00af00\">1,920</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_199 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)                  │           <span style=\"color: #00af00; text-decoration-color: #00af00\">2,080</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_200 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)                  │             <span style=\"color: #00af00; text-decoration-color: #00af00\">528</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_201 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)                   │              <span style=\"color: #00af00; text-decoration-color: #00af00\">17</span> │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m4,545\u001b[0m (17.75 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">4,545</span> (17.75 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m4,545\u001b[0m (17.75 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">4,545</span> (17.75 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(X_train_r,\n",
        "                    y_train_r.to_numpy(),\n",
        "                    epochs=45,\n",
        "                    batch_size=128,\n",
        "                    verbose=1,\n",
        "                    validation_data=(X_test_r, y_test_r))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q86OoSmfJEqi",
        "outputId": "6ecca5fa-aa5a-4eb5-9ef6-e26eeabf0c68"
      },
      "execution_count": 119,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/45\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.0193 - auc_30: 0.9277 - loss: 0.6424 - precision_30: 0.9635 - recall_30: 0.7685 - val_accuracy: 0.0270 - val_auc_30: 0.9728 - val_loss: 0.2709 - val_precision_30: 1.0000 - val_recall_30: 0.8767\n",
            "Epoch 2/45\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.0442 - auc_30: 0.9700 - loss: 0.2620 - precision_30: 0.9648 - recall_30: 0.8949 - val_accuracy: 0.1486 - val_auc_30: 0.9790 - val_loss: 0.1757 - val_precision_30: 0.9301 - val_recall_30: 0.9110\n",
            "Epoch 3/45\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.1471 - auc_30: 0.9703 - loss: 0.2668 - precision_30: 0.9256 - recall_30: 0.9318 - val_accuracy: 0.1520 - val_auc_30: 0.9646 - val_loss: 0.2792 - val_precision_30: 0.9357 - val_recall_30: 0.8973\n",
            "Epoch 4/45\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.1471 - auc_30: 0.9878 - loss: 0.1373 - precision_30: 0.9359 - recall_30: 0.9376 - val_accuracy: 0.1419 - val_auc_30: 0.9766 - val_loss: 0.2053 - val_precision_30: 0.9291 - val_recall_30: 0.8973\n",
            "Epoch 5/45\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.1442 - auc_30: 0.9857 - loss: 0.1377 - precision_30: 0.9604 - recall_30: 0.9289 - val_accuracy: 0.1351 - val_auc_30: 0.9812 - val_loss: 0.1704 - val_precision_30: 0.9441 - val_recall_30: 0.9247\n",
            "Epoch 6/45\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.1303 - auc_30: 0.9894 - loss: 0.1179 - precision_30: 0.9501 - recall_30: 0.9480 - val_accuracy: 0.1149 - val_auc_30: 0.9558 - val_loss: 0.3737 - val_precision_30: 0.9552 - val_recall_30: 0.8767\n",
            "Epoch 7/45\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.1119 - auc_30: 0.9769 - loss: 0.1667 - precision_30: 0.9763 - recall_30: 0.9205 - val_accuracy: 0.1047 - val_auc_30: 0.9737 - val_loss: 0.1987 - val_precision_30: 0.9559 - val_recall_30: 0.8904\n",
            "Epoch 8/45\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.1207 - auc_30: 0.9915 - loss: 0.1032 - precision_30: 0.9972 - recall_30: 0.9397 - val_accuracy: 0.1351 - val_auc_30: 0.9815 - val_loss: 0.1688 - val_precision_30: 0.9496 - val_recall_30: 0.9041\n",
            "Epoch 9/45\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.1296 - auc_30: 0.9944 - loss: 0.0792 - precision_30: 0.9959 - recall_30: 0.9706 - val_accuracy: 0.1520 - val_auc_30: 0.9814 - val_loss: 0.1689 - val_precision_30: 0.9441 - val_recall_30: 0.9247\n",
            "Epoch 10/45\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.1586 - auc_30: 0.9919 - loss: 0.1004 - precision_30: 0.9745 - recall_30: 0.9595 - val_accuracy: 0.1520 - val_auc_30: 0.9661 - val_loss: 0.2539 - val_precision_30: 0.9559 - val_recall_30: 0.8904\n",
            "Epoch 11/45\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.1537 - auc_30: 0.9858 - loss: 0.1583 - precision_30: 0.9641 - recall_30: 0.9300 - val_accuracy: 0.1520 - val_auc_30: 0.9437 - val_loss: 0.4986 - val_precision_30: 0.9552 - val_recall_30: 0.8767\n",
            "Epoch 12/45\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.1481 - auc_30: 0.9763 - loss: 0.1979 - precision_30: 0.9878 - recall_30: 0.9267 - val_accuracy: 0.1824 - val_auc_30: 0.9811 - val_loss: 0.1780 - val_precision_30: 0.9433 - val_recall_30: 0.9110\n",
            "Epoch 13/45\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.1654 - auc_30: 0.9867 - loss: 0.1124 - precision_30: 0.9987 - recall_30: 0.9378 - val_accuracy: 0.1858 - val_auc_30: 0.9810 - val_loss: 0.1751 - val_precision_30: 0.9437 - val_recall_30: 0.9178\n",
            "Epoch 14/45\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.1907 - auc_30: 0.9912 - loss: 0.1181 - precision_30: 0.9592 - recall_30: 0.9673 - val_accuracy: 0.1757 - val_auc_30: 0.9549 - val_loss: 0.4187 - val_precision_30: 0.9556 - val_recall_30: 0.8836\n",
            "Epoch 15/45\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.1897 - auc_30: 0.9863 - loss: 0.1208 - precision_30: 0.9903 - recall_30: 0.9433 - val_accuracy: 0.1959 - val_auc_30: 0.9715 - val_loss: 0.2190 - val_precision_30: 0.9493 - val_recall_30: 0.8973\n",
            "Epoch 16/45\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.1970 - auc_30: 0.9961 - loss: 0.0791 - precision_30: 0.9973 - recall_30: 0.9435 - val_accuracy: 0.2095 - val_auc_30: 0.9813 - val_loss: 0.1907 - val_precision_30: 0.9496 - val_recall_30: 0.9041\n",
            "Epoch 17/45\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.1963 - auc_30: 0.9950 - loss: 0.0776 - precision_30: 0.9895 - recall_30: 0.9517 - val_accuracy: 0.2061 - val_auc_30: 0.9679 - val_loss: 0.2812 - val_precision_30: 0.9485 - val_recall_30: 0.8836\n",
            "Epoch 18/45\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.2055 - auc_30: 0.9948 - loss: 0.0850 - precision_30: 0.9961 - recall_30: 0.9342 - val_accuracy: 0.2128 - val_auc_30: 0.9737 - val_loss: 0.2163 - val_precision_30: 0.9562 - val_recall_30: 0.8973\n",
            "Epoch 19/45\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.2116 - auc_30: 0.9969 - loss: 0.0732 - precision_30: 0.9928 - recall_30: 0.9458 - val_accuracy: 0.2365 - val_auc_30: 0.9805 - val_loss: 0.1983 - val_precision_30: 0.9493 - val_recall_30: 0.8973\n",
            "Epoch 20/45\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.2339 - auc_30: 0.9965 - loss: 0.0718 - precision_30: 0.9952 - recall_30: 0.9429 - val_accuracy: 0.2432 - val_auc_30: 0.9808 - val_loss: 0.1950 - val_precision_30: 0.9315 - val_recall_30: 0.9315\n",
            "Epoch 21/45\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.2409 - auc_30: 0.9956 - loss: 0.0827 - precision_30: 0.9684 - recall_30: 0.9649 - val_accuracy: 0.2500 - val_auc_30: 0.9725 - val_loss: 0.2232 - val_precision_30: 0.9565 - val_recall_30: 0.9041\n",
            "Epoch 22/45\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.2333 - auc_30: 0.9941 - loss: 0.0952 - precision_30: 0.9808 - recall_30: 0.9437 - val_accuracy: 0.2399 - val_auc_30: 0.9663 - val_loss: 0.2914 - val_precision_30: 0.9556 - val_recall_30: 0.8836\n",
            "Epoch 23/45\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.2561 - auc_30: 0.9952 - loss: 0.0857 - precision_30: 0.9857 - recall_30: 0.9475 - val_accuracy: 0.2601 - val_auc_30: 0.9663 - val_loss: 0.2695 - val_precision_30: 0.9556 - val_recall_30: 0.8836\n",
            "Epoch 24/45\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.2535 - auc_30: 0.9982 - loss: 0.0611 - precision_30: 0.9978 - recall_30: 0.9545 - val_accuracy: 0.2703 - val_auc_30: 0.9769 - val_loss: 0.1998 - val_precision_30: 0.9565 - val_recall_30: 0.9041\n",
            "Epoch 25/45\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.2652 - auc_30: 0.9977 - loss: 0.0671 - precision_30: 0.9882 - recall_30: 0.9559 - val_accuracy: 0.2703 - val_auc_30: 0.9724 - val_loss: 0.2263 - val_precision_30: 0.9565 - val_recall_30: 0.9041\n",
            "Epoch 26/45\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.2655 - auc_30: 0.9977 - loss: 0.0600 - precision_30: 0.9900 - recall_30: 0.9629 - val_accuracy: 0.2703 - val_auc_30: 0.9774 - val_loss: 0.2013 - val_precision_30: 0.9504 - val_recall_30: 0.9178\n",
            "Epoch 27/45\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.2872 - auc_30: 0.9984 - loss: 0.0503 - precision_30: 0.9974 - recall_30: 0.9771 - val_accuracy: 0.2669 - val_auc_30: 0.9587 - val_loss: 0.4006 - val_precision_30: 0.9481 - val_recall_30: 0.8767\n",
            "Epoch 28/45\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.2669 - auc_30: 0.9979 - loss: 0.0634 - precision_30: 0.9942 - recall_30: 0.9602 - val_accuracy: 0.2838 - val_auc_30: 0.9745 - val_loss: 0.2312 - val_precision_30: 0.9500 - val_recall_30: 0.9110\n",
            "Epoch 29/45\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.2907 - auc_30: 0.9979 - loss: 0.0592 - precision_30: 0.9912 - recall_30: 0.9622 - val_accuracy: 0.2939 - val_auc_30: 0.9732 - val_loss: 0.2311 - val_precision_30: 0.9073 - val_recall_30: 0.9384\n",
            "Epoch 30/45\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.2777 - auc_30: 0.9943 - loss: 0.0896 - precision_30: 0.9744 - recall_30: 0.9735 - val_accuracy: 0.2770 - val_auc_30: 0.9530 - val_loss: 0.4243 - val_precision_30: 0.9481 - val_recall_30: 0.8767\n",
            "Epoch 31/45\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.2973 - auc_30: 0.9831 - loss: 0.1508 - precision_30: 0.9625 - recall_30: 0.9542 - val_accuracy: 0.2601 - val_auc_30: 0.9319 - val_loss: 0.9460 - val_precision_30: 0.9478 - val_recall_30: 0.8699\n",
            "Epoch 32/45\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.2757 - auc_30: 0.9680 - loss: 0.3724 - precision_30: 0.9896 - recall_30: 0.9189 - val_accuracy: 0.3007 - val_auc_30: 0.9732 - val_loss: 0.2317 - val_precision_30: 0.9139 - val_recall_30: 0.9452\n",
            "Epoch 33/45\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.3060 - auc_30: 0.9863 - loss: 0.1556 - precision_30: 0.9781 - recall_30: 0.9521 - val_accuracy: 0.2770 - val_auc_30: 0.9484 - val_loss: 0.5086 - val_precision_30: 0.9485 - val_recall_30: 0.8836\n",
            "Epoch 34/45\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.3004 - auc_30: 0.9850 - loss: 0.1251 - precision_30: 0.9815 - recall_30: 0.9574 - val_accuracy: 0.2872 - val_auc_30: 0.9571 - val_loss: 0.3486 - val_precision_30: 0.9420 - val_recall_30: 0.8904\n",
            "Epoch 35/45\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.3161 - auc_30: 0.9945 - loss: 0.0747 - precision_30: 0.9991 - recall_30: 0.9523 - val_accuracy: 0.2872 - val_auc_30: 0.9672 - val_loss: 0.2434 - val_precision_30: 0.9504 - val_recall_30: 0.9178\n",
            "Epoch 36/45\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.3025 - auc_30: 0.9972 - loss: 0.0792 - precision_30: 0.9630 - recall_30: 0.9775 - val_accuracy: 0.2872 - val_auc_30: 0.9552 - val_loss: 0.4123 - val_precision_30: 0.9481 - val_recall_30: 0.8767\n",
            "Epoch 37/45\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.2899 - auc_30: 0.9951 - loss: 0.0740 - precision_30: 1.0000 - recall_30: 0.9475 - val_accuracy: 0.2973 - val_auc_30: 0.9720 - val_loss: 0.2177 - val_precision_30: 0.9375 - val_recall_30: 0.9247\n",
            "Epoch 38/45\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.3122 - auc_30: 0.9933 - loss: 0.0997 - precision_30: 0.9558 - recall_30: 0.9875 - val_accuracy: 0.2905 - val_auc_30: 0.9529 - val_loss: 0.4199 - val_precision_30: 0.9412 - val_recall_30: 0.8767\n",
            "Epoch 39/45\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.2993 - auc_30: 0.9881 - loss: 0.1099 - precision_30: 0.9987 - recall_30: 0.9413 - val_accuracy: 0.3041 - val_auc_30: 0.9699 - val_loss: 0.2280 - val_precision_30: 0.9375 - val_recall_30: 0.9247\n",
            "Epoch 40/45\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.3114 - auc_30: 0.9980 - loss: 0.0592 - precision_30: 0.9817 - recall_30: 0.9753 - val_accuracy: 0.2973 - val_auc_30: 0.9526 - val_loss: 0.4016 - val_precision_30: 0.9416 - val_recall_30: 0.8836\n",
            "Epoch 41/45\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.3185 - auc_30: 0.9967 - loss: 0.0626 - precision_30: 0.9987 - recall_30: 0.9536 - val_accuracy: 0.3108 - val_auc_30: 0.9699 - val_loss: 0.2245 - val_precision_30: 0.9195 - val_recall_30: 0.9384\n",
            "Epoch 42/45\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.3126 - auc_30: 0.9958 - loss: 0.0969 - precision_30: 0.9690 - recall_30: 0.9770 - val_accuracy: 0.3041 - val_auc_30: 0.9512 - val_loss: 0.4575 - val_precision_30: 0.9552 - val_recall_30: 0.8767\n",
            "Epoch 43/45\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.3088 - auc_30: 0.9894 - loss: 0.0910 - precision_30: 0.9972 - recall_30: 0.9423 - val_accuracy: 0.3074 - val_auc_30: 0.9676 - val_loss: 0.2423 - val_precision_30: 0.9371 - val_recall_30: 0.9178\n",
            "Epoch 44/45\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.3116 - auc_30: 0.9962 - loss: 0.0751 - precision_30: 0.9776 - recall_30: 0.9593 - val_accuracy: 0.3074 - val_auc_30: 0.9540 - val_loss: 0.3620 - val_precision_30: 0.9485 - val_recall_30: 0.8836\n",
            "Epoch 45/45\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.3332 - auc_30: 0.9987 - loss: 0.0469 - precision_30: 0.9903 - recall_30: 0.9697 - val_accuracy: 0.3176 - val_auc_30: 0.9680 - val_loss: 0.2549 - val_precision_30: 0.9433 - val_recall_30: 0.9110\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "loss, accuracy, f1_score, precision, recall = model.evaluate(X_test, y_test)\n",
        "print(f'Loss: {loss}, Accuracy: {accuracy}, F1-Score: {f1_score}, Precision: {precision}, Recall: {recall}, AUC: {roc_auc_score(y_test, model.predict(X_test))}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "umC2yhfTJEm6",
        "outputId": "6fb89041-d3a2-4e75-8482-ccf5551cfdae"
      },
      "execution_count": 120,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m2671/2671\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 9.8481e-04 - auc_30: 0.9825 - loss: 0.2204 - precision_30: 0.0312 - recall_30: 0.9538\n",
            "\u001b[1m2671/2671\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step\n",
            "Loss: 0.2204991579055786, Accuracy: 0.0010533337481319904, F1-Score: 0.030080366879701614, Precision: 0.9632353186607361, Recall: 0.9857803583145142, AUC: 0.9900608976988993\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Criando um DataFrame para armazenar as métricas\n",
        "results = pd.DataFrame({\n",
        "    'Modelo': ['Original', 'Otimizado'],\n",
        "    'Accuracy': [0.9992, accuracy],\n",
        "    'Precision': [0.8823, precision],\n",
        "    'Recall': [0.6363, recall],\n",
        "    'F1-Score': [0.7407, f1_score],\n",
        "    'AUC': [0.9509, roc_auc_score(y_test, model.predict(X_test))]\n",
        "})\n",
        "\n",
        "# Plotando os gráficos\n",
        "fig = make_subplots(rows=2, cols=2, subplot_titles=('Accuracy', 'Precision', 'Recall', 'F1-Score'))\n",
        "\n",
        "fig.add_trace(go.Bar(x=results['Modelo'], y=results['Accuracy'], name='Accuracy'), row=1, col=1)\n",
        "fig.add_trace(go.Bar(x=results['Modelo'], y=results['Precision'], name='Precision'), row=1, col=2)\n",
        "fig.add_trace(go.Bar(x=results['Modelo'], y=results['Recall'], name='Recall'), row=2, col=1)\n",
        "fig.add_trace(go.Bar(x=results['Modelo'], y=results['F1-Score'], name='F1-Score'), row=2, col=2)\n",
        "\n",
        "fig.update_layout(height=600, width=800, title_text=\"Comparação de Métricas entre Modelos\")\n",
        "fig.show()\n",
        "\n",
        "# Gráfico para AUC\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.barplot(x='Modelo', y='AUC', data=results)\n",
        "plt.title('Comparação de AUC entre Modelos')\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "O02PjyZdOfoY",
        "outputId": "4e57ae57-2455-4804-f511-90dd562ac846"
      },
      "execution_count": 121,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m2671/2671\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 5ms/step\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script charset=\"utf-8\" src=\"https://cdn.plot.ly/plotly-2.24.1.min.js\"></script>                <div id=\"5553fa67-ab8a-4916-98ff-7509e582a6ed\" class=\"plotly-graph-div\" style=\"height:600px; width:800px;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"5553fa67-ab8a-4916-98ff-7509e582a6ed\")) {                    Plotly.newPlot(                        \"5553fa67-ab8a-4916-98ff-7509e582a6ed\",                        [{\"name\":\"Accuracy\",\"x\":[\"Original\",\"Otimizado\"],\"y\":[0.9992,0.0010533337481319904],\"type\":\"bar\",\"xaxis\":\"x\",\"yaxis\":\"y\"},{\"name\":\"Precision\",\"x\":[\"Original\",\"Otimizado\"],\"y\":[0.8823,0.9632353186607361],\"type\":\"bar\",\"xaxis\":\"x2\",\"yaxis\":\"y2\"},{\"name\":\"Recall\",\"x\":[\"Original\",\"Otimizado\"],\"y\":[0.6363,0.9857803583145142],\"type\":\"bar\",\"xaxis\":\"x3\",\"yaxis\":\"y3\"},{\"name\":\"F1-Score\",\"x\":[\"Original\",\"Otimizado\"],\"y\":[0.7407,0.030080366879701614],\"type\":\"bar\",\"xaxis\":\"x4\",\"yaxis\":\"y4\"}],                        {\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmapgl\":[{\"type\":\"heatmapgl\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"type\":\"scattergl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"bgcolor\":\"#E5ECF6\",\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"#E5ECF6\",\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"subunitcolor\":\"white\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"white\"},\"title\":{\"x\":0.05},\"mapbox\":{\"style\":\"light\"}}},\"xaxis\":{\"anchor\":\"y\",\"domain\":[0.0,0.45]},\"yaxis\":{\"anchor\":\"x\",\"domain\":[0.625,1.0]},\"xaxis2\":{\"anchor\":\"y2\",\"domain\":[0.55,1.0]},\"yaxis2\":{\"anchor\":\"x2\",\"domain\":[0.625,1.0]},\"xaxis3\":{\"anchor\":\"y3\",\"domain\":[0.0,0.45]},\"yaxis3\":{\"anchor\":\"x3\",\"domain\":[0.0,0.375]},\"xaxis4\":{\"anchor\":\"y4\",\"domain\":[0.55,1.0]},\"yaxis4\":{\"anchor\":\"x4\",\"domain\":[0.0,0.375]},\"annotations\":[{\"font\":{\"size\":16},\"showarrow\":false,\"text\":\"Accuracy\",\"x\":0.225,\"xanchor\":\"center\",\"xref\":\"paper\",\"y\":1.0,\"yanchor\":\"bottom\",\"yref\":\"paper\"},{\"font\":{\"size\":16},\"showarrow\":false,\"text\":\"Precision\",\"x\":0.775,\"xanchor\":\"center\",\"xref\":\"paper\",\"y\":1.0,\"yanchor\":\"bottom\",\"yref\":\"paper\"},{\"font\":{\"size\":16},\"showarrow\":false,\"text\":\"Recall\",\"x\":0.225,\"xanchor\":\"center\",\"xref\":\"paper\",\"y\":0.375,\"yanchor\":\"bottom\",\"yref\":\"paper\"},{\"font\":{\"size\":16},\"showarrow\":false,\"text\":\"F1-Score\",\"x\":0.775,\"xanchor\":\"center\",\"xref\":\"paper\",\"y\":0.375,\"yanchor\":\"bottom\",\"yref\":\"paper\"}],\"title\":{\"text\":\"Compara\\u00e7\\u00e3o de M\\u00e9tricas entre Modelos\"},\"height\":600,\"width\":800},                        {\"responsive\": true}                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('5553fa67-ab8a-4916-98ff-7509e582a6ed');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })                };                            </script>        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 800x600 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "7nuMJRlLPpoR"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.0"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}